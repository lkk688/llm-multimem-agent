
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../self-supervised/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>Deep Learning Foundations - Multimodal Memory LLM and AI Agent</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.4af4bdda.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#deep-learning-from-perceptrons-to-modern-architectures" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Multimodal Memory LLM and AI Agent" class="md-header__button md-logo" aria-label="Multimodal Memory LLM and AI Agent" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Multimodal Memory LLM and AI Agent
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Deep Learning Foundations
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Multimodal Memory LLM and AI Agent" class="md-nav__button md-logo" aria-label="Multimodal Memory LLM and AI Agent" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Multimodal Memory LLM and AI Agent
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Core Modules
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Core Modules
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Deep Learning Foundations
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Deep Learning Foundations
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    <span class="md-ellipsis">
      Table of Contents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      What is Deep Learning?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#history-of-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      History of Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="History of Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-perceptron-era-1940s-1960s" class="md-nav__link">
    <span class="md-ellipsis">
      The Perceptron Era (1940s-1960s)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Perceptron Era (1940s-1960s)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mcculloch-pitts-neuron-1943" class="md-nav__link">
    <span class="md-ellipsis">
      McCulloch-Pitts Neuron (1943)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rosenblatts-perceptron-1957" class="md-nav__link">
    <span class="md-ellipsis">
      Rosenblatt's Perceptron (1957)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-first-ai-winter-1969-1980s" class="md-nav__link">
    <span class="md-ellipsis">
      The First AI Winter (1969-1980s)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-multi-layer-perceptron-renaissance-1980s" class="md-nav__link">
    <span class="md-ellipsis">
      The Multi-Layer Perceptron Renaissance (1980s)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Multi-Layer Perceptron Renaissance (1980s)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backpropagation-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation Algorithm
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-second-ai-winter-1990s" class="md-nav__link">
    <span class="md-ellipsis">
      The Second AI Winter (1990s)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-deep-learning-revolution" class="md-nav__link">
    <span class="md-ellipsis">
      The Deep Learning Revolution
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Deep Learning Revolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-perfect-storm-2000s-2010s" class="md-nav__link">
    <span class="md-ellipsis">
      The Perfect Storm (2000s-2010s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imagenet-and-the-visual-recognition-challenge" class="md-nav__link">
    <span class="md-ellipsis">
      ImageNet and the Visual Recognition Challenge
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#convolutional-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Convolutional Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-context-and-evolution" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Context and Evolution
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mathematical Foundation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolution-operation-mathematical-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Convolution Operation - Mathematical Deep Dive
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-channel-convolution-complete-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Channel Convolution - Complete Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-size-calculation-comprehensive-formula" class="md-nav__link">
    <span class="md-ellipsis">
      Output Size Calculation - Comprehensive Formula
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pooling-operations-dimensionality-reduction-and-translation-invariance" class="md-nav__link">
    <span class="md-ellipsis">
      Pooling Operations - Dimensionality Reduction and Translation Invariance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pooling Operations - Dimensionality Reduction and Translation Invariance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#max-pooling-preserving-dominant-features" class="md-nav__link">
    <span class="md-ellipsis">
      Max Pooling - Preserving Dominant Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#average-pooling-smooth-feature-aggregation" class="md-nav__link">
    <span class="md-ellipsis">
      Average Pooling - Smooth Feature Aggregation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#global-average-pooling-spatial-information-collapse" class="md-nav__link">
    <span class="md-ellipsis">
      Global Average Pooling - Spatial Information Collapse
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-functions-nonlinearity-and-gradient-flow" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Functions - Nonlinearity and Gradient Flow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Activation Functions - Nonlinearity and Gradient Flow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#relu-family-addressing-the-vanishing-gradient-problem" class="md-nav__link">
    <span class="md-ellipsis">
      ReLU Family - Addressing the Vanishing Gradient Problem
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-activation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Activation Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-function-selection-guidelines" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Function Selection Guidelines
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alexnet-the-deep-learning-revolution" class="md-nav__link">
    <span class="md-ellipsis">
      AlexNet - The Deep Learning Revolution
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AlexNet - The Deep Learning Revolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-impact-and-context" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Impact and Context
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-innovations-and-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Key Innovations and Techniques
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-and-training-details" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation and Training Details
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#legacy-and-modern-relevance" class="md-nav__link">
    <span class="md-ellipsis">
      Legacy and Modern Relevance
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#major-cnn-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      Major CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Major CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vggnet-depth-matters-2014" class="md-nav__link">
    <span class="md-ellipsis">
      VGGNet: Depth Matters (2014)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VGGNet: Depth Matters (2014)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations" class="md-nav__link">
    <span class="md-ellipsis">
      Key Innovations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-33-filters" class="md-nav__link">
    <span class="md-ellipsis">
      Why 3×3 Filters?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg-16-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      VGG-16 Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnet-the-residual-revolution-2015" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet: The Residual Revolution (2015)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ResNet: The Residual Revolution (2015)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-degradation-problem" class="md-nav__link">
    <span class="md-ellipsis">
      The Degradation Problem
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#residual-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Residual Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#residual-block-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Residual Block Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bottleneck-architecture-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Bottleneck Architecture Deep Dive
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evolution-of-bottleneck-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      Evolution of Bottleneck Architectures
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-formulation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Formulation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-flow-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Flow Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnet-50-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet-50 Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#impact-and-variants" class="md-nav__link">
    <span class="md-ellipsis">
      Impact and Variants
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#googlenetinception-efficient-architecture-design-2014" class="md-nav__link">
    <span class="md-ellipsis">
      GoogLeNet/Inception: Efficient Architecture Design (2014)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GoogLeNet/Inception: Efficient Architecture Design (2014)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inception-module" class="md-nav__link">
    <span class="md-ellipsis">
      Inception Module
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auxiliary-classifiers" class="md-nav__link">
    <span class="md-ellipsis">
      Auxiliary Classifiers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-cnn-architectures-post-googlenet-era" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced CNN Architectures: Post-GoogLeNet Era
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced CNN Architectures: Post-GoogLeNet Era">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mobilenet-v1-efficient-mobile-vision-2017" class="md-nav__link">
    <span class="md-ellipsis">
      MobileNet v1: Efficient Mobile Vision (2017)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mobilenet-v2-inverted-residuals-and-linear-bottlenecks-2018" class="md-nav__link">
    <span class="md-ellipsis">
      MobileNet v2: Inverted Residuals and Linear Bottlenecks (2018)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnext-aggregated-residual-transformations-2017" class="md-nav__link">
    <span class="md-ellipsis">
      ResNeXt: Aggregated Residual Transformations (2017)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#efficientnet-compound-scaling-2019" class="md-nav__link">
    <span class="md-ellipsis">
      EfficientNet: Compound Scaling (2019)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regnet-designing-network-design-spaces-2020" class="md-nav__link">
    <span class="md-ellipsis">
      RegNet: Designing Network Design Spaces (2020)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convnext-a-convnet-for-the-2020s-2022" class="md-nav__link">
    <span class="md-ellipsis">
      ConvNeXt: A ConvNet for the 2020s (2022)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture-evolution-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture Evolution Summary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-cnn-design-principles" class="md-nav__link">
    <span class="md-ellipsis">
      Modern CNN Design Principles
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimization-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Optimization Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Optimization Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gradient-descent-variants" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Descent Variants
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Gradient Descent Variants">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stochastic-gradient-descent-sgd" class="md-nav__link">
    <span class="md-ellipsis">
      Stochastic Gradient Descent (SGD)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive-learning-rate-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Adaptive Learning Rate Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate Scheduling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Learning Rate Scheduling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-decay" class="md-nav__link">
    <span class="md-ellipsis">
      Step Decay
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exponential-decay" class="md-nav__link">
    <span class="md-ellipsis">
      Exponential Decay
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine-annealing" class="md-nav__link">
    <span class="md-ellipsis">
      Cosine Annealing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warm-up-and-restart" class="md-nav__link">
    <span class="md-ellipsis">
      Warm-up and Restart
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weight-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Weight Initialization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Weight Initialization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#xavierglorot-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Xavier/Glorot Initialization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#he-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      He Initialization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularization-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Regularization Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularization Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#l1-and-l2-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      L1 and L2 Regularization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="L1 and L2 Regularization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#l2-regularization-weight-decay" class="md-nav__link">
    <span class="md-ellipsis">
      L2 Regularization (Weight Decay)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1-regularization-lasso" class="md-nav__link">
    <span class="md-ellipsis">
      L1 Regularization (Lasso)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#elastic-net" class="md-nav__link">
    <span class="md-ellipsis">
      Elastic Net
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dropout">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#standard-dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Standard Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverted-dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Inverted Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropconnect" class="md-nav__link">
    <span class="md-ellipsis">
      DropConnect
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Batch Normalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benefits" class="md-nav__link">
    <span class="md-ellipsis">
      Benefits
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variants" class="md-nav__link">
    <span class="md-ellipsis">
      Variants
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Data Augmentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Augmentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#traditional-augmentations" class="md-nav__link">
    <span class="md-ellipsis">
      Traditional Augmentations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-augmentations" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Augmentations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-training-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Training Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Training Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transfer Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fine-tuning-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tuning Strategies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-gpu-training" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-GPU Training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-GPU Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Data Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distributed-training" class="md-nav__link">
    <span class="md-ellipsis">
      Distributed Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mixed-precision-training" class="md-nav__link">
    <span class="md-ellipsis">
      Mixed Precision Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modern-architectures-and-trends" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Architectures and Trends
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Modern Architectures and Trends">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vision-transformers-vits" class="md-nav__link">
    <span class="md-ellipsis">
      Vision Transformers (ViTs)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vision Transformers (ViTs)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-formulation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Formulation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-architecture-search-nas-evolution-and-current-status" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Architecture Search (NAS): Evolution and Current Status
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Neural Architecture Search (NAS): Evolution and Current Status">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-context-and-peak-era-2017-2020" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Context and Peak Era (2017-2020)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#darts-differentiable-architecture-search" class="md-nav__link">
    <span class="md-ellipsis">
      DARTS (Differentiable Architecture Search)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#current-status-of-nas-2024-perspective" class="md-nav__link">
    <span class="md-ellipsis">
      Current Status of NAS (2024 Perspective)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semi-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Semi-Supervised Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Semi-Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#problem-formulation" class="md-nav__link">
    <span class="md-ellipsis">
      Problem Formulation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consistency-regularization-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Consistency Regularization Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Consistency Regularization Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#-model-and-temporal-ensembling" class="md-nav__link">
    <span class="md-ellipsis">
      Π-Model and Temporal Ensembling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-teacher" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Teacher
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pseudo-labeling-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Pseudo-Labeling Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pseudo-Labeling Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#self-training-and-co-training" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Training and Co-Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fixmatch-and-advanced-methods" class="md-nav__link">
    <span class="md-ellipsis">
      FixMatch and Advanced Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-semi-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Semi-Supervised Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Modern Semi-Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mixmatch-and-remixmatch" class="md-nav__link">
    <span class="md-ellipsis">
      MixMatch and ReMixMatch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#current-applications-and-trends-2023-2024" class="md-nav__link">
    <span class="md-ellipsis">
      Current Applications and Trends (2023-2024)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Supervised Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Self-Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contrastive-learning-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Learning Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Contrastive Learning Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#simclr-and-moco-family" class="md-nav__link">
    <span class="md-ellipsis">
      SimCLR and MoCo Family
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#swav-and-advanced-contrastive-methods" class="md-nav__link">
    <span class="md-ellipsis">
      SwAV and Advanced Contrastive Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#masked-modeling-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Masked Modeling Approaches
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Masked Modeling Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vision-mae-and-beyond" class="md-nav__link">
    <span class="md-ellipsis">
      Vision: MAE and Beyond
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#language-bert-to-modern-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Language: BERT to Modern LLMs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metas-dino-series-self-supervised-vision-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      Meta's DINO Series: Self-Supervised Vision Transformers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Meta&#39;s DINO Series: Self-Supervised Vision Transformers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dino-2021" class="md-nav__link">
    <span class="md-ellipsis">
      DINO (2021)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dinov2-2023" class="md-nav__link">
    <span class="md-ellipsis">
      DINOv2 (2023)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dinov3-2024" class="md-nav__link">
    <span class="md-ellipsis">
      DINOv3 (2024)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#core-technical-innovations" class="md-nav__link">
    <span class="md-ellipsis">
      Core Technical Innovations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-achievements" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Achievements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical-architecture-details" class="md-nav__link">
    <span class="md-ellipsis">
      Technical Architecture Details
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practical-impact-and-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Impact and Applications
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#future-directions-and-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      Future Directions and Limitations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#current-trends-and-research-focus-2023-2024" class="md-nav__link">
    <span class="md-ellipsis">
      Current Trends and Research Focus (2023-2024)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Current Trends and Research Focus (2023-2024)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#foundation-models-and-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      Foundation Models and Scaling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#efficiency-and-practical-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Efficiency and Practical Applications
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#research-directions-2024" class="md-nav__link">
    <span class="md-ellipsis">
      Research Directions (2024)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-guide" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Guide
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Implementation Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setting-up-a-deep-learning-project" class="md-nav__link">
    <span class="md-ellipsis">
      Setting Up a Deep Learning Project
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Setting Up a Deep Learning Project">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#project-structure" class="md-nav__link">
    <span class="md-ellipsis">
      Project Structure
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuration-management" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration Management
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-loop-template" class="md-nav__link">
    <span class="md-ellipsis">
      Training Loop Template
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debugging-and-monitoring" class="md-nav__link">
    <span class="md-ellipsis">
      Debugging and Monitoring
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Debugging and Monitoring">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#common-issues-and-solutions" class="md-nav__link">
    <span class="md-ellipsis">
      Common Issues and Solutions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references-and-resources" class="md-nav__link">
    <span class="md-ellipsis">
      References and Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="References and Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#foundational-papers" class="md-nav__link">
    <span class="md-ellipsis">
      Foundational Papers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Foundational Papers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Foundations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Deep Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimization-and-training" class="md-nav__link">
    <span class="md-ellipsis">
      Optimization and Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#self-supervised-learning_1" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Supervised Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-resources" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Implementation Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#frameworks-and-libraries" class="md-nav__link">
    <span class="md-ellipsis">
      Frameworks and Libraries
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datasets" class="md-nav__link">
    <span class="md-ellipsis">
      Datasets
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tools-and-utilities" class="md-nav__link">
    <span class="md-ellipsis">
      Tools and Utilities
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#books-and-courses" class="md-nav__link">
    <span class="md-ellipsis">
      Books and Courses
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Books and Courses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#books" class="md-nav__link">
    <span class="md-ellipsis">
      Books
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#online-courses" class="md-nav__link">
    <span class="md-ellipsis">
      Online Courses
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Takeaways">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-perspective" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Perspective
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architectural-principles" class="md-nav__link">
    <span class="md-ellipsis">
      Architectural Principles
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Training Best Practices
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-trends" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Trends
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#future-directions" class="md-nav__link">
    <span class="md-ellipsis">
      Future Directions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../self-supervised/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Self-Supervised Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer Fundamentals
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../embeddings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multimodal Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLM Frameworks and Architectures
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../memory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Memory Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tool Calling and Agent Capabilities
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multi_modal_LM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Modal Language Models
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Advanced Topics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Advanced Topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers_advanced/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced Transformer Techniques
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference_optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inference Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_architecture_evolution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPT Architecture Evolution
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autonomous_system/autonomous_systems_survey/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autonomous Systems Survey
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../physical_ai_autonomous_driving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Physical AI in Autonomous Driving
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Notebooks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Notebooks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/memory_example/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Memory Example
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    <span class="md-ellipsis">
      Table of Contents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      What is Deep Learning?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#history-of-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      History of Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="History of Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-perceptron-era-1940s-1960s" class="md-nav__link">
    <span class="md-ellipsis">
      The Perceptron Era (1940s-1960s)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Perceptron Era (1940s-1960s)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mcculloch-pitts-neuron-1943" class="md-nav__link">
    <span class="md-ellipsis">
      McCulloch-Pitts Neuron (1943)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rosenblatts-perceptron-1957" class="md-nav__link">
    <span class="md-ellipsis">
      Rosenblatt's Perceptron (1957)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-first-ai-winter-1969-1980s" class="md-nav__link">
    <span class="md-ellipsis">
      The First AI Winter (1969-1980s)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-multi-layer-perceptron-renaissance-1980s" class="md-nav__link">
    <span class="md-ellipsis">
      The Multi-Layer Perceptron Renaissance (1980s)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Multi-Layer Perceptron Renaissance (1980s)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backpropagation-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation Algorithm
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-second-ai-winter-1990s" class="md-nav__link">
    <span class="md-ellipsis">
      The Second AI Winter (1990s)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-deep-learning-revolution" class="md-nav__link">
    <span class="md-ellipsis">
      The Deep Learning Revolution
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Deep Learning Revolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-perfect-storm-2000s-2010s" class="md-nav__link">
    <span class="md-ellipsis">
      The Perfect Storm (2000s-2010s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imagenet-and-the-visual-recognition-challenge" class="md-nav__link">
    <span class="md-ellipsis">
      ImageNet and the Visual Recognition Challenge
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#convolutional-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Convolutional Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-context-and-evolution" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Context and Evolution
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mathematical Foundation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convolution-operation-mathematical-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Convolution Operation - Mathematical Deep Dive
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-channel-convolution-complete-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Channel Convolution - Complete Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-size-calculation-comprehensive-formula" class="md-nav__link">
    <span class="md-ellipsis">
      Output Size Calculation - Comprehensive Formula
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pooling-operations-dimensionality-reduction-and-translation-invariance" class="md-nav__link">
    <span class="md-ellipsis">
      Pooling Operations - Dimensionality Reduction and Translation Invariance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pooling Operations - Dimensionality Reduction and Translation Invariance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#max-pooling-preserving-dominant-features" class="md-nav__link">
    <span class="md-ellipsis">
      Max Pooling - Preserving Dominant Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#average-pooling-smooth-feature-aggregation" class="md-nav__link">
    <span class="md-ellipsis">
      Average Pooling - Smooth Feature Aggregation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#global-average-pooling-spatial-information-collapse" class="md-nav__link">
    <span class="md-ellipsis">
      Global Average Pooling - Spatial Information Collapse
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-functions-nonlinearity-and-gradient-flow" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Functions - Nonlinearity and Gradient Flow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Activation Functions - Nonlinearity and Gradient Flow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#relu-family-addressing-the-vanishing-gradient-problem" class="md-nav__link">
    <span class="md-ellipsis">
      ReLU Family - Addressing the Vanishing Gradient Problem
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-activation-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Activation Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-function-selection-guidelines" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Function Selection Guidelines
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alexnet-the-deep-learning-revolution" class="md-nav__link">
    <span class="md-ellipsis">
      AlexNet - The Deep Learning Revolution
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AlexNet - The Deep Learning Revolution">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-impact-and-context" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Impact and Context
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-innovations-and-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Key Innovations and Techniques
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-and-training-details" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation and Training Details
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#legacy-and-modern-relevance" class="md-nav__link">
    <span class="md-ellipsis">
      Legacy and Modern Relevance
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#major-cnn-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      Major CNN Architectures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Major CNN Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vggnet-depth-matters-2014" class="md-nav__link">
    <span class="md-ellipsis">
      VGGNet: Depth Matters (2014)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VGGNet: Depth Matters (2014)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations" class="md-nav__link">
    <span class="md-ellipsis">
      Key Innovations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-33-filters" class="md-nav__link">
    <span class="md-ellipsis">
      Why 3×3 Filters?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vgg-16-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      VGG-16 Architecture
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnet-the-residual-revolution-2015" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet: The Residual Revolution (2015)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ResNet: The Residual Revolution (2015)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-degradation-problem" class="md-nav__link">
    <span class="md-ellipsis">
      The Degradation Problem
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#residual-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Residual Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#residual-block-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Residual Block Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bottleneck-architecture-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Bottleneck Architecture Deep Dive
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evolution-of-bottleneck-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      Evolution of Bottleneck Architectures
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-formulation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Formulation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-flow-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Flow Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnet-50-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      ResNet-50 Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#impact-and-variants" class="md-nav__link">
    <span class="md-ellipsis">
      Impact and Variants
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#googlenetinception-efficient-architecture-design-2014" class="md-nav__link">
    <span class="md-ellipsis">
      GoogLeNet/Inception: Efficient Architecture Design (2014)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GoogLeNet/Inception: Efficient Architecture Design (2014)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#inception-module" class="md-nav__link">
    <span class="md-ellipsis">
      Inception Module
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auxiliary-classifiers" class="md-nav__link">
    <span class="md-ellipsis">
      Auxiliary Classifiers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-cnn-architectures-post-googlenet-era" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced CNN Architectures: Post-GoogLeNet Era
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced CNN Architectures: Post-GoogLeNet Era">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mobilenet-v1-efficient-mobile-vision-2017" class="md-nav__link">
    <span class="md-ellipsis">
      MobileNet v1: Efficient Mobile Vision (2017)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mobilenet-v2-inverted-residuals-and-linear-bottlenecks-2018" class="md-nav__link">
    <span class="md-ellipsis">
      MobileNet v2: Inverted Residuals and Linear Bottlenecks (2018)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resnext-aggregated-residual-transformations-2017" class="md-nav__link">
    <span class="md-ellipsis">
      ResNeXt: Aggregated Residual Transformations (2017)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#efficientnet-compound-scaling-2019" class="md-nav__link">
    <span class="md-ellipsis">
      EfficientNet: Compound Scaling (2019)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regnet-designing-network-design-spaces-2020" class="md-nav__link">
    <span class="md-ellipsis">
      RegNet: Designing Network Design Spaces (2020)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convnext-a-convnet-for-the-2020s-2022" class="md-nav__link">
    <span class="md-ellipsis">
      ConvNeXt: A ConvNet for the 2020s (2022)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture-evolution-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture Evolution Summary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-cnn-design-principles" class="md-nav__link">
    <span class="md-ellipsis">
      Modern CNN Design Principles
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimization-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Optimization Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Optimization Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gradient-descent-variants" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Descent Variants
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Gradient Descent Variants">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stochastic-gradient-descent-sgd" class="md-nav__link">
    <span class="md-ellipsis">
      Stochastic Gradient Descent (SGD)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptive-learning-rate-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Adaptive Learning Rate Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate-scheduling" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate Scheduling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Learning Rate Scheduling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-decay" class="md-nav__link">
    <span class="md-ellipsis">
      Step Decay
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exponential-decay" class="md-nav__link">
    <span class="md-ellipsis">
      Exponential Decay
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine-annealing" class="md-nav__link">
    <span class="md-ellipsis">
      Cosine Annealing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warm-up-and-restart" class="md-nav__link">
    <span class="md-ellipsis">
      Warm-up and Restart
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weight-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Weight Initialization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Weight Initialization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#xavierglorot-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Xavier/Glorot Initialization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#he-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      He Initialization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularization-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Regularization Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularization Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#l1-and-l2-regularization" class="md-nav__link">
    <span class="md-ellipsis">
      L1 and L2 Regularization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="L1 and L2 Regularization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#l2-regularization-weight-decay" class="md-nav__link">
    <span class="md-ellipsis">
      L2 Regularization (Weight Decay)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1-regularization-lasso" class="md-nav__link">
    <span class="md-ellipsis">
      L1 Regularization (Lasso)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#elastic-net" class="md-nav__link">
    <span class="md-ellipsis">
      Elastic Net
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dropout">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#standard-dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Standard Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverted-dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Inverted Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropconnect" class="md-nav__link">
    <span class="md-ellipsis">
      DropConnect
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Normalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Batch Normalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#benefits" class="md-nav__link">
    <span class="md-ellipsis">
      Benefits
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variants" class="md-nav__link">
    <span class="md-ellipsis">
      Variants
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-augmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Data Augmentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Augmentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#traditional-augmentations" class="md-nav__link">
    <span class="md-ellipsis">
      Traditional Augmentations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-augmentations" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Augmentations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-training-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Training Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Training Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transfer Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fine-tuning-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tuning Strategies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-gpu-training" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-GPU Training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-GPU Training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-parallelism" class="md-nav__link">
    <span class="md-ellipsis">
      Data Parallelism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distributed-training" class="md-nav__link">
    <span class="md-ellipsis">
      Distributed Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mixed-precision-training" class="md-nav__link">
    <span class="md-ellipsis">
      Mixed Precision Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modern-architectures-and-trends" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Architectures and Trends
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Modern Architectures and Trends">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vision-transformers-vits" class="md-nav__link">
    <span class="md-ellipsis">
      Vision Transformers (ViTs)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vision Transformers (ViTs)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-formulation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Formulation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-architecture-search-nas-evolution-and-current-status" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Architecture Search (NAS): Evolution and Current Status
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Neural Architecture Search (NAS): Evolution and Current Status">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-context-and-peak-era-2017-2020" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Context and Peak Era (2017-2020)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#darts-differentiable-architecture-search" class="md-nav__link">
    <span class="md-ellipsis">
      DARTS (Differentiable Architecture Search)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#current-status-of-nas-2024-perspective" class="md-nav__link">
    <span class="md-ellipsis">
      Current Status of NAS (2024 Perspective)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#semi-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Semi-Supervised Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Semi-Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#problem-formulation" class="md-nav__link">
    <span class="md-ellipsis">
      Problem Formulation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#consistency-regularization-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Consistency Regularization Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Consistency Regularization Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#-model-and-temporal-ensembling" class="md-nav__link">
    <span class="md-ellipsis">
      Π-Model and Temporal Ensembling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-teacher" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Teacher
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pseudo-labeling-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Pseudo-Labeling Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pseudo-Labeling Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#self-training-and-co-training" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Training and Co-Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fixmatch-and-advanced-methods" class="md-nav__link">
    <span class="md-ellipsis">
      FixMatch and Advanced Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-semi-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Semi-Supervised Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Modern Semi-Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mixmatch-and-remixmatch" class="md-nav__link">
    <span class="md-ellipsis">
      MixMatch and ReMixMatch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#current-applications-and-trends-2023-2024" class="md-nav__link">
    <span class="md-ellipsis">
      Current Applications and Trends (2023-2024)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Supervised Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Self-Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contrastive-learning-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Learning Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Contrastive Learning Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#simclr-and-moco-family" class="md-nav__link">
    <span class="md-ellipsis">
      SimCLR and MoCo Family
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#swav-and-advanced-contrastive-methods" class="md-nav__link">
    <span class="md-ellipsis">
      SwAV and Advanced Contrastive Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#masked-modeling-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Masked Modeling Approaches
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Masked Modeling Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vision-mae-and-beyond" class="md-nav__link">
    <span class="md-ellipsis">
      Vision: MAE and Beyond
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#language-bert-to-modern-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Language: BERT to Modern LLMs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metas-dino-series-self-supervised-vision-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      Meta's DINO Series: Self-Supervised Vision Transformers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Meta&#39;s DINO Series: Self-Supervised Vision Transformers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dino-2021" class="md-nav__link">
    <span class="md-ellipsis">
      DINO (2021)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dinov2-2023" class="md-nav__link">
    <span class="md-ellipsis">
      DINOv2 (2023)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dinov3-2024" class="md-nav__link">
    <span class="md-ellipsis">
      DINOv3 (2024)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#core-technical-innovations" class="md-nav__link">
    <span class="md-ellipsis">
      Core Technical Innovations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-achievements" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Achievements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#technical-architecture-details" class="md-nav__link">
    <span class="md-ellipsis">
      Technical Architecture Details
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practical-impact-and-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Impact and Applications
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#future-directions-and-limitations" class="md-nav__link">
    <span class="md-ellipsis">
      Future Directions and Limitations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#current-trends-and-research-focus-2023-2024" class="md-nav__link">
    <span class="md-ellipsis">
      Current Trends and Research Focus (2023-2024)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Current Trends and Research Focus (2023-2024)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#foundation-models-and-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      Foundation Models and Scaling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#efficiency-and-practical-applications" class="md-nav__link">
    <span class="md-ellipsis">
      Efficiency and Practical Applications
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#research-directions-2024" class="md-nav__link">
    <span class="md-ellipsis">
      Research Directions (2024)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-guide" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Guide
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Implementation Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setting-up-a-deep-learning-project" class="md-nav__link">
    <span class="md-ellipsis">
      Setting Up a Deep Learning Project
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Setting Up a Deep Learning Project">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#project-structure" class="md-nav__link">
    <span class="md-ellipsis">
      Project Structure
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuration-management" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration Management
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-loop-template" class="md-nav__link">
    <span class="md-ellipsis">
      Training Loop Template
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debugging-and-monitoring" class="md-nav__link">
    <span class="md-ellipsis">
      Debugging and Monitoring
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Debugging and Monitoring">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#common-issues-and-solutions" class="md-nav__link">
    <span class="md-ellipsis">
      Common Issues and Solutions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references-and-resources" class="md-nav__link">
    <span class="md-ellipsis">
      References and Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="References and Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#foundational-papers" class="md-nav__link">
    <span class="md-ellipsis">
      Foundational Papers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Foundational Papers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Foundations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Deep Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimization-and-training" class="md-nav__link">
    <span class="md-ellipsis">
      Optimization and Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#self-supervised-learning_1" class="md-nav__link">
    <span class="md-ellipsis">
      Self-Supervised Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementation-resources" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Implementation Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#frameworks-and-libraries" class="md-nav__link">
    <span class="md-ellipsis">
      Frameworks and Libraries
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datasets" class="md-nav__link">
    <span class="md-ellipsis">
      Datasets
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tools-and-utilities" class="md-nav__link">
    <span class="md-ellipsis">
      Tools and Utilities
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#books-and-courses" class="md-nav__link">
    <span class="md-ellipsis">
      Books and Courses
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Books and Courses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#books" class="md-nav__link">
    <span class="md-ellipsis">
      Books
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#online-courses" class="md-nav__link">
    <span class="md-ellipsis">
      Online Courses
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Takeaways">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#historical-perspective" class="md-nav__link">
    <span class="md-ellipsis">
      Historical Perspective
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architectural-principles" class="md-nav__link">
    <span class="md-ellipsis">
      Architectural Principles
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Training Best Practices
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-trends" class="md-nav__link">
    <span class="md-ellipsis">
      Modern Trends
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#future-directions" class="md-nav__link">
    <span class="md-ellipsis">
      Future Directions
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="deep-learning-from-perceptrons-to-modern-architectures">Deep Learning: From Perceptrons to Modern Architectures</h1>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#history-of-neural-networks">History of Neural Networks</a></li>
<li><a href="#the-deep-learning-revolution">The Deep Learning Revolution</a></li>
<li><a href="#convolutional-neural-networks">Convolutional Neural Networks</a></li>
<li><a href="#major-cnn-architectures">Major CNN Architectures</a></li>
<li><a href="#advanced-cnn-architectures-post-googlenet-era">Advanced CNN Architectures: Post-GoogLeNet Era</a></li>
<li><a href="#neural-architecture-search-nas-evolution-and-current-status">Neural Architecture Search (NAS)</a></li>
<li><a href="#optimization-techniques">Optimization Techniques</a></li>
<li><a href="#regularization-methods">Regularization Methods</a></li>
<li><a href="#advanced-training-techniques">Advanced Training Techniques</a></li>
<li><a href="#modern-architectures-and-trends">Modern Architectures and Trends</a></li>
<li><a href="#semi-supervised-learning">Semi-Supervised Learning</a></li>
<li><a href="#self-supervised-learning">Self-Supervised Learning</a></li>
<li><a href="#implementation-guide">Implementation Guide</a></li>
<li><a href="#references-and-resources">References and Resources</a></li>
</ol>
<hr />
<h2 id="introduction">Introduction</h2>
<p>Deep Learning has revolutionized artificial intelligence, enabling breakthroughs in computer vision, natural language processing, speech recognition, and many other domains. This comprehensive tutorial explores the evolution of neural networks from simple perceptrons to sophisticated modern architectures.</p>
<h3 id="what-is-deep-learning">What is Deep Learning?</h3>
<p>Deep Learning is a subset of machine learning that uses artificial neural networks with multiple layers (hence "deep") to model and understand complex patterns in data. The key characteristics include:</p>
<ul>
<li><strong>Hierarchical Feature Learning</strong>: Automatic extraction of features at multiple levels of abstraction</li>
<li><strong>End-to-End Learning</strong>: Direct mapping from raw input to desired output</li>
<li><strong>Scalability</strong>: Performance improves with more data and computational resources</li>
<li><strong>Versatility</strong>: Applicable across diverse domains and tasks</li>
</ul>
<h3 id="mathematical-foundation">Mathematical Foundation</h3>
<p>At its core, deep learning involves learning a function <span class="arithmatex">\(f: \mathcal{X} \rightarrow \mathcal{Y}\)</span> that maps inputs <span class="arithmatex">\(x \in \mathcal{X}\)</span> to outputs <span class="arithmatex">\(y \in \mathcal{Y}\)</span>. This function is approximated by a composition of simpler functions:</p>
<div class="arithmatex">\[f(x) = f^{(L)}(f^{(L-1)}(...f^{(2)}(f^{(1)}(x))))\]</div>
<p>Where each <span class="arithmatex">\(f^{(i)}\)</span> represents a layer in the network, and <span class="arithmatex">\(L\)</span> is the total number of layers.</p>
<hr />
<h2 id="history-of-neural-networks">History of Neural Networks</h2>
<h3 id="the-perceptron-era-1940s-1960s">The Perceptron Era (1940s-1960s)</h3>
<h4 id="mcculloch-pitts-neuron-1943">McCulloch-Pitts Neuron (1943)</h4>
<p><strong>Paper</strong>: <a href="https://link.springer.com/article/10.1007/BF02478259">A Logical Calculus of Ideas Immanent in Nervous Activity</a></p>
<p>The first mathematical model of a neuron, proposed by Warren McCulloch and Walter Pitts:</p>
<div class="arithmatex">\[y = \begin{cases}
1 &amp; \text{if } \sum_{i=1}^n w_i x_i \geq \theta \\
0 &amp; \text{otherwise}
\end{cases}\]</div>
<p>Where:
- <span class="arithmatex">\(x_i\)</span> are binary inputs
- <span class="arithmatex">\(w_i\)</span> are weights
- <span class="arithmatex">\(\theta\)</span> is the threshold
- <span class="arithmatex">\(y\)</span> is the binary output</p>
<h4 id="rosenblatts-perceptron-1957">Rosenblatt's Perceptron (1957)</h4>
<p><strong>Paper</strong>: <a href="https://psycnet.apa.org/record/1959-09865-001">The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain</a></p>
<p>Frank Rosenblatt introduced the first learning algorithm for neural networks:</p>
<div class="arithmatex">\[w_{i}^{(t+1)} = w_{i}^{(t)} + \eta (y - \hat{y}) x_i\]</div>
<p>Where:
- <span class="arithmatex">\(\eta\)</span> is the learning rate
- <span class="arithmatex">\(y\)</span> is the true label
- <span class="arithmatex">\(\hat{y}\)</span> is the predicted output
- <span class="arithmatex">\(t\)</span> denotes the time step</p>
<p><strong>Perceptron Learning Algorithm</strong>:
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">perceptron_update</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Update perceptron weights using the perceptron learning rule</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)):</span>
        <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">error</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">weights</span>
</code></pre></div></p>
<h4 id="the-first-ai-winter-1969-1980s">The First AI Winter (1969-1980s)</h4>
<p><strong>Minsky and Papert's Critique</strong>: <a href="https://mitpress.mit.edu/9780262630221/perceptrons/">Perceptrons: An Introduction to Computational Geometry</a></p>
<p>In 1969, Marvin Minsky and Seymour Papert proved that single-layer perceptrons cannot solve linearly non-separable problems like XOR:</p>
<p><strong>XOR Problem</strong>:
| <span class="arithmatex">\(x_1\)</span> | <span class="arithmatex">\(x_2\)</span> | XOR |
|-------|-------|-----|
| 0     | 0     | 0   |
| 0     | 1     | 1   |
| 1     | 0     | 1   |
| 1     | 1     | 0   |</p>
<p>No single line can separate the positive and negative examples, highlighting the limitations of linear classifiers.</p>
<h3 id="the-multi-layer-perceptron-renaissance-1980s">The Multi-Layer Perceptron Renaissance (1980s)</h3>
<h4 id="backpropagation-algorithm">Backpropagation Algorithm</h4>
<p><strong>Papers</strong>: 
- <a href="https://www.nature.com/articles/323533a0">Learning Representations by Back-Propagating Errors</a> (Rumelhart, Hinton, Williams, 1986)
- <a href="https://web.stanford.edu/class/psych209a/ReadingsByDate/02_06/PDPVolIChapter8.pdf">Learning Internal Representations by Error Propagation</a> (Rumelhart &amp; McClelland, 1986)</p>
<p>The breakthrough that enabled training multi-layer networks by efficiently computing gradients:</p>
<p><strong>Forward Pass</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)}\)</span>\)</span>
<span class="arithmatex">\(<span class="arithmatex">\(a^{(l)} = \sigma(z^{(l)})\)</span>\)</span></p>
<p><strong>Backward Pass</strong> (Chain Rule):
<span class="arithmatex">\(<span class="arithmatex">\(\frac{\partial \mathcal{L}}{\partial W^{(l)}} = \frac{\partial \mathcal{L}}{\partial z^{(l)}} \frac{\partial z^{(l)}}{\partial W^{(l)}} = \delta^{(l)} (a^{(l-1)})^T\)</span>\)</span></p>
<div class="arithmatex">\[\delta^{(l)} = \frac{\partial \mathcal{L}}{\partial z^{(l)}} = (W^{(l+1)})^T \delta^{(l+1)} \odot \sigma'(z^{(l)})\]</div>
<p>Where:
- <span class="arithmatex">\(\mathcal{L}\)</span> is the loss function
- <span class="arithmatex">\(\sigma\)</span> is the activation function
- <span class="arithmatex">\(\odot\)</span> denotes element-wise multiplication
- <span class="arithmatex">\(\delta^{(l)}\)</span> is the error term for layer <span class="arithmatex">\(l\)</span></p>
<p><strong>Implementation Example</strong>:
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sigmoid_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MLP</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="c1"># Initialize weights randomly</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_size</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z2</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">a2</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Backward propagation</span>
        <span class="n">dz2</span> <span class="o">=</span> <span class="n">output</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">dW2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dz2</span><span class="p">)</span>
        <span class="n">db2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dz2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">da1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dz2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">dz1</span> <span class="o">=</span> <span class="n">da1</span> <span class="o">*</span> <span class="n">sigmoid_derivative</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a1</span><span class="p">)</span>
        <span class="n">dW1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dz1</span><span class="p">)</span>
        <span class="n">db1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dz1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dW1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dW2</span><span class="p">,</span> <span class="n">db2</span>
</code></pre></div></p>
<h3 id="the-second-ai-winter-1990s">The Second AI Winter (1990s)</h3>
<p>Despite the theoretical breakthrough of backpropagation, practical limitations emerged:</p>
<ol>
<li><strong>Vanishing Gradient Problem</strong>: Gradients become exponentially small in deep networks</li>
<li><strong>Limited Computational Resources</strong>: Training deep networks was computationally prohibitive</li>
<li><strong>Lack of Data</strong>: Insufficient large-scale datasets</li>
<li><strong>Competition from SVMs</strong>: Support Vector Machines often outperformed neural networks</li>
</ol>
<hr />
<h2 id="the-deep-learning-revolution">The Deep Learning Revolution</h2>
<h3 id="the-perfect-storm-2000s-2010s">The Perfect Storm (2000s-2010s)</h3>
<p>Several factors converged to enable the deep learning revolution:</p>
<ol>
<li><strong>Big Data</strong>: Internet-scale datasets became available</li>
<li><strong>GPU Computing</strong>: Parallel processing power for matrix operations</li>
<li><strong>Algorithmic Innovations</strong>: Better initialization, activation functions, and optimization</li>
<li><strong>Open Source Frameworks</strong>: TensorFlow, PyTorch, etc.</li>
</ol>
<h3 id="imagenet-and-the-visual-recognition-challenge">ImageNet and the Visual Recognition Challenge</h3>
<p><strong>Dataset</strong>: <a href="http://www.image-net.org/challenges/LSVRC/">ImageNet Large Scale Visual Recognition Challenge (ILSVRC)</a></p>
<p><strong>Paper</strong>: <a href="https://ieeexplore.ieee.org/document/5206848">ImageNet: A Large-Scale Hierarchical Image Database</a></p>
<p>ImageNet became the benchmark that catalyzed the deep learning revolution:</p>
<ul>
<li><strong>Scale</strong>: 14+ million images, 20,000+ categories</li>
<li><strong>Challenge</strong>: Annual competition from 2010-2017</li>
<li><strong>Impact</strong>: Drove innovation in computer vision architectures</li>
</ul>
<p><strong>ILSVRC Results Timeline</strong>:
| Year | Winner | Top-5 Error | Architecture |
|------|--------|-------------|-------------|
| 2010 | NEC | 28.2% | Traditional CV |
| 2011 | XRCE | 25.8% | Traditional CV |
| 2012 | <strong>AlexNet</strong> | <strong>16.4%</strong> | <strong>CNN</strong> |
| 2013 | Clarifai | 11.7% | CNN |
| 2014 | GoogLeNet | 6.7% | Inception |
| 2015 | <strong>ResNet</strong> | <strong>3.6%</strong> | <strong>Residual</strong> |
| 2016 | Trimps-Soushen | 2.99% | Ensemble |
| 2017 | SENet | 2.25% | Attention |</p>
<h2 id="convolutional-neural-networks">Convolutional Neural Networks</h2>
<h3 id="historical-context-and-evolution">Historical Context and Evolution</h3>
<p>Convolutional Neural Networks (CNNs) have their roots in biological vision research and early neural network architectures:</p>
<ul>
<li><strong>1959-1968</strong>: Hubel and Wiesel's groundbreaking work on cat visual cortex revealed hierarchical feature detection</li>
<li><strong>1980</strong>: Kunihiko Fukushima introduced the <strong>Neocognitron</strong>, the first CNN-like architecture with local receptive fields</li>
<li><strong>1989</strong>: Yann LeCun developed <strong>LeNet</strong>, demonstrating backpropagation training for CNNs</li>
<li><strong>1998</strong>: <strong>LeNet-5</strong> achieved commercial success in digit recognition for postal services</li>
<li><strong>2012</strong>: <strong>AlexNet</strong> revolutionized computer vision, marking the beginning of the deep learning era</li>
</ul>
<p><strong>Key Papers</strong>:
- <a href="https://link.springer.com/article/10.1007/BF00344251">Neocognitron (Fukushima, 1980)</a>
- <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">Gradient-based learning applied to document recognition (LeCun et al., 1998)</a>
- <a href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">ImageNet Classification with Deep CNNs (Krizhevsky et al., 2012)</a></p>
<h3 id="mathematical-foundation_1">Mathematical Foundation</h3>
<p>Convolutional Neural Networks are specifically designed for processing grid-like data such as images. They leverage three fundamental principles that make them exceptionally effective for visual tasks:</p>
<ol>
<li><strong>Local Connectivity</strong>: Each neuron connects only to a small, localized region of the input, mimicking the receptive fields in biological vision systems</li>
<li><strong>Parameter Sharing</strong>: The same set of weights (kernel/filter) is applied across all spatial locations, dramatically reducing the number of parameters</li>
<li><strong>Translation Invariance</strong>: Features can be detected regardless of their position in the input, enabling robust pattern recognition</li>
</ol>
<h4 id="convolution-operation-mathematical-deep-dive">Convolution Operation - Mathematical Deep Dive</h4>
<p>The <strong>mathematical convolution</strong> operation in continuous form:</p>
<div class="arithmatex">\[(f * g)(t) = \int_{-\infty}^{\infty} f(\tau) g(t - \tau) d\tau\]</div>
<p>For discrete 2D signals (images), the convolution becomes:</p>
<div class="arithmatex">\[(I * K)_{i,j} = \sum_{m} \sum_{n} I_{i-m,j-n} K_{m,n}\]</div>
<p><strong>Explanation</strong>: This equation computes the convolution at position <span class="arithmatex">\((i,j)\)</span> by:
- Taking the input image <span class="arithmatex">\(I\)</span> at position <span class="arithmatex">\((i-m, j-n)\)</span>
- Multiplying it with the kernel <span class="arithmatex">\(K\)</span> at position <span class="arithmatex">\((m,n)\)</span>
- Summing over all valid kernel positions
- The negative indices <span class="arithmatex">\((i-m, j-n)\)</span> implement the "flipping" characteristic of true convolution</p>
<p><strong>Cross-Correlation in Practice</strong>:</p>
<p>In deep learning, we typically use <strong>cross-correlation</strong> (often still called "convolution"):</p>
<div class="arithmatex">\[(I * K)_{i,j} = \sum_{m} \sum_{n} I_{i+m,j+n} K_{m,n}\]</div>
<p><strong>Explanation</strong>: This simplified operation:
- Uses positive indices <span class="arithmatex">\((i+m, j+n)\)</span>, avoiding kernel flipping
- Maintains the same computational benefits
- Is mathematically equivalent to convolution with a pre-flipped kernel
- Reduces implementation complexity while preserving learning capability</p>
<h4 id="multi-channel-convolution-complete-analysis">Multi-Channel Convolution - Complete Analysis</h4>
<p>For input with <span class="arithmatex">\(C\)</span> channels and <span class="arithmatex">\(F\)</span> filters, the complete convolution operation:</p>
<div class="arithmatex">\[Y_{i,j,f} = \sum_{c=1}^{C} \sum_{u=0}^{K-1} \sum_{v=0}^{K-1} X_{i+u,j+v,c} \cdot W_{u,v,c,f} + b_f\]</div>
<p><strong>Detailed Explanation</strong>:
- <span class="arithmatex">\(Y_{i,j,f}\)</span>: Output feature map <span class="arithmatex">\(f\)</span> at spatial position <span class="arithmatex">\((i,j)\)</span>
- <span class="arithmatex">\(X_{i+u,j+v,c}\)</span>: Input channel <span class="arithmatex">\(c\)</span> at position <span class="arithmatex">\((i+u, j+v)\)</span>
- <span class="arithmatex">\(W_{u,v,c,f}\)</span>: Weight connecting input channel <span class="arithmatex">\(c\)</span> to output filter <span class="arithmatex">\(f\)</span> at kernel position <span class="arithmatex">\((u,v)\)</span>
- <span class="arithmatex">\(b_f\)</span>: Bias term for filter <span class="arithmatex">\(f\)</span>
- The triple summation ensures each output pixel considers all input channels and all kernel positions</p>
<p><strong>Computational Complexity</strong>: <span class="arithmatex">\(O(H \cdot W \cdot C \cdot F \cdot K^2)\)</span> for each layer</p>
<h4 id="output-size-calculation-comprehensive-formula">Output Size Calculation - Comprehensive Formula</h4>
<p>Given input dimensions <span class="arithmatex">\((H_{in}, W_{in})\)</span>, kernel size <span class="arithmatex">\(K\)</span>, padding <span class="arithmatex">\(P\)</span>, stride <span class="arithmatex">\(S\)</span>, and dilation <span class="arithmatex">\(D\)</span>:</p>
<div class="arithmatex">\[H_{out} = \left\lfloor \frac{H_{in} + 2P - D(K-1) - 1}{S} \right\rfloor + 1$$
$$W_{out} = \left\lfloor \frac{W_{in} + 2P - D(K-1) - 1}{S} \right\rfloor + 1\]</div>
<p><strong>Parameter Explanation</strong>:
- <strong>Padding <span class="arithmatex">\(P\)</span></strong>: Adds <span class="arithmatex">\(P\)</span> pixels of zeros around input borders, preserving spatial dimensions
- <strong>Stride <span class="arithmatex">\(S\)</span></strong>: Step size for kernel movement; <span class="arithmatex">\(S&gt;1\)</span> reduces output size
- <strong>Dilation <span class="arithmatex">\(D\)</span></strong>: Spacing between kernel elements; <span class="arithmatex">\(D&gt;1\)</span> increases receptive field without additional parameters
- <strong>Floor operation <span class="arithmatex">\(\lfloor \cdot \rfloor\)</span></strong>: Ensures integer output dimensions</p>
<p><strong>Implementation Example</strong>:
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ConvolutionAnalysis</span><span class="p">:</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_output_size</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate CNN layer output size&quot;&quot;&quot;</span>
        <span class="n">h_in</span><span class="p">,</span> <span class="n">w_in</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="n">h_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">h_in</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">padding</span> <span class="o">-</span> <span class="n">dilation</span><span class="o">*</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">w_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">w_in</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">padding</span> <span class="o">-</span> <span class="n">dilation</span><span class="o">*</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">h_out</span><span class="p">,</span> <span class="n">w_out</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">receptive_field_size</span><span class="p">(</span><span class="n">layers_config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate receptive field size through multiple layers&quot;&quot;&quot;</span>
        <span class="n">rf</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">stride_product</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span> <span class="ow">in</span> <span class="n">layers_config</span><span class="p">:</span>
            <span class="n">rf</span> <span class="o">=</span> <span class="n">rf</span> <span class="o">+</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_product</span>
            <span class="n">stride_product</span> <span class="o">*=</span> <span class="n">stride</span>

        <span class="k">return</span> <span class="n">rf</span>

<span class="c1"># Example usage</span>
<span class="n">conv_analyzer</span> <span class="o">=</span> <span class="n">ConvolutionAnalysis</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output size: </span><span class="si">{</span><span class="n">conv_analyzer</span><span class="o">.</span><span class="n">calculate_output_size</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p">),</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Receptive field: </span><span class="si">{</span><span class="n">conv_analyzer</span><span class="o">.</span><span class="n">receptive_field_size</span><span class="p">([(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="w"> </span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="pooling-operations-dimensionality-reduction-and-translation-invariance">Pooling Operations - Dimensionality Reduction and Translation Invariance</h3>
<p>Pooling operations serve multiple critical purposes:
1. <strong>Dimensionality reduction</strong>: Reduces spatial dimensions and computational load
2. <strong>Translation invariance</strong>: Makes features robust to small spatial shifts
3. <strong>Hierarchical feature extraction</strong>: Enables learning of increasingly abstract features</p>
<h4 id="max-pooling-preserving-dominant-features">Max Pooling - Preserving Dominant Features</h4>
<div class="arithmatex">\[\text{MaxPool}(X)_{i,j} = \max_{u,v \in \text{pool region}} X_{i \cdot s + u, j \cdot s + v}\]</div>
<p><strong>Explanation</strong>: 
- Selects the maximum value within each pooling window
- <span class="arithmatex">\(s\)</span> is the stride (typically equals pool size for non-overlapping windows)
- Preserves the strongest activations, maintaining important features
- Provides translation invariance: small shifts in input don't change max values
- <strong>Biological motivation</strong>: Similar to complex cells in visual cortex that respond to the strongest stimulus</p>
<h4 id="average-pooling-smooth-feature-aggregation">Average Pooling - Smooth Feature Aggregation</h4>
<div class="arithmatex">\[\text{AvgPool}(X)_{i,j} = \frac{1}{K^2} \sum_{u,v \in \text{pool region}} X_{i \cdot s + u, j \cdot s + v}\]</div>
<p><strong>Explanation</strong>:
- Computes mean activation within each <span class="arithmatex">\(K \times K\)</span> pooling window
- <span class="arithmatex">\(K^2\)</span> normalizes the sum to maintain activation magnitude
- Provides smoother downsampling compared to max pooling
- Less prone to noise but may lose important sharp features
- <strong>Use case</strong>: Often preferred in the final layers before classification</p>
<h4 id="global-average-pooling-spatial-information-collapse">Global Average Pooling - Spatial Information Collapse</h4>
<div class="arithmatex">\[\text{GAP}(X)_c = \frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} X_{i,j,c}\]</div>
<p><strong>Explanation</strong>:
- Reduces each feature map to a single value by averaging all spatial locations
- <span class="arithmatex">\(H \times W\)</span> is the total number of spatial positions
- <strong>Advantages</strong>: Eliminates fully connected layers, reducing overfitting
- <strong>Introduced by</strong>: Network in Network (Lin et al., 2013)
- <strong>Modern usage</strong>: Standard in ResNet, DenseNet, and other architectures</p>
<p><strong>Advanced Pooling Variants</strong>:
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AdvancedPooling</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span> <span class="o">=</span> <span class="n">pool_size</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">adaptive_max_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adaptive max pooling - output size independent of input size&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">adaptive_max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">mixed_pooling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Combination of max and average pooling&quot;&quot;&quot;</span>
        <span class="n">max_pool</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">)</span>
        <span class="n">avg_pool</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">max_pool</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">avg_pool</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">stochastic_pooling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Stochastic pooling for regularization&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">)</span>

        <span class="c1"># Simplified stochastic pooling implementation</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">pooled_h</span><span class="p">,</span> <span class="n">pooled_w</span> <span class="o">=</span> <span class="n">height</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">,</span> <span class="n">width</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span>

        <span class="c1"># Reshape for pooling regions</span>
        <span class="n">x_reshaped</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">pooled_h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">,</span> <span class="n">pooled_w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="p">)</span>
        <span class="n">x_pooling_regions</span> <span class="o">=</span> <span class="n">x_reshaped</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">x_pooling_regions</span> <span class="o">=</span> <span class="n">x_pooling_regions</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">pooled_h</span><span class="p">,</span> <span class="n">pooled_w</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Stochastic selection based on probabilities</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x_pooling_regions</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool_size</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x_pooling_regions</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">indices</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">pooled_h</span><span class="p">,</span> <span class="n">pooled_w</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="activation-functions-nonlinearity-and-gradient-flow">Activation Functions - Nonlinearity and Gradient Flow</h3>
<p>Activation functions introduce nonlinearity, enabling neural networks to learn complex patterns. The choice of activation function significantly impacts training dynamics and model performance.</p>
<h4 id="relu-family-addressing-the-vanishing-gradient-problem">ReLU Family - Addressing the Vanishing Gradient Problem</h4>
<p><strong>ReLU (Rectified Linear Unit)</strong>: <span class="arithmatex">\(f(x) = \max(0, x)\)</span></p>
<p><strong>Mathematical Properties</strong>:
- <strong>Derivative</strong>: <span class="arithmatex">\(f'(x) = \begin{cases} 1 &amp; \text{if } x &gt; 0 \\ 0 &amp; \text{if } x \leq 0 \end{cases}\)</span>
- <strong>Advantages</strong>: Computationally efficient, mitigates vanishing gradients, sparse activation
- <strong>Disadvantages</strong>: "Dying ReLU" problem - neurons can become permanently inactive
- <strong>Introduced by</strong>: Nair &amp; Hinton (2010), popularized by AlexNet (2012)</p>
<p><strong>Leaky ReLU</strong>: <span class="arithmatex">\(f(x) = \begin{cases} x &amp; \text{if } x &gt; 0 \\ \alpha x &amp; \text{if } x \leq 0 \end{cases}\)</span></p>
<p><strong>Explanation</strong>: 
- Small slope <span class="arithmatex">\(\alpha\)</span> (typically 0.01) for negative inputs prevents "dying" neurons
- <strong>Derivative</strong>: <span class="arithmatex">\(f'(x) = \begin{cases} 1 &amp; \text{if } x &gt; 0 \\ \alpha &amp; \text{if } x \leq 0 \end{cases}\)</span>
- Maintains gradient flow even for negative inputs</p>
<p><strong>ELU (Exponential Linear Unit)</strong>: <span class="arithmatex">\(f(x) = \begin{cases} x &amp; \text{if } x &gt; 0 \\ \alpha(e^x - 1) &amp; \text{if } x \leq 0 \end{cases}\)</span></p>
<p><strong>Mathematical Analysis</strong>:
- <strong>Derivative</strong>: <span class="arithmatex">\(f'(x) = \begin{cases} 1 &amp; \text{if } x &gt; 0 \\ \alpha e^x &amp; \text{if } x \leq 0 \end{cases}\)</span>
- Smooth transition at zero, reducing noise in gradients
- Negative saturation helps with robust learning
- <strong>Paper</strong>: <a href="https://arxiv.org/abs/1511.07289">Fast and Accurate Deep Network Learning by ELUs (Clevert et al., 2015)</a></p>
<h4 id="modern-activation-functions">Modern Activation Functions</h4>
<p><strong>Swish/SiLU</strong>: <span class="arithmatex">\(f(x) = x \cdot \sigma(\beta x) = \frac{x}{1 + e^{-\beta x}}\)</span></p>
<p><strong>Mathematical Properties</strong>:
- <strong>Derivative</strong>: <span class="arithmatex">\(f'(x) = \sigma(\beta x) + x \cdot \sigma(\beta x) \cdot (1 - \sigma(\beta x)) \cdot \beta\)</span>
- Self-gated activation: input modulates its own activation
- Smooth, non-monotonic function
- <strong>Discovered by</strong>: Neural Architecture Search (Ramachandran et al., 2017)
- <strong>Paper</strong>: <a href="https://arxiv.org/abs/1710.05941">Searching for Activation Functions (Ramachandran et al., 2017)</a></p>
<p><strong>GELU (Gaussian Error Linear Unit)</strong>: <span class="arithmatex">\(f(x) = x \cdot \Phi(x) = x \cdot \frac{1}{2}[1 + \text{erf}(\frac{x}{\sqrt{2}})]\)</span></p>
<p><strong>Approximation</strong>: <span class="arithmatex">\(f(x) \approx 0.5x(1 + \tanh[\sqrt{\frac{2}{\pi}}(x + 0.044715x^3)])\)</span></p>
<p><strong>Explanation</strong>:
- Probabilistic interpretation: multiply input by probability it's greater than random normal variable
- Smooth approximation to ReLU with better gradient properties
- <strong>Standard in</strong>: BERT, GPT, and other transformer architectures
- <strong>Paper</strong>: <a href="https://arxiv.org/abs/1606.08415">Gaussian Error Linear Units (Hendrycks &amp; Gimpel, 2016)</a></p>
<p><strong>Comprehensive Implementation</strong>:
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AdvancedActivations</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Standard ReLU activation&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">leaky_relu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Leaky ReLU with configurable slope&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">elu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Exponential Linear Unit&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">swish</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Swish/SiLU activation&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">beta</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">gelu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">approximate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;GELU activation with optional approximation&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">approximate</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.044715</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">gelu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">mish</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Mish activation: x * tanh(softplus(x))&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">hardswish</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Hard Swish - efficient approximation of Swish&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">relu6</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="mi">6</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compare_activations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compare different activation functions&quot;&quot;&quot;</span>
        <span class="n">activations</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;ReLU&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="s1">&#39;Leaky ReLU&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="s1">&#39;ELU&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="s1">&#39;Swish&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">swish</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="s1">&#39;GELU&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">gelu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="s1">&#39;Mish&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">mish</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="s1">&#39;Hard Swish&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">hardswish</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">activations</span>

<span class="c1"># Activation function analysis</span>
<span class="n">activations</span> <span class="o">=</span> <span class="n">AdvancedActivations</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">activations</span><span class="o">.</span><span class="n">compare_activations</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Gradient analysis</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">x</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> - Mean gradient: </span><span class="si">{</span><span class="n">grad</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></p>
<h4 id="activation-function-selection-guidelines">Activation Function Selection Guidelines</h4>
<ol>
<li><strong>ReLU</strong>: Default choice for hidden layers, computationally efficient</li>
<li><strong>Leaky ReLU/ELU</strong>: When experiencing dying ReLU problems</li>
<li><strong>Swish/GELU</strong>: For transformer architectures and when computational cost is acceptable</li>
<li><strong>Tanh/Sigmoid</strong>: Output layers for specific ranges ([-1,1] or [0,1])</li>
<li><strong>Softmax</strong>: Multi-class classification output layers</li>
</ol>
<p><strong>Research Papers</strong>:
- <a href="http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf">Deep Sparse Rectifier Neural Networks (Glorot et al., 2011)</a>
- <a href="https://arxiv.org/abs/1505.00853">Empirical Evaluation of Rectified Activations (Xu et al., 2015)</a>
- <a href="https://arxiv.org/abs/2010.09458">Activation Functions: Comparison of trends in Practice and Research (Dubey et al., 2022)</a></p>
<h3 id="alexnet-the-deep-learning-revolution">AlexNet - The Deep Learning Revolution</h3>
<p>AlexNet, introduced by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton in 2012, marked a pivotal moment in computer vision and deep learning history. It achieved a dramatic improvement in ImageNet classification, reducing the top-5 error rate from 26.2% to 15.3%.</p>
<h4 id="historical-impact-and-context">Historical Impact and Context</h4>
<p><strong>Pre-AlexNet Era (2010-2012)</strong>:
- Traditional computer vision relied on hand-crafted features (SIFT, HOG, SURF)
- Shallow machine learning models (SVM, Random Forest) dominated
- ImageNet challenge winners used conventional approaches
- Deep networks were considered impractical due to computational limitations</p>
<p><strong>AlexNet's Revolutionary Impact</strong>:
- <strong>Computational breakthrough</strong>: Leveraged GPU acceleration (NVIDIA GTX 580)
- <strong>Scale demonstration</strong>: Proved deep networks could work with sufficient data and compute
- <strong>Industry transformation</strong>: Sparked the modern AI boom and deep learning adoption
- <strong>Research paradigm shift</strong>: From feature engineering to end-to-end learning</p>
<h4 id="architecture-analysis">Architecture Analysis</h4>
<p><strong>Network Structure</strong>:
<div class="highlight"><pre><span></span><code>Input: 224×224×3 RGB images
├── Conv1: 96 filters, 11×11, stride=4, ReLU → 55×55×96
├── MaxPool1: 3×3, stride=2 → 27×27×96
├── Conv2: 256 filters, 5×5, stride=1, ReLU → 27×27×256
├── MaxPool2: 3×3, stride=2 → 13×13×256
├── Conv3: 384 filters, 3×3, stride=1, ReLU → 13×13×384
├── Conv4: 384 filters, 3×3, stride=1, ReLU → 13×13×384
├── Conv5: 256 filters, 3×3, stride=1, ReLU → 13×13×256
├── MaxPool3: 3×3, stride=2 → 6×6×256
├── FC1: 4096 neurons, ReLU, Dropout(0.5)
├── FC2: 4096 neurons, ReLU, Dropout(0.5)
└── FC3: 1000 neurons (ImageNet classes), Softmax
</code></pre></div></p>
<p><strong>Mathematical Specifications</strong>:</p>
<p><strong>Total Parameters</strong>: ~60 million
- Convolutional layers: ~2.3M parameters
- Fully connected layers: ~58M parameters (96% of total)</p>
<p><strong>Memory Requirements</strong>:
- Forward pass: ~233MB for single image
- Training: ~1.2GB (including gradients and optimizer states)</p>
<p><strong>Computational Complexity</strong>:
- Forward pass: ~724 million multiply-accumulate operations
- Training time: ~6 days on two GTX 580 GPUs</p>
<h4 id="key-innovations-and-techniques">Key Innovations and Techniques</h4>
<p><strong>1. ReLU Activation Function</strong></p>
<p>AlexNet popularized ReLU over traditional sigmoid/tanh:</p>
<div class="arithmatex">\[f(x) = \max(0, x)\]</div>
<p><strong>Advantages demonstrated</strong>:
- <strong>Training speed</strong>: 6× faster convergence than tanh
- <strong>Gradient flow</strong>: Mitigates vanishing gradient problem
- <strong>Sparsity</strong>: Natural regularization through sparse activations</p>
<p><strong>2. Dropout Regularization</strong></p>
<p>Introduced by Hinton et al., applied in fully connected layers:</p>
<div class="arithmatex">\[y_i = \begin{cases} 
\frac{x_i}{p} &amp; \text{with probability } p \\
0 &amp; \text{with probability } 1-p
\end{cases}\]</div>
<p><strong>Mathematical Analysis</strong>:
- <strong>Training</strong>: Randomly sets neurons to zero with probability <span class="arithmatex">\(p=0.5\)</span>
- <strong>Inference</strong>: Scales activations by <span class="arithmatex">\(1/p\)</span> to maintain expected values
- <strong>Effect</strong>: Reduces overfitting by preventing co-adaptation of neurons</p>
<p><strong>3. Data Augmentation</strong></p>
<p>Systematic data augmentation to increase dataset size:
- <strong>Random crops</strong>: 224×224 patches from 256×256 images
- <strong>Horizontal flips</strong>: Double effective dataset size
- <strong>Color jittering</strong>: PCA-based color augmentation
- <strong>Test-time augmentation</strong>: Average predictions from multiple crops</p>
<p><strong>4. Local Response Normalization (LRN)</strong></p>
<div class="arithmatex">\[b_{x,y}^i = a_{x,y}^i / \left(k + \alpha \sum_{j=\max(0,i-n/2)}^{\min(N-1,i+n/2)} (a_{x,y}^j)^2\right)^\beta\]</div>
<p><strong>Parameters</strong>: <span class="arithmatex">\(k=2, n=5, \alpha=10^{-4}, \beta=0.75\)</span></p>
<p><strong>Explanation</strong>:
- Normalizes activations across feature maps at each spatial location
- Implements lateral inhibition similar to biological neurons
- <strong>Note</strong>: Later replaced by Batch Normalization in modern architectures</p>
<p><strong>5. GPU Parallelization</strong></p>
<p>Pioneered efficient GPU training for deep networks:
- <strong>Model parallelism</strong>: Split network across two GPUs
- <strong>Communication strategy</strong>: GPUs communicate only at specific layers
- <strong>Memory optimization</strong>: Careful management of GPU memory constraints</p>
<h4 id="implementation-and-training-details">Implementation and Training Details</h4>
<p><strong>Comprehensive PyTorch Implementation</strong>:
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Feature extraction layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="c1"># Conv1: Large receptive field to capture low-level features</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LocalResponseNorm</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>

            <span class="c1"># Conv2: Increase depth, reduce spatial dimensions</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LocalResponseNorm</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>

            <span class="c1"># Conv3-5: Deep feature extraction without pooling</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Adaptive pooling for flexible input sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

        <span class="c1"># Classification layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Initialize weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weights</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize weights following AlexNet paper&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AlexNetTrainer</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

        <span class="c1"># Original AlexNet training configuration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
            <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
            <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
            <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span>
        <span class="p">)</span>

        <span class="c1"># Learning rate scheduler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train for one epoch&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Batch </span><span class="si">{</span><span class="n">batch_idx</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, &#39;</span>
                      <span class="sa">f</span><span class="s1">&#39;Acc: </span><span class="si">{</span><span class="mf">100.</span><span class="o">*</span><span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">),</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">data_augmentation_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;AlexNet-style data augmentation&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>

        <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="n">brightness</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> 
                               <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
        <span class="p">])</span>

<span class="c1"># Usage example</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AlexNet</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">AlexNetTrainer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Model analysis</span>
<span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">trainable_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total parameters: </span><span class="si">{</span><span class="n">total_params</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trainable parameters: </span><span class="si">{</span><span class="n">trainable_params</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Receptive field calculation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">calculate_alexnet_receptive_field</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate theoretical receptive field of AlexNet&quot;&quot;&quot;</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>  <span class="c1"># Conv1: kernel=11, stride=4, padding=2</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>   <span class="c1"># MaxPool1: kernel=3, stride=2</span>
        <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>   <span class="c1"># Conv2: kernel=5, stride=1, padding=2</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>   <span class="c1"># MaxPool2: kernel=3, stride=2</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>   <span class="c1"># Conv3: kernel=3, stride=1, padding=1</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>   <span class="c1"># Conv4: kernel=3, stride=1, padding=1</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>   <span class="c1"># Conv5: kernel=3, stride=1, padding=1</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>   <span class="c1"># MaxPool3: kernel=3, stride=2</span>
    <span class="p">]</span>

    <span class="n">rf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">stride_product</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">for</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
        <span class="n">rf</span> <span class="o">=</span> <span class="n">rf</span> <span class="o">+</span> <span class="p">(</span><span class="n">kernel</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_product</span>
        <span class="n">stride_product</span> <span class="o">*=</span> <span class="n">stride</span>

    <span class="k">return</span> <span class="n">rf</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AlexNet receptive field: </span><span class="si">{</span><span class="n">calculate_alexnet_receptive_field</span><span class="p">()</span><span class="si">}</span><span class="s2"> pixels&quot;</span><span class="p">)</span>
</code></pre></div></p>
<h4 id="legacy-and-modern-relevance">Legacy and Modern Relevance</h4>
<p><strong>Immediate Impact (2012-2015)</strong>:
- <strong>ImageNet dominance</strong>: Sparked the "CNN revolution" in computer vision
- <strong>Industry adoption</strong>: Major tech companies invested heavily in deep learning
- <strong>Research explosion</strong>: Exponential growth in CNN architecture research
- <strong>Hardware development</strong>: Accelerated GPU development for AI workloads</p>
<p><strong>Architectural Influence</strong>:
- <strong>VGGNet (2014)</strong>: Deeper networks with smaller filters
- <strong>GoogLeNet (2014)</strong>: Inception modules and efficient architectures
- <strong>ResNet (2015)</strong>: Skip connections enabling ultra-deep networks
- <strong>Modern CNNs</strong>: EfficientNet, RegNet, ConvNeXt build on AlexNet principles</p>
<p><strong>Lessons and Limitations</strong>:</p>
<p><strong>Key Insights</strong>:
1. <strong>Scale matters</strong>: Large datasets and models enable breakthrough performance
2. <strong>GPU acceleration</strong>: Computational power unlocks deep learning potential
3. <strong>End-to-end learning</strong>: Feature learning outperforms hand-crafted features
4. <strong>Regularization importance</strong>: Dropout and data augmentation prevent overfitting</p>
<p><strong>Modern Perspective</strong>:
- <strong>Architectural inefficiency</strong>: Too many parameters in fully connected layers
- <strong>Limited depth</strong>: Modern networks are much deeper (100+ layers)
- <strong>Normalization</strong>: Batch normalization replaced Local Response Normalization
- <strong>Attention mechanisms</strong>: Transformers now dominate many vision tasks</p>
<p><strong>Research Papers and Resources</strong>:
- <strong>Original Paper</strong>: <a href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">ImageNet Classification with Deep Convolutional Neural Networks (Krizhevsky et al., 2012)</a>
- <strong>Implementation</strong>: <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/alexnet.py">Official PyTorch AlexNet</a>
- <strong>Historical Analysis</strong>: <a href="https://arxiv.org/abs/1404.7828">The History of Deep Learning (Schmidhuber, 2015)</a>
- <strong>GPU Computing</strong>: <a href="https://ai.stanford.edu/~ang/papers/icml09-LargeScaleUnsupervisedDeepLearningGPU.pdf">Large-scale Deep Unsupervised Learning using Graphics Processors (Raina et al., 2009)</a></p>
<p><strong>Modern Alternatives and Evolution</strong>:
<div class="highlight"><pre><span></span><code><span class="c1"># Modern efficient alternatives to AlexNet</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">efficientnet_b0</span><span class="p">,</span> <span class="n">resnet50</span><span class="p">,</span> <span class="n">convnext_tiny</span>

<span class="c1"># EfficientNet: Better accuracy with fewer parameters</span>
<span class="n">efficient_model</span> <span class="o">=</span> <span class="n">efficientnet_b0</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;EfficientNet-B0 parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">efficient_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># ResNet: Skip connections enable deeper networks</span>
<span class="n">resnet_model</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ResNet-50 parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">resnet_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># ConvNeXt: Modern CNN design</span>
<span class="n">convnext_model</span> <span class="o">=</span> <span class="n">convnext_tiny</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ConvNeXt-Tiny parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">convnext_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></p>
<p>AlexNet's revolutionary impact cannot be overstated—it single-handedly launched the modern deep learning era and demonstrated that neural networks could achieve superhuman performance on complex visual tasks. While modern architectures have surpassed its performance and efficiency, AlexNet remains a foundational milestone in the history of artificial intelligence.</p>
<hr />
<h2 id="major-cnn-architectures">Major CNN Architectures</h2>
<h3 id="vggnet-depth-matters-2014">VGGNet: Depth Matters (2014)</h3>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p>
<p><strong>Authors</strong>: Karen Simonyan, Andrew Zisserman (Oxford)</p>
<p><strong>Code</strong>: <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py">VGG Implementation</a></p>
<h4 id="key-innovations">Key Innovations</h4>
<ol>
<li><strong>Uniform Architecture</strong>: Only 3×3 convolutions and 2×2 max pooling</li>
<li><strong>Increased Depth</strong>: Up to 19 layers (VGG-19)</li>
<li><strong>Small Filters</strong>: 3×3 filters throughout the network</li>
</ol>
<h4 id="why-33-filters">Why 3×3 Filters?</h4>
<p>Two 3×3 convolutions have the same receptive field as one 5×5 convolution but with:
- <strong>Fewer parameters</strong>: <span class="arithmatex">\(2 \times (3^2 \times C^2) = 18C^2\)</span> vs. <span class="arithmatex">\(5^2 \times C^2 = 25C^2\)</span>
- <strong>More non-linearity</strong>: Two ReLU activations instead of one
- <strong>Better feature learning</strong>: More complex decision boundaries</p>
<h4 id="vgg-16-architecture">VGG-16 Architecture</h4>
<div class="highlight"><pre><span></span><code>Input: 224×224×3

Block 1:
Conv3-64, Conv3-64, MaxPool → 112×112×64

Block 2:
Conv3-128, Conv3-128, MaxPool → 56×56×128

Block 3:
Conv3-256, Conv3-256, Conv3-256, MaxPool → 28×28×256

Block 4:
Conv3-512, Conv3-512, Conv3-512, MaxPool → 14×14×512

Block 5:
Conv3-512, Conv3-512, Conv3-512, MaxPool → 7×7×512

Classifier:
FC-4096, FC-4096, FC-1000
</code></pre></div>
<p><strong>PyTorch Implementation</strong>:
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VGG16</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VGG16</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="c1"># Block 1</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>

            <span class="c1"># Block 2</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>

            <span class="c1"># Block 3</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>

            <span class="c1"># Block 4</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>

            <span class="c1"># Block 5</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></p>
<h3 id="resnet-the-residual-revolution-2015">ResNet: The Residual Revolution (2015)</h3>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></p>
<p><strong>Authors</strong>: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun (Microsoft Research)</p>
<p><strong>Code</strong>: <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py">ResNet Implementation</a></p>
<h4 id="the-degradation-problem">The Degradation Problem</h4>
<p>As networks get deeper, accuracy saturates and then degrades rapidly. This is <strong>not</strong> due to overfitting but rather optimization difficulty.</p>
<p><strong>Observation</strong>: A deeper network should perform at least as well as its shallower counterpart by learning identity mappings in the extra layers.</p>
<h4 id="residual-learning">Residual Learning</h4>
<p>Instead of learning the desired mapping <span class="arithmatex">\(\mathcal{H}(x)\)</span>, learn the residual:</p>
<div class="arithmatex">\[\mathcal{F}(x) = \mathcal{H}(x) - x\]</div>
<p>Then the original mapping becomes:</p>
<div class="arithmatex">\[\mathcal{H}(x) = \mathcal{F}(x) + x\]</div>
<p><strong>Hypothesis</strong>: It's easier to optimize <span class="arithmatex">\(\mathcal{F}(x) = 0\)</span> (identity) than to learn <span class="arithmatex">\(\mathcal{H}(x) = x\)</span> directly.</p>
<h4 id="residual-block-architecture">Residual Block Architecture</h4>
<p><strong>Basic Block</strong> (for ResNet-18, ResNet-34):
<div class="highlight"><pre><span></span><code>x → Conv3×3 → BN → ReLU → Conv3×3 → BN → (+) → ReLU
↓                                           ↑
└─────────────── identity ──────────────────┘
</code></pre></div></p>
<p><strong>Bottleneck Block</strong> (for ResNet-50, ResNet-101, ResNet-152):
<div class="highlight"><pre><span></span><code>x → Conv1×1 → BN → ReLU → Conv3×3 → BN → ReLU → Conv1×1 → BN → (+) → ReLU
↓                                                                ↑
└─────────────────────── identity ───────────────────────────────┘
</code></pre></div></p>
<h4 id="bottleneck-architecture-deep-dive">Bottleneck Architecture Deep Dive</h4>
<p><strong>Wide-Narrow-Wide Design Pattern</strong>:</p>
<p>The bottleneck block follows a sophisticated <strong>wide-narrow-wide</strong> computational pattern that revolutionized deep network efficiency:</p>
<ol>
<li><strong>Dimension Reduction (Wide → Narrow)</strong>: </li>
<li>First 1×1 convolution reduces channel dimensions by 4×</li>
<li>Example: 1024 → 256 channels</li>
<li>
<p><strong>Purpose</strong>: Reduce computational cost of expensive 3×3 convolutions</p>
</li>
<li>
<p><strong>Spatial Processing (Narrow)</strong>:</p>
</li>
<li>3×3 convolution operates on reduced feature maps</li>
<li><strong>Computational savings</strong>: ~16× fewer operations than full-width 3×3</li>
<li>
<p>Maintains spatial feature extraction capability</p>
</li>
<li>
<p><strong>Dimension Expansion (Narrow → Wide)</strong>:</p>
</li>
<li>Final 1×1 convolution restores original dimensions</li>
<li>Example: 256 → 1024 channels</li>
<li><strong>Purpose</strong>: Match residual connection dimensions</li>
</ol>
<p><strong>Mathematical Analysis of Computational Efficiency</strong>:</p>
<p>For input dimensions <span class="arithmatex">\(H \times W \times C\)</span> with <span class="arithmatex">\(C = 1024\)</span>:</p>
<p><strong>Standard 3×3 Convolution</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\text{FLOPs} = H \times W \times C \times C \times 9 = 9HWC^2\)</span>\)</span></p>
<p><strong>Bottleneck Design</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\text{FLOPs} = HW(C \times \frac{C}{4} + \frac{C}{4} \times \frac{C}{4} \times 9 + \frac{C}{4} \times C) = HWC^2(1 + \frac{9}{16} + 1) = 2.56HWC^2\)</span>\)</span></p>
<p><strong>Efficiency Gain</strong>: <span class="arithmatex">\(\frac{9HWC^2}{2.56HWC^2} \approx 3.5×\)</span> reduction in computational cost</p>
<h4 id="batch-normalization-integration">Batch Normalization Integration</h4>
<p><strong>Strategic Placement</strong>:
ResNet pioneered the <strong>Conv → BN → ReLU</strong> ordering, which became the standard:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># ResNet&#39;s BN placement</span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>      <span class="c1"># 1×1 conv</span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>      <span class="c1"># Batch normalization</span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>     <span class="c1"># Activation</span>

<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>    <span class="c1"># 3×3 conv  </span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>      <span class="c1"># Batch normalization</span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>     <span class="c1"># Activation</span>

<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>    <span class="c1"># 1×1 conv</span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>      <span class="c1"># Batch normalization</span>
<span class="c1"># No activation before residual addition</span>

<span class="n">out</span> <span class="o">+=</span> <span class="n">identity</span>          <span class="c1"># Residual connection</span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>     <span class="c1"># Final activation</span>
</code></pre></div>
<p><strong>Key Design Decisions</strong>:</p>
<ol>
<li><strong>No BN on Identity Path</strong>: The skip connection remains unmodified</li>
<li><strong>Pre-activation vs Post-activation</strong>: Original ResNet uses post-activation</li>
<li><strong>Final Layer</strong>: No ReLU before residual addition to preserve gradient flow</li>
</ol>
<p><strong>Batch Normalization Benefits in ResNet</strong>:
- <strong>Internal Covariate Shift Reduction</strong>: Stabilizes layer inputs during training
- <strong>Higher Learning Rates</strong>: Enables faster convergence
- <strong>Regularization Effect</strong>: Reduces overfitting through noise injection
- <strong>Gradient Flow</strong>: Maintains healthy gradients in very deep networks</p>
<p><strong>Mathematical Formulation</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\text{BN}(x) = \gamma \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} + \beta\)</span>\)</span></p>
<p>Where:
- <span class="arithmatex">\(\mu_B, \sigma_B^2\)</span>: Batch mean and variance
- <span class="arithmatex">\(\gamma, \beta\)</span>: Learnable scale and shift parameters
- <span class="arithmatex">\(\epsilon\)</span>: Small constant for numerical stability</p>
<h4 id="evolution-of-bottleneck-architectures">Evolution of Bottleneck Architectures</h4>
<p><strong>1. Pre-activation ResNet (2016)</strong></p>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1603.05027">Identity Mappings in Deep Residual Networks</a></p>
<p><strong>Key Innovation</strong>: <strong>BN → ReLU → Conv</strong> ordering</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Pre-activation bottleneck</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>        <span class="c1"># BN first</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>     <span class="c1"># Then ReLU</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>    <span class="c1"># Then conv</span>

    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span> <span class="o">+</span> <span class="n">identity</span>    <span class="c1"># Clean residual addition</span>
</code></pre></div>
<p><strong>Advantages</strong>:
- <strong>Cleaner gradient flow</strong>: Identity mapping is truly unmodified
- <strong>Better convergence</strong>: Especially for very deep networks (1000+ layers)
- <strong>Simplified design</strong>: Consistent BN-ReLU-Conv pattern</p>
<p><strong>2. ResNeXt: Cardinality over Depth (2017)</strong></p>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1611.05431">Aggregated Residual Transformations for Deep Neural Networks</a></p>
<p><strong>Innovation</strong>: <strong>Split-Transform-Merge</strong> strategy with grouped convolutions</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ResNeXtBottleneck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">cardinality</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">D</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="p">(</span><span class="mi">64</span> <span class="o">/</span> <span class="mi">64</span><span class="p">))</span>  <span class="c1"># Base width</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">D</span><span class="o">*</span><span class="n">cardinality</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">D</span><span class="o">*</span><span class="n">cardinality</span><span class="p">)</span>

        <span class="c1"># Grouped convolution - key innovation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">D</span><span class="o">*</span><span class="n">cardinality</span><span class="p">,</span> <span class="n">D</span><span class="o">*</span><span class="n">cardinality</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> 
                              <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                              <span class="n">groups</span><span class="o">=</span><span class="n">cardinality</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">D</span><span class="o">*</span><span class="n">cardinality</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">D</span><span class="o">*</span><span class="n">cardinality</span><span class="p">,</span> <span class="n">planes</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>
<p><strong>Mathematical Insight</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\mathcal{F}(x) = \sum_{i=1}^{C} \mathcal{T}_i(x)\)</span>\)</span></p>
<p>Where <span class="arithmatex">\(C\)</span> is cardinality and <span class="arithmatex">\(\mathcal{T}_i\)</span> is the <span class="arithmatex">\(i\)</span>-th transformation.</p>
<p><strong>3. SE-ResNet: Squeeze-and-Excitation (2018)</strong></p>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1709.01507">Squeeze-and-Excitation Networks</a></p>
<p><strong>Innovation</strong>: <strong>Channel attention mechanism</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">SEBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">squeeze</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">excitation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span> <span class="o">//</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channels</span> <span class="o">//</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>  <span class="c1"># Global average pooling</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">excitation</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Channel weights</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Channel-wise scaling</span>
</code></pre></div>
<p><strong>4. ECA-Net: Efficient Channel Attention (2020)</strong></p>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1910.03151">ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks</a></p>
<p><strong>Innovation</strong>: <strong>Parameter-efficient attention</strong> using 1D convolution</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ECABlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">kernel_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">abs</span><span class="p">((</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">))</span>
        <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span> <span class="k">if</span> <span class="n">kernel_size</span> <span class="o">%</span> <span class="mi">2</span> <span class="k">else</span> <span class="n">kernel_size</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">avg_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
                             <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p><strong>5. ResNeSt: Split-Attention Networks (2020)</strong></p>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/2004.08955">ResNeSt: Split-Attention Networks</a></p>
<p><strong>Innovation</strong>: <strong>Multi-path attention</strong> combining ResNeXt and SE mechanisms</p>
<p><strong>Architecture Evolution Summary</strong>:</p>
<table>
<thead>
<tr>
<th>Architecture</th>
<th>Year</th>
<th>Key Innovation</th>
<th>Parameters</th>
<th>ImageNet Top-1</th>
</tr>
</thead>
<tbody>
<tr>
<td>ResNet-50</td>
<td>2015</td>
<td>Residual connections</td>
<td>25.6M</td>
<td>76.0%</td>
</tr>
<tr>
<td>Pre-ResNet-50</td>
<td>2016</td>
<td>Pre-activation</td>
<td>25.6M</td>
<td>76.4%</td>
</tr>
<tr>
<td>ResNeXt-50</td>
<td>2017</td>
<td>Grouped convolutions</td>
<td>25.0M</td>
<td>77.8%</td>
</tr>
<tr>
<td>SE-ResNet-50</td>
<td>2018</td>
<td>Channel attention</td>
<td>28.1M</td>
<td>77.6%</td>
</tr>
<tr>
<td>ECA-ResNet-50</td>
<td>2020</td>
<td>Efficient attention</td>
<td>25.6M</td>
<td>77.9%</td>
</tr>
<tr>
<td>ResNeSt-50</td>
<td>2020</td>
<td>Split-attention</td>
<td>27.5M</td>
<td>81.1%</td>
</tr>
</tbody>
</table>
<p><strong>Modern Bottleneck Design Principles</strong>:</p>
<ol>
<li><strong>Efficiency</strong>: Maintain computational efficiency through dimension reduction</li>
<li><strong>Attention</strong>: Incorporate channel or spatial attention mechanisms</li>
<li><strong>Multi-path</strong>: Use multiple transformation paths for richer representations</li>
<li><strong>Normalization</strong>: Strategic placement of normalization layers</li>
<li><strong>Activation</strong>: Careful activation function placement for gradient flow</li>
</ol>
<h4 id="mathematical-formulation">Mathematical Formulation</h4>
<p>For a residual block:
<span class="arithmatex">\(<span class="arithmatex">\(y_l = h(x_l) + \mathcal{F}(x_l, W_l)\)</span>\)</span>
<span class="arithmatex">\(<span class="arithmatex">\(x_{l+1} = f(y_l)\)</span>\)</span></p>
<p>Where:
- <span class="arithmatex">\(x_l\)</span> is input to the <span class="arithmatex">\(l\)</span>-th block
- <span class="arithmatex">\(\mathcal{F}\)</span> is the residual function
- <span class="arithmatex">\(h(x_l) = x_l\)</span> is identity mapping
- <span class="arithmatex">\(f\)</span> is ReLU activation</p>
<p>For the entire network:
<span class="arithmatex">\(<span class="arithmatex">\(x_L = x_l + \sum_{i=l}^{L-1} \mathcal{F}(x_i, W_i)\)</span>\)</span></p>
<h4 id="gradient-flow-analysis">Gradient Flow Analysis</h4>
<p>The gradient of the loss with respect to <span class="arithmatex">\(x_l\)</span>:</p>
<div class="arithmatex">\[\frac{\partial \mathcal{L}}{\partial x_l} = \frac{\partial \mathcal{L}}{\partial x_L} \frac{\partial x_L}{\partial x_l} = \frac{\partial \mathcal{L}}{\partial x_L} \left(1 + \frac{\partial}{\partial x_l} \sum_{i=l}^{L-1} \mathcal{F}(x_i, W_i)\right)\]</div>
<p>The key insight: The gradient has two terms:
1. <span class="arithmatex">\(\frac{\partial \mathcal{L}}{\partial x_L}\)</span> - direct path (never vanishes)
2. <span class="arithmatex">\(\frac{\partial \mathcal{L}}{\partial x_L} \frac{\partial}{\partial x_l} \sum_{i=l}^{L-1} \mathcal{F}(x_i, W_i)\)</span> - residual path</p>
<p>This ensures that gradients can flow directly to earlier layers.</p>
<h4 id="resnet-50-architecture">ResNet-50 Architecture</h4>
<div class="highlight"><pre><span></span><code>Input: 224×224×3

Conv1: 7×7, 64, stride 2 → 112×112×64
MaxPool: 3×3, stride 2 → 56×56×64

Conv2_x: [1×1,64; 3×3,64; 1×1,256] × 3 → 56×56×256
Conv3_x: [1×1,128; 3×3,128; 1×1,512] × 4 → 28×28×512
Conv4_x: [1×1,256; 3×3,256; 1×1,1024] × 6 → 14×14×1024
Conv5_x: [1×1,512; 3×3,512; 1×1,2048] × 3 → 7×7×2048

GlobalAvgPool → 1×1×2048
FC: 1000
</code></pre></div>
<p><strong>PyTorch Implementation</strong>:
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">BasicBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BasicBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">+=</span> <span class="n">identity</span>  <span class="c1"># Residual connection</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Bottleneck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Bottleneck</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">planes</span><span class="p">,</span> <span class="n">planes</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">+=</span> <span class="n">identity</span>  <span class="c1"># Residual connection</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></p>
<h4 id="impact-and-variants">Impact and Variants</h4>
<p><strong>ResNet Variants</strong>:
- <strong>ResNeXt</strong>: <a href="https://arxiv.org/abs/1611.05431">Aggregated Residual Transformations for Deep Neural Networks</a>
- <strong>Wide ResNet</strong>: <a href="https://arxiv.org/abs/1605.07146">Wide Residual Networks</a>
- <strong>DenseNet</strong>: <a href="https://arxiv.org/abs/1608.06993">Densely Connected Convolutional Networks</a>
- <strong>ResNeSt</strong>: <a href="https://arxiv.org/abs/2004.08955">ResNeSt: Split-Attention Networks</a></p>
<h3 id="googlenetinception-efficient-architecture-design-2014">GoogLeNet/Inception: Efficient Architecture Design (2014)</h3>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1409.4842">Going Deeper with Convolutions</a></p>
<p><strong>Authors</strong>: Christian Szegedy et al. (Google)</p>
<h4 id="inception-module">Inception Module</h4>
<p>The key idea: Use multiple filter sizes in parallel and let the network decide which to use.</p>
<div class="highlight"><pre><span></span><code>Input
├── 1×1 conv
├── 1×1 conv → 3×3 conv
├── 1×1 conv → 5×5 conv
└── 3×3 maxpool → 1×1 conv
        ↓
    Concatenate
</code></pre></div>
<p><strong>Dimensionality Reduction</strong>: 1×1 convolutions reduce computational cost:
- Without 1×1: <span class="arithmatex">\(5 \times 5 \times 192 \times 32 = 153,600\)</span> operations
- With 1×1: <span class="arithmatex">\(1 \times 1 \times 192 \times 16 + 5 \times 5 \times 16 \times 32 = 15,872\)</span> operations</p>
<h4 id="auxiliary-classifiers">Auxiliary Classifiers</h4>
<p>To combat vanishing gradients, GoogLeNet uses auxiliary classifiers at intermediate layers:</p>
<div class="arithmatex">\[\mathcal{L}_{total} = \mathcal{L}_{main} + 0.3 \times \mathcal{L}_{aux1} + 0.3 \times \mathcal{L}_{aux2}\]</div>
<hr />
<h3 id="advanced-cnn-architectures-post-googlenet-era">Advanced CNN Architectures: Post-GoogLeNet Era</h3>
<h4 id="mobilenet-v1-efficient-mobile-vision-2017">MobileNet v1: Efficient Mobile Vision (2017)</h4>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1704.04861">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></p>
<p><strong>Authors</strong>: Andrew G. Howard et al. (Google)</p>
<p><strong>Code</strong>: <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv1.py">MobileNet Implementation</a></p>
<p><strong>Key Innovation</strong>: <strong>Depthwise Separable Convolutions</strong></p>
<p>Standard convolution is factorized into:
1. <strong>Depthwise Convolution</strong>: Applies a single filter per input channel
2. <strong>Pointwise Convolution</strong>: 1×1 convolution to combine outputs</p>
<p><strong>Computational Efficiency</strong>:
- Standard conv: <span class="arithmatex">\(D_K \times D_K \times M \times N \times D_F \times D_F\)</span>
- Depthwise separable: <span class="arithmatex">\(D_K \times D_K \times M \times D_F \times D_F + M \times N \times D_F \times D_F\)</span>
- <strong>Reduction factor</strong>: <span class="arithmatex">\(\frac{1}{N} + \frac{1}{D_K^2}\)</span> (typically 8-9× fewer operations)</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">DepthwiseSeparableConv</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Depthwise convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">depthwise</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> 
                                  <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                  <span class="n">groups</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">)</span>

        <span class="c1"># Pointwise convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pointwise</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">depthwise</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pointwise</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<h4 id="mobilenet-v2-inverted-residuals-and-linear-bottlenecks-2018">MobileNet v2: Inverted Residuals and Linear Bottlenecks (2018)</h4>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1801.04381">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></p>
<p><strong>Authors</strong>: Mark Sandler et al. (Google)</p>
<p><strong>Code</strong>: <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py">MobileNetV2 Implementation</a></p>
<p><strong>Key Innovations</strong>:
1. <strong>Inverted Residual Block</strong>: Expand → Depthwise → Project
2. <strong>Linear Bottlenecks</strong>: Remove ReLU from final layer to preserve information</p>
<p><strong>Inverted Residual Structure</strong>:
<div class="highlight"><pre><span></span><code>Input (low-dim) → Expand (high-dim) → Depthwise → Project (low-dim) → Output
</code></pre></div></p>
<p><strong>Mathematical Insight</strong>: ReLU destroys information in low-dimensional spaces but preserves it in high-dimensional spaces.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">InvertedResidual</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">oup</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">expand_ratio</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">inp</span> <span class="o">*</span> <span class="n">expand_ratio</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_res_connect</span> <span class="o">=</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">inp</span> <span class="o">==</span> <span class="n">oup</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">expand_ratio</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Expansion</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">])</span>

        <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
            <span class="c1"># Depthwise</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> 
                     <span class="n">groups</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="c1"># Pointwise (linear)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">oup</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">oup</span><span class="p">),</span>
        <span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_res_connect</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<h4 id="resnext-aggregated-residual-transformations-2017">ResNeXt: Aggregated Residual Transformations (2017)</h4>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1611.05431">Aggregated Residual Transformations for Deep Neural Networks</a></p>
<p><strong>Authors</strong>: Saining Xie et al. (UC San Diego, Facebook AI Research)</p>
<p><strong>Code</strong>: <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py">ResNeXt Implementation</a></p>
<p><strong>Key Innovation</strong>: <strong>Cardinality</strong> as a new dimension beyond depth and width</p>
<p><strong>Design Philosophy</strong>: "Split-Transform-Merge" strategy
- <strong>Split</strong>: Input into multiple paths
- <strong>Transform</strong>: Apply same topology to each path
- <strong>Merge</strong>: Aggregate transformations</p>
<p><strong>Mathematical Formulation</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\mathcal{F}(x) = \sum_{i=1}^{C} \mathcal{T}_i(x)\)</span>\)</span></p>
<p>Where <span class="arithmatex">\(C\)</span> is cardinality and <span class="arithmatex">\(\mathcal{T}_i\)</span> represents the <span class="arithmatex">\(i\)</span>-th transformation.</p>
<p><strong>Grouped Convolution Implementation</strong>:
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ResNeXtBottleneck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">cardinality</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">base_width</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="p">(</span><span class="n">base_width</span> <span class="o">/</span> <span class="mf">64.</span><span class="p">))</span> <span class="o">*</span> <span class="n">cardinality</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>

        <span class="c1"># Grouped convolution - key innovation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> 
                              <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">cardinality</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">planes</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></p>
<h4 id="efficientnet-compound-scaling-2019">EfficientNet: Compound Scaling (2019)</h4>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1905.11946">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></p>
<p><strong>Authors</strong>: Mingxing Tan, Quoc V. Le (Google Brain)</p>
<p><strong>Code</strong>: <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py">EfficientNet Implementation</a></p>
<p><strong>Key Innovation</strong>: <strong>Compound Scaling Method</strong></p>
<p>Instead of scaling depth, width, or resolution independently, EfficientNet scales all three dimensions:</p>
<div class="arithmatex">\[\text{depth: } d = \alpha^\phi$$
$$\text{width: } w = \beta^\phi$$  
$$\text{resolution: } r = \gamma^\phi\]</div>
<p><strong>Constraint</strong>: <span class="arithmatex">\(\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2\)</span> (to maintain FLOP budget)</p>
<p><strong>Mobile Inverted Bottleneck (MBConv) Block</strong>:
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MBConvBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">oup</span><span class="p">,</span> <span class="n">expand_ratio</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">se_ratio</span><span class="o">=</span><span class="mf">0.25</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">inp</span> <span class="o">*</span> <span class="n">expand_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_res_connect</span> <span class="o">=</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">inp</span> <span class="o">==</span> <span class="n">oup</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">expand_ratio</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Expansion</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">])</span>

        <span class="c1"># Depthwise</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> 
                     <span class="n">kernel_size</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="c1"># Squeeze-and-Excitation</span>
        <span class="k">if</span> <span class="n">se_ratio</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SEBlock</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">inp</span> <span class="o">*</span> <span class="n">se_ratio</span><span class="p">)))</span>

        <span class="c1"># Pointwise</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">oup</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">oup</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_res_connect</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></p>
<h4 id="regnet-designing-network-design-spaces-2020">RegNet: Designing Network Design Spaces (2020)</h4>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/2003.13678">Designing Network Design Spaces</a></p>
<p><strong>Authors</strong>: Ilija Radosavovic et al. (Facebook AI Research)</p>
<p><strong>Code</strong>: <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/regnet.py">RegNet Implementation</a></p>
<p><strong>Key Innovation</strong>: <strong>Systematic Design Space Exploration</strong></p>
<p>RegNet discovers design principles through systematic exploration:
1. <strong>Good networks have simple structure</strong>
2. <strong>Width and depth should increase together</strong>
3. <strong>Bottleneck ratio should be around 1.0</strong>
4. <strong>Group width should be 8-16</strong></p>
<p><strong>RegNet Design Rules</strong>:
- Width increases in quantized steps: <span class="arithmatex">\(w_{j+1} = w_j \cdot q\)</span> where <span class="arithmatex">\(q &gt; 1\)</span>
- Depth is determined by width multiplier
- Group convolutions with fixed group width</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">RegNetBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w_in</span><span class="p">,</span> <span class="n">w_out</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">group_width</span><span class="p">,</span> <span class="n">bottleneck_ratio</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">w_b</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">w_out</span> <span class="o">*</span> <span class="n">bottleneck_ratio</span><span class="p">))</span>
        <span class="n">num_groups</span> <span class="o">=</span> <span class="n">w_b</span> <span class="o">//</span> <span class="n">group_width</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">w_in</span> <span class="o">!=</span> <span class="n">w_out</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">w_in</span><span class="p">,</span> <span class="n">w_out</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">w_out</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">w_in</span><span class="p">,</span> <span class="n">w_b</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">w_b</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">w_b</span><span class="p">,</span> <span class="n">w_b</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                     <span class="n">groups</span><span class="o">=</span><span class="n">num_groups</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">w_b</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">w_b</span><span class="p">,</span> <span class="n">w_out</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">w_out</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x_proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="k">else</span> <span class="n">x</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x_proj</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div>
<h4 id="convnext-a-convnet-for-the-2020s-2022">ConvNeXt: A ConvNet for the 2020s (2022)</h4>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/2201.03545">A ConvNet for the 2020s</a></p>
<p><strong>Authors</strong>: Zhuang Liu et al. (Facebook AI Research, UC Berkeley)</p>
<p><strong>Code</strong>: <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/convnext.py">ConvNeXt Implementation</a></p>
<p><strong>Key Innovation</strong>: <strong>Modernizing ConvNets with Transformer Design Principles</strong></p>
<p>ConvNeXt systematically studies how to modernize a standard ResNet:
1. <strong>Macro Design</strong>: Stage compute ratios (1:1:3:1 → 1:1:9:1)
2. <strong>ResNeXt-ify</strong>: Grouped convolutions
3. <strong>Inverted Bottleneck</strong>: Expand then compress
4. <strong>Large Kernel Sizes</strong>: 7×7 depthwise convolutions
5. <strong>Various Layer-wise Micro Designs</strong>: LayerNorm, GELU, fewer normalization layers</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ConvNeXtBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">drop_path</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">layer_scale_init_value</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">dim</span><span class="p">)</span>  <span class="c1"># Expansion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>  <span class="c1"># Compression</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">layer_scale_init_value</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">dim</span><span class="p">)),</span> 
                                 <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">layer_scale_init_value</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span> <span class="o">=</span> <span class="n">DropPath</span><span class="p">(</span><span class="n">drop_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">drop_path</span> <span class="o">&gt;</span> <span class="mf">0.</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, C, H, W) -&gt; (N, H, W, C)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (N, H, W, C) -&gt; (N, C, H, W)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_path</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<h4 id="architecture-evolution-summary">Architecture Evolution Summary</h4>
<table>
<thead>
<tr>
<th>Architecture</th>
<th>Year</th>
<th>Key Innovation</th>
<th>ImageNet Top-1</th>
<th>Parameters</th>
<th>FLOPs</th>
</tr>
</thead>
<tbody>
<tr>
<td>GoogLeNet</td>
<td>2014</td>
<td>Inception modules</td>
<td>69.8%</td>
<td>6.8M</td>
<td>1.5G</td>
</tr>
<tr>
<td>MobileNet v1</td>
<td>2017</td>
<td>Depthwise separable</td>
<td>70.6%</td>
<td>4.2M</td>
<td>0.57G</td>
</tr>
<tr>
<td>MobileNet v2</td>
<td>2018</td>
<td>Inverted residuals</td>
<td>72.0%</td>
<td>3.4M</td>
<td>0.30G</td>
</tr>
<tr>
<td>ResNeXt-50</td>
<td>2017</td>
<td>Grouped convolutions</td>
<td>77.8%</td>
<td>25.0M</td>
<td>4.2G</td>
</tr>
<tr>
<td>EfficientNet-B0</td>
<td>2019</td>
<td>Compound scaling</td>
<td>77.3%</td>
<td>5.3M</td>
<td>0.39G</td>
</tr>
<tr>
<td>RegNet-Y-4GF</td>
<td>2020</td>
<td>Design space search</td>
<td>80.0%</td>
<td>21M</td>
<td>4.0G</td>
</tr>
<tr>
<td>ConvNeXt-T</td>
<td>2022</td>
<td>Modernized ConvNet</td>
<td>82.1%</td>
<td>29M</td>
<td>4.5G</td>
</tr>
</tbody>
</table>
<h4 id="modern-cnn-design-principles">Modern CNN Design Principles</h4>
<p><strong>Efficiency-Oriented Designs</strong>:
1. <strong>Depthwise Separable Convolutions</strong>: Reduce computational cost
2. <strong>Inverted Bottlenecks</strong>: Expand-process-compress pattern
3. <strong>Squeeze-and-Excitation</strong>: Channel attention for better representations
4. <strong>Neural Architecture Search</strong>: Automated design space exploration</p>
<p><strong>Performance-Oriented Designs</strong>:
1. <strong>Compound Scaling</strong>: Balanced scaling of depth, width, and resolution
2. <strong>Large Kernels</strong>: Return to larger receptive fields (7×7, 9×9)
3. <strong>Modern Activations</strong>: GELU, Swish/SiLU over ReLU
4. <strong>Advanced Normalization</strong>: LayerNorm, GroupNorm over BatchNorm
5. <strong>Regularization</strong>: DropPath, Stochastic Depth, Label Smoothing</p>
<p><strong>Research Papers and Resources</strong>:
- <strong>MobileNet Series</strong>: <a href="https://arxiv.org/abs/1704.04861">v1</a>, <a href="https://arxiv.org/abs/1801.04381">v2</a>, <a href="https://arxiv.org/abs/1905.02244">v3</a>
- <strong>EfficientNet Series</strong>: <a href="https://arxiv.org/abs/1905.11946">Original</a>, <a href="https://arxiv.org/abs/2104.00298">v2</a>
- <strong>RegNet</strong>: <a href="https://arxiv.org/abs/2003.13678">Design Spaces</a>
- <strong>ConvNeXt</strong>: <a href="https://arxiv.org/abs/2201.03545">Modernizing ConvNets</a>
- <strong>Comprehensive Survey</strong>: <a href="https://arxiv.org/abs/2106.08962">Efficient Deep Learning</a></p>
<hr />
<h2 id="optimization-techniques">Optimization Techniques</h2>
<h3 id="gradient-descent-variants">Gradient Descent Variants</h3>
<h4 id="stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</h4>
<p><strong>Vanilla SGD</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\theta_{t+1} = \theta_t - \eta \nabla_{\theta} \mathcal{L}(\theta_t; x^{(i)}, y^{(i)})\)</span>\)</span></p>
<p><strong>SGD with Momentum</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(v_t = \gamma v_{t-1} + \eta \nabla_{\theta} \mathcal{L}(\theta_t)\)</span>\)</span>
<span class="arithmatex">\(<span class="arithmatex">\(\theta_{t+1} = \theta_t - v_t\)</span>\)</span></p>
<p>Where <span class="arithmatex">\(\gamma\)</span> (typically 0.9) is the momentum coefficient.</p>
<p><strong>Nesterov Accelerated Gradient (NAG)</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(v_t = \gamma v_{t-1} + \eta \nabla_{\theta} \mathcal{L}(\theta_t - \gamma v_{t-1})\)</span>\)</span>
<span class="arithmatex">\(<span class="arithmatex">\(\theta_{t+1} = \theta_t - v_t\)</span>\)</span></p>
<h4 id="adaptive-learning-rate-methods">Adaptive Learning Rate Methods</h4>
<p><strong>AdaGrad</strong>: <a href="https://jmlr.org/papers/v12/duchi11a.html">Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></p>
<div class="arithmatex">\[G_t = G_{t-1} + (\nabla_{\theta} \mathcal{L}(\theta_t))^2$$
$$\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \nabla_{\theta} \mathcal{L}(\theta_t)\]</div>
<p><strong>RMSprop</strong>: <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</a></p>
<div class="arithmatex">\[E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma) (\nabla_{\theta} \mathcal{L}(\theta_t))^2$$
$$\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} \nabla_{\theta} \mathcal{L}(\theta_t)\]</div>
<p><strong>Adam</strong>: <a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a></p>
<div class="arithmatex">\[m_t = \beta_1 m_{t-1} + (1-\beta_1) \nabla_{\theta} \mathcal{L}(\theta_t)$$
$$v_t = \beta_2 v_{t-1} + (1-\beta_2) (\nabla_{\theta} \mathcal{L}(\theta_t))^2\]</div>
<div class="arithmatex">\[\hat{m}_t = \frac{m_t}{1-\beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1-\beta_2^t}\]</div>
<div class="arithmatex">\[\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t\]</div>
<p>Typical values: <span class="arithmatex">\(\beta_1 = 0.9\)</span>, <span class="arithmatex">\(\beta_2 = 0.999\)</span>, <span class="arithmatex">\(\epsilon = 10^{-8}\)</span></p>
<p><strong>AdamW</strong>: <a href="https://arxiv.org/abs/1711.05101">Decoupled Weight Decay Regularization</a></p>
<p>Decouples weight decay from gradient-based update:
<span class="arithmatex">\(<span class="arithmatex">\(\theta_{t+1} = \theta_t - \eta \left(\frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} + \lambda \theta_t\right)\)</span>\)</span></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>

<span class="c1"># Optimizer comparison</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">YourModel</span><span class="p">()</span>

<span class="c1"># SGD with momentum</span>
<span class="n">optimizer_sgd</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Adam</span>
<span class="n">optimizer_adam</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>

<span class="c1"># AdamW</span>
<span class="n">optimizer_adamw</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Learning rate scheduling</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer_adam</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div>
<h3 id="learning-rate-scheduling">Learning Rate Scheduling</h3>
<h4 id="step-decay">Step Decay</h4>
<div class="arithmatex">\[\eta_t = \eta_0 \times \gamma^{\lfloor t/s \rfloor}\]</div>
<p>Where <span class="arithmatex">\(s\)</span> is the step size and <span class="arithmatex">\(\gamma\)</span> is the decay factor.</p>
<h4 id="exponential-decay">Exponential Decay</h4>
<div class="arithmatex">\[\eta_t = \eta_0 \times e^{-\lambda t}\]</div>
<h4 id="cosine-annealing">Cosine Annealing</h4>
<div class="arithmatex">\[\eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})(1 + \cos(\frac{t}{T}\pi))\]</div>
<h4 id="warm-up-and-restart">Warm-up and Restart</h4>
<p><strong>Linear Warm-up</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\eta_t = \begin{cases}
\frac{t}{T_{warmup}} \eta_{target} &amp; \text{if } t &lt; T_{warmup} \\
\eta_{target} &amp; \text{otherwise}
\end{cases}\)</span>\)</span></p>
<h3 id="weight-initialization">Weight Initialization</h3>
<h4 id="xavierglorot-initialization">Xavier/Glorot Initialization</h4>
<p><strong>Paper</strong>: <a href="http://proceedings.mlr.press/v9/glorot10a.html">Understanding the difficulty of training deep feedforward neural networks</a></p>
<p>For layer with <span class="arithmatex">\(n_{in}\)</span> inputs and <span class="arithmatex">\(n_{out}\)</span> outputs:</p>
<p><strong>Xavier Normal</strong>: <span class="arithmatex">\(W \sim \mathcal{N}(0, \frac{2}{n_{in} + n_{out}})\)</span></p>
<p><strong>Xavier Uniform</strong>: <span class="arithmatex">\(W \sim \mathcal{U}(-\sqrt{\frac{6}{n_{in} + n_{out}}}, \sqrt{\frac{6}{n_{in} + n_{out}}})\)</span></p>
<h4 id="he-initialization">He Initialization</h4>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1502.01852">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></p>
<p>Designed for ReLU activations:</p>
<p><strong>He Normal</strong>: <span class="arithmatex">\(W \sim \mathcal{N}(0, \frac{2}{n_{in}})\)</span></p>
<p><strong>He Uniform</strong>: <span class="arithmatex">\(W \sim \mathcal{U}(-\sqrt{\frac{6}{n_{in}}}, \sqrt{\frac{6}{n_{in}}})\)</span></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">def</span><span class="w"> </span><span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="c1"># He initialization for ReLU</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_out&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Apply initialization</span>
<span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
</code></pre></div>
<hr />
<h2 id="regularization-methods">Regularization Methods</h2>
<h3 id="l1-and-l2-regularization">L1 and L2 Regularization</h3>
<h4 id="l2-regularization-weight-decay">L2 Regularization (Weight Decay)</h4>
<div class="arithmatex">\[\mathcal{L}_{total} = \mathcal{L}_{data} + \lambda \sum_{i} w_i^2\]</div>
<p>Gradient update:
<span class="arithmatex">\(<span class="arithmatex">\(\frac{\partial \mathcal{L}_{total}}{\partial w_i} = \frac{\partial \mathcal{L}_{data}}{\partial w_i} + 2\lambda w_i\)</span>\)</span></p>
<h4 id="l1-regularization-lasso">L1 Regularization (Lasso)</h4>
<div class="arithmatex">\[\mathcal{L}_{total} = \mathcal{L}_{data} + \lambda \sum_{i} |w_i|\]</div>
<p>Promotes sparsity in weights.</p>
<h4 id="elastic-net">Elastic Net</h4>
<div class="arithmatex">\[\mathcal{L}_{total} = \mathcal{L}_{data} + \lambda_1 \sum_{i} |w_i| + \lambda_2 \sum_{i} w_i^2\]</div>
<h3 id="dropout">Dropout</h3>
<p><strong>Paper</strong>: <a href="https://jmlr.org/papers/v15/srivastava14a.html">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></p>
<h4 id="standard-dropout">Standard Dropout</h4>
<p>During training:
<span class="arithmatex">\(<span class="arithmatex">\(y_i = \begin{cases}
\frac{x_i}{1-p} &amp; \text{with probability } 1-p \\
0 &amp; \text{with probability } p
\end{cases}\)</span>\)</span></p>
<p>During inference: <span class="arithmatex">\(y_i = x_i\)</span> (no dropout)</p>
<h4 id="inverted-dropout">Inverted Dropout</h4>
<p>Scale during training to avoid scaling during inference:
<span class="arithmatex">\(<span class="arithmatex">\(y_i = \begin{cases}
\frac{x_i}{1-p} &amp; \text{with probability } 1-p \\
0 &amp; \text{with probability } p
\end{cases}\)</span>\)</span></p>
<h4 id="dropconnect">DropConnect</h4>
<p><strong>Paper</strong>: <a href="https://proceedings.mlr.press/v28/wan13.html">Regularization of Neural Networks using DropConnect</a></p>
<p>Instead of dropping activations, drop connections (weights):
<span class="arithmatex">\(<span class="arithmatex">\(y = f((W \odot M)x + b)\)</span>\)</span></p>
<p>Where <span class="arithmatex">\(M\)</span> is a binary mask.</p>
<h3 id="batch-normalization">Batch Normalization</h3>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p>
<h4 id="algorithm">Algorithm</h4>
<p>For a mini-batch <span class="arithmatex">\(\mathcal{B} = \{x_1, ..., x_m\}\)</span>:</p>
<ol>
<li>
<p><strong>Compute statistics</strong>:
   <span class="arithmatex">\(<span class="arithmatex">\(\mu_{\mathcal{B}} = \frac{1}{m} \sum_{i=1}^m x_i\)</span>\)</span>
   <span class="arithmatex">\(<span class="arithmatex">\(\sigma_{\mathcal{B}}^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_{\mathcal{B}})^2\)</span>\)</span></p>
</li>
<li>
<p><strong>Normalize</strong>:
   <span class="arithmatex">\(<span class="arithmatex">\(\hat{x}_i = \frac{x_i - \mu_{\mathcal{B}}}{\sqrt{\sigma_{\mathcal{B}}^2 + \epsilon}}\)</span>\)</span></p>
</li>
<li>
<p><strong>Scale and shift</strong>:
   <span class="arithmatex">\(<span class="arithmatex">\(y_i = \gamma \hat{x}_i + \beta\)</span>\)</span></p>
</li>
</ol>
<p>Where <span class="arithmatex">\(\gamma\)</span> and <span class="arithmatex">\(\beta\)</span> are learnable parameters.</p>
<h4 id="benefits">Benefits</h4>
<ol>
<li><strong>Faster training</strong>: Higher learning rates possible</li>
<li><strong>Reduced sensitivity to initialization</strong></li>
<li><strong>Regularization effect</strong>: Reduces overfitting</li>
<li><strong>Gradient flow</strong>: Helps with vanishing gradients</li>
</ol>
<h4 id="variants">Variants</h4>
<p><strong>Layer Normalization</strong>: <a href="https://arxiv.org/abs/1607.06450">Layer Normalization</a>
<span class="arithmatex">\(<span class="arithmatex">\(\mu_l = \frac{1}{H} \sum_{i=1}^H x_i^l, \quad \sigma_l^2 = \frac{1}{H} \sum_{i=1}^H (x_i^l - \mu_l)^2\)</span>\)</span></p>
<p><strong>Group Normalization</strong>: <a href="https://arxiv.org/abs/1803.08494">Group Normalization</a></p>
<p><strong>Instance Normalization</strong>: <a href="https://arxiv.org/abs/1607.08022">Instance Normalization: The Missing Ingredient for Fast Stylization</a></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">NormalizationComparison</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Different normalization techniques</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">([</span><span class="n">num_features</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>  <span class="c1"># [C, H, W]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">group_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>  <span class="c1"># 8 groups</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">instance_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Choose normalization based on use case</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<h3 id="data-augmentation">Data Augmentation</h3>
<h4 id="traditional-augmentations">Traditional Augmentations</h4>
<ol>
<li><strong>Geometric</strong>: Rotation, scaling, translation, flipping</li>
<li><strong>Photometric</strong>: Brightness, contrast, saturation, hue</li>
<li><strong>Noise</strong>: Gaussian noise, salt-and-pepper noise</li>
<li><strong>Occlusion</strong>: Random erasing, cutout</li>
</ol>
<h4 id="advanced-augmentations">Advanced Augmentations</h4>
<p><strong>Mixup</strong>: <a href="https://arxiv.org/abs/1710.09412">mixup: Beyond Empirical Risk Minimization</a></p>
<div class="arithmatex">\[\tilde{x} = \lambda x_i + (1-\lambda) x_j$$
$$\tilde{y} = \lambda y_i + (1-\lambda) y_j\]</div>
<p>Where <span class="arithmatex">\(\lambda \sim \text{Beta}(\alpha, \alpha)\)</span></p>
<p><strong>CutMix</strong>: <a href="https://arxiv.org/abs/1905.04899">CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features</a></p>
<p>Combine patches from two images with proportional labels.</p>
<p><strong>AutoAugment</strong>: <a href="https://arxiv.org/abs/1805.09501">AutoAugment: Learning Augmentation Strategies from Data</a></p>
<p>Use reinforcement learning to find optimal augmentation policies.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transforms</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="k">def</span><span class="w"> </span><span class="nf">mixup_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixup augmentation&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">alpha</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">lam</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lam</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="n">mixed_x</span> <span class="o">=</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lam</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">y_a</span><span class="p">,</span> <span class="n">y_b</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">mixed_x</span><span class="p">,</span> <span class="n">y_a</span><span class="p">,</span> <span class="n">y_b</span><span class="p">,</span> <span class="n">lam</span>

<span class="c1"># Standard augmentations</span>
<span class="n">transform_train</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="n">brightness</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">))</span>
<span class="p">])</span>
</code></pre></div>
<hr />
<h2 id="advanced-training-techniques">Advanced Training Techniques</h2>
<h3 id="transfer-learning">Transfer Learning</h3>
<h4 id="fine-tuning-strategies">Fine-tuning Strategies</h4>
<ol>
<li><strong>Feature Extraction</strong>: Freeze pre-trained layers, train only classifier</li>
<li><strong>Fine-tuning</strong>: Train entire network with lower learning rate</li>
<li><strong>Gradual Unfreezing</strong>: Progressively unfreeze layers during training</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>

<span class="c1"># Load pre-trained model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Strategy 1: Feature extraction</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Replace classifier</span>
<span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># Strategy 2: Fine-tuning with different learning rates</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">}</span>
<span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</code></pre></div>
<h3 id="multi-gpu-training">Multi-GPU Training</h3>
<h4 id="data-parallelism">Data Parallelism</h4>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># Simple data parallelism</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</code></pre></div>
<h4 id="distributed-training">Distributed Training</h4>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.multiprocessing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn.parallel</span><span class="w"> </span><span class="kn">import</span> <span class="n">DistributedDataParallel</span> <span class="k">as</span> <span class="n">DDP</span>

<span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
    <span class="n">setup</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">YourModel</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DDP</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>

    <span class="c1"># Training loop</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="c1"># ... training code ...</span>
        <span class="k">pass</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">world_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
    <span class="n">mp</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">world_size</span><span class="p">,),</span> <span class="n">nprocs</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>
</code></pre></div>
<h3 id="mixed-precision-training">Mixed Precision Training</h3>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/1710.03740">Mixed Precision Training</a></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">torch.cuda.amp</span><span class="w"> </span><span class="kn">import</span> <span class="n">autocast</span><span class="p">,</span> <span class="n">GradScaler</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">YourModel</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">()</span>

<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Forward pass with autocast</span>
    <span class="k">with</span> <span class="n">autocast</span><span class="p">():</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

    <span class="c1"># Backward pass with gradient scaling</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</code></pre></div>
<hr />
<h2 id="modern-architectures-and-trends">Modern Architectures and Trends</h2>
<h3 id="vision-transformers-vits">Vision Transformers (ViTs)</h3>
<p><strong>Paper</strong>: <a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></p>
<p><strong>Code</strong>: <a href="https://github.com/google-research/vision_transformer">Vision Transformer</a></p>
<h4 id="architecture">Architecture</h4>
<ol>
<li><strong>Patch Embedding</strong>: Split image into patches and linearly embed</li>
<li><strong>Position Embedding</strong>: Add learnable position embeddings</li>
<li><strong>Transformer Encoder</strong>: Standard transformer blocks</li>
<li><strong>Classification Head</strong>: MLP for final prediction</li>
</ol>
<h4 id="mathematical-formulation_1">Mathematical Formulation</h4>
<p><strong>Patch Embedding</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\mathbf{z}_0 = [\mathbf{x}_{class}; \mathbf{x}_p^1\mathbf{E}; \mathbf{x}_p^2\mathbf{E}; \cdots; \mathbf{x}_p^N\mathbf{E}] + \mathbf{E}_{pos}\)</span>\)</span></p>
<p>Where:
- <span class="arithmatex">\(\mathbf{x}_p^i \in \mathbb{R}^{P^2 \cdot C}\)</span> is the <span class="arithmatex">\(i\)</span>-th flattened patch
- <span class="arithmatex">\(\mathbf{E} \in \mathbb{R}^{(P^2 \cdot C) \times D}\)</span> is the patch embedding matrix
- <span class="arithmatex">\(\mathbf{E}_{pos} \in \mathbb{R}^{(N+1) \times D}\)</span> are position embeddings</p>
<p><strong>Transformer Block</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\mathbf{z}'_l = \text{MSA}(\text{LN}(\mathbf{z}_{l-1})) + \mathbf{z}_{l-1}\)</span>\)</span>
<span class="arithmatex">\(<span class="arithmatex">\(\mathbf{z}_l = \text{MLP}(\text{LN}(\mathbf{z}'_l)) + \mathbf{z}'_l\)</span>\)</span></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">einops</span><span class="w"> </span><span class="kn">import</span> <span class="n">rearrange</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PatchEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_size</span> <span class="o">=</span> <span class="n">img_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_size</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> 
                                   <span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: (B, C, H, W)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (B, embed_dim, H/P, W/P)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;b e h w -&gt; b (h w) e&#39;</span><span class="p">)</span>  <span class="c1"># (B, N, embed_dim)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span><span class="w"> </span><span class="nc">VisionTransformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                 <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">patch_embed</span> <span class="o">=</span> <span class="n">PatchEmbedding</span><span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embed</span><span class="o">.</span><span class="n">n_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> 
                                     <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">4</span><span class="o">*</span><span class="n">embed_dim</span><span class="p">,</span> 
                                     <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">depth</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Patch embedding</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (B, N, embed_dim)</span>

        <span class="c1"># Add class token</span>
        <span class="n">cls_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">cls_tokens</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, N+1, embed_dim)</span>

        <span class="c1"># Add position embedding</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span>

        <span class="c1"># Transformer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Classification</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>  <span class="c1"># Use class token</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<h3 id="neural-architecture-search-nas-evolution-and-current-status">Neural Architecture Search (NAS): Evolution and Current Status</h3>
<h4 id="historical-context-and-peak-era-2017-2020">Historical Context and Peak Era (2017-2020)</h4>
<p><strong>Foundational Papers</strong>:
- <a href="https://arxiv.org/abs/1611.01578">Neural Architecture Search with Reinforcement Learning</a> (2017)
- <a href="https://arxiv.org/abs/1806.09055">DARTS: Differentiable Architecture Search</a> (2018)
- <a href="https://arxiv.org/abs/1905.11946">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a> (2019)</p>
<p><strong>Key Approaches During Peak Era</strong>:
1. <strong>Reinforcement Learning</strong>: Use RL to search architecture space
2. <strong>Evolutionary Algorithms</strong>: Evolve architectures through mutations
3. <strong>Differentiable Search</strong>: Make architecture search differentiable
4. <strong>Progressive Search</strong>: Gradually increase complexity</p>
<h4 id="darts-differentiable-architecture-search">DARTS (Differentiable Architecture Search)</h4>
<p><strong>Continuous Relaxation</strong>: Instead of discrete architecture choices, use weighted combinations:</p>
<div class="arithmatex">\[o^{(i,j)} = \sum_{o \in \mathcal{O}} \frac{\exp(\alpha_o^{(i,j)})}{\sum_{o' \in \mathcal{O}} \exp(\alpha_{o'}^{(i,j)})} o(x)\]</div>
<p>Where <span class="arithmatex">\(\alpha\)</span> are architecture parameters learned via gradient descent.</p>
<h4 id="current-status-of-nas-2024-perspective">Current Status of NAS (2024 Perspective)</h4>
<p><strong>🔥 Is NAS Still Hot?</strong> <strong>Partially - Evolved Focus</strong></p>
<p><strong>Why NAS Research Has Cooled Down</strong>:</p>
<ol>
<li>
<p><strong>Transformer Dominance</strong>: The rise of Vision Transformers (ViTs) and foundation models shifted focus from CNN architecture search to scaling and adaptation strategies</p>
</li>
<li>
<p><strong>Computational Cost vs. Benefit</strong>: NAS requires enormous computational resources (thousands of GPU hours) for marginal improvements over well-established architectures</p>
</li>
<li>
<p><strong>Manual Design Success</strong>: Hand-crafted architectures like ResNet, EfficientNet, and ConvNeXt proved highly effective and generalizable</p>
</li>
<li>
<p><strong>Transfer Learning Paradigm</strong>: Pre-trained models became dominant, reducing the need for task-specific architecture search</p>
</li>
</ol>
<p><strong>Where NAS Remains Relevant</strong>:</p>
<ol>
<li><strong>Edge Computing &amp; Mobile</strong>: Resource-constrained environments still benefit from architecture optimization</li>
<li>
<p><strong>Papers</strong>: <a href="https://arxiv.org/abs/1908.09791">Once-for-All</a>, <a href="https://arxiv.org/abs/1905.02244">MobileNets-v3</a></p>
</li>
<li>
<p><strong>Hardware-Aware NAS</strong>: Optimizing for specific hardware (TPUs, edge devices)</p>
</li>
<li>
<p><strong>Papers</strong>: <a href="https://arxiv.org/abs/1812.03443">FBNet</a>, <a href="https://arxiv.org/abs/1812.00332">ProxylessNAS</a></p>
</li>
<li>
<p><strong>Specialized Domains</strong>: Medical imaging, autonomous driving where custom architectures matter</p>
</li>
<li><strong>Papers</strong>: <a href="https://arxiv.org/abs/2001.00179">NAS-Bench-201</a></li>
</ol>
<p><strong>Modern Evolution - Beyond Traditional NAS</strong>:</p>
<ol>
<li><strong>Neural Architecture Scaling</strong>: Focus shifted to scaling laws and compound scaling</li>
<li><strong>EfficientNet family</strong> remains highly influential</li>
<li>
<p><strong>Scaling laws</strong> for transformers (GPT, BERT families)</p>
</li>
<li>
<p><strong>Architecture Components Search</strong>: Instead of full architectures, search for specific components</p>
</li>
<li><strong>Attention mechanisms</strong>: Multi-head, sparse attention patterns</li>
<li>
<p><strong>Activation functions</strong>: Swish, GELU discovered through search</p>
</li>
<li>
<p><strong>Prompt Architecture Search</strong>: In the LLM era, searching optimal prompt structures</p>
</li>
<li><strong>Papers</strong>: <a href="https://arxiv.org/abs/2010.15980">AutoPrompt</a>, <a href="https://arxiv.org/abs/2103.10385">P-Tuning</a></li>
</ol>
<p><strong>Current Research Trends (2023-2024)</strong>:</p>
<ol>
<li><strong>Foundation Model Architecture</strong>: Searching architectures for large-scale pre-training</li>
<li><strong>Multimodal Architecture Search</strong>: Optimizing vision-language model architectures</li>
<li><strong>Efficient Fine-tuning Architectures</strong>: LoRA, adapters, and parameter-efficient methods</li>
<li><strong>Automated Model Compression</strong>: Combining NAS with pruning and quantization</li>
</ol>
<p><strong>Industry Adoption Status</strong>:</p>
<p>✅ <strong>Still Used</strong>: Google (EfficientNet family), Facebook/Meta (RegNet), Apple (mobile optimization)</p>
<p>❌ <strong>Less Common</strong>: Startups and smaller companies prefer established architectures</p>
<p><strong>Verdict</strong>: NAS is <strong>not as hot</strong> as 2017-2020 peak, but has <strong>evolved</strong> into more specialized applications. The field matured from "search everything" to "search what matters" - focusing on efficiency, hardware constraints, and domain-specific optimizations rather than general-purpose architecture discovery.</p>
<p><strong>Modern Alternatives to Traditional NAS</strong>:
- <strong>Architecture Families</strong>: Use proven families (ResNet, EfficientNet, ViT) with scaling
- <strong>Transfer Learning</strong>: Start with pre-trained models and adapt
- <strong>Manual Design + Scaling Laws</strong>: Combine human insight with systematic scaling
- <strong>Component-wise Optimization</strong>: Optimize specific components rather than full architectures</p>
<hr />
<h2 id="semi-supervised-learning">Semi-Supervised Learning</h2>
<h3 id="problem-formulation">Problem Formulation</h3>
<p>Given:
- Labeled data: <span class="arithmatex">\(\mathcal{D}_l = \{(x_i, y_i)\}_{i=1}^{n_l}\)</span>
- Unlabeled data: <span class="arithmatex">\(\mathcal{D}_u = \{x_j\}_{j=1}^{n_u}\)</span> where <span class="arithmatex">\(n_u \gg n_l\)</span></p>
<p>Goal: Learn from both labeled and unlabeled data to improve performance.</p>
<h3 id="consistency-regularization-methods">Consistency Regularization Methods</h3>
<h4 id="-model-and-temporal-ensembling">Π-Model and Temporal Ensembling</h4>
<p><strong>Π-Model</strong>: <a href="https://arxiv.org/abs/1610.02242">Temporal Ensembling for Semi-Supervised Learning</a></p>
<div class="arithmatex">\[\mathcal{L} = \mathcal{L}_{supervised} + \lambda \mathcal{L}_{consistency}\]</div>
<p>Where:
<span class="arithmatex">\(<span class="arithmatex">\(\mathcal{L}_{consistency} = \mathbb{E}[||f(x + \epsilon_1) - f(x + \epsilon_2)||^2]\)</span>\)</span></p>
<p><strong>Temporal Ensembling</strong>: Maintains exponential moving average of predictions:
<span class="arithmatex">\(<span class="arithmatex">\(Z_i^{(t)} = \alpha Z_i^{(t-1)} + (1-\alpha) z_i^{(t)}\)</span>\)</span></p>
<h4 id="mean-teacher">Mean Teacher</h4>
<p><strong>Mean Teacher</strong>: <a href="https://arxiv.org/abs/1703.01780">Mean teachers are better role models</a></p>
<p>Use exponential moving average of student weights as teacher:
<span class="arithmatex">\(<span class="arithmatex">\(\theta'_t = \alpha \theta'_{t-1} + (1-\alpha) \theta_t\)</span>\)</span></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MeanTeacher</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">student_model</span><span class="p">,</span> <span class="n">teacher_model</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.999</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">student</span> <span class="o">=</span> <span class="n">student_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher</span> <span class="o">=</span> <span class="n">teacher_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

        <span class="c1"># Initialize teacher with student weights</span>
        <span class="k">for</span> <span class="n">teacher_param</span><span class="p">,</span> <span class="n">student_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">teacher</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
                                               <span class="bp">self</span><span class="o">.</span><span class="n">student</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
            <span class="n">teacher_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">student_param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_teacher</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># EMA update</span>
        <span class="k">for</span> <span class="n">teacher_param</span><span class="p">,</span> <span class="n">student_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">teacher</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
                                               <span class="bp">self</span><span class="o">.</span><span class="n">student</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
            <span class="n">teacher_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">student_param</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">consistency_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">student_output</span><span class="p">,</span> <span class="n">teacher_output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">student_output</span><span class="p">,</span> <span class="n">teacher_output</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
</code></pre></div>
<h3 id="pseudo-labeling-methods">Pseudo-Labeling Methods</h3>
<h4 id="self-training-and-co-training">Self-Training and Co-Training</h4>
<p><strong>Self-Training</strong>: Use model predictions as pseudo-labels for unlabeled data.</p>
<ol>
<li>Train on labeled data</li>
<li>Predict on unlabeled data</li>
<li>Select high-confidence predictions as pseudo-labels</li>
<li>Retrain on labeled + pseudo-labeled data</li>
</ol>
<p><strong>Co-Training</strong>: <a href="https://www.cs.cmu.edu/~avrim/Papers/cotrain.pdf">Combining Labeled and Unlabeled Data with Co-Training</a></p>
<p>Train two models on different feature views and use their predictions to teach each other.</p>
<h4 id="fixmatch-and-advanced-methods">FixMatch and Advanced Methods</h4>
<p><strong>FixMatch</strong>: <a href="https://arxiv.org/abs/2001.07685">FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence</a></p>
<p>Combines consistency regularization with pseudo-labeling:</p>
<div class="arithmatex">\[\mathcal{L} = \mathcal{L}_s + \lambda_u \frac{1}{\mu B} \sum_{b=1}^{\mu B} \mathbb{1}(\max(q_b) \geq \tau) \mathcal{H}(\hat{q}_b, q_b)\]</div>
<p>Where:
- <span class="arithmatex">\(q_b = p_m(y|\alpha(u_b))\)</span> is prediction on weakly augmented unlabeled data
- <span class="arithmatex">\(\hat{q}_b = p_m(y|\mathcal{A}(u_b))\)</span> is prediction on strongly augmented data
- <span class="arithmatex">\(\tau\)</span> is confidence threshold</p>
<p><strong>FlexMatch</strong>: <a href="https://arxiv.org/abs/2110.08263">FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling</a></p>
<p>Adaptive threshold selection based on learning status of each class.</p>
<p><strong>AdaMatch</strong>: <a href="https://arxiv.org/abs/2106.04732">AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation</a></p>
<p>Combines semi-supervised learning with domain adaptation.</p>
<h3 id="modern-semi-supervised-learning">Modern Semi-Supervised Learning</h3>
<h4 id="mixmatch-and-remixmatch">MixMatch and ReMixMatch</h4>
<p><strong>MixMatch</strong>: <a href="https://arxiv.org/abs/1905.02249">MixMatch: A Holistic Approach to Semi-Supervised Learning</a></p>
<p>Combines consistency regularization, entropy minimization, and traditional regularization.</p>
<p><strong>ReMixMatch</strong>: <a href="https://arxiv.org/abs/1911.09785">ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring</a></p>
<p>Improves MixMatch with distribution alignment and augmentation anchoring.</p>
<h4 id="current-applications-and-trends-2023-2024">Current Applications and Trends (2023-2024)</h4>
<p><strong>Medical Imaging</strong>: Semi-supervised learning is crucial where labeled medical data is scarce.
- <strong>Papers</strong>: <a href="https://arxiv.org/abs/2301.08081">Semi-supervised Medical Image Segmentation</a>
- <strong>Applications</strong>: Radiology, pathology, drug discovery</p>
<p><strong>Natural Language Processing</strong>: 
- <strong>Few-shot Learning</strong>: GPT-style models with limited labeled examples
- <strong>Domain Adaptation</strong>: Adapting models to specific domains with minimal labels</p>
<p><strong>Computer Vision</strong>:
- <strong>Object Detection</strong>: YOLO-World, Grounding DINO for open-vocabulary detection
- <strong>Segmentation</strong>: SAM (Segment Anything Model) fine-tuning with limited labels</p>
<hr />
<h2 id="self-supervised-learning">Self-Supervised Learning</h2>
<h3 id="contrastive-learning-methods">Contrastive Learning Methods</h3>
<h4 id="simclr-and-moco-family">SimCLR and MoCo Family</h4>
<p><strong>SimCLR</strong>: <a href="https://arxiv.org/abs/2002.05709">A Simple Framework for Contrastive Learning of Visual Representations</a></p>
<p><strong>Objective</strong>: Learn representations by contrasting positive and negative pairs.</p>
<div class="arithmatex">\[\ell_{i,j} = -\log \frac{\exp(\text{sim}(z_i, z_j)/\tau)}{\sum_{k=1}^{2N} \mathbb{1}_{[k \neq i]} \exp(\text{sim}(z_i, z_k)/\tau)}\]</div>
<p>Where <span class="arithmatex">\(\text{sim}(u,v) = u^T v / (||u|| ||v||)\)</span> is cosine similarity.</p>
<p><strong>MoCo v1/v2/v3</strong>: <a href="https://arxiv.org/abs/1911.05722">Momentum Contrast for Unsupervised Visual Representation Learning</a></p>
<ul>
<li><strong>MoCo v1</strong>: Momentum-updated encoder with memory bank</li>
<li><strong>MoCo v2</strong>: <a href="https://arxiv.org/abs/2003.04297">Improved Baselines with Momentum Contrastive Learning</a></li>
<li><strong>MoCo v3</strong>: <a href="https://arxiv.org/abs/2104.02057">An Empirical Study of Training Self-Supervised Vision Transformers</a></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">SimCLR</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_encoder</span><span class="p">,</span> <span class="n">projection_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">base_encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">base_encoder</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">base_encoder</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">base_encoder</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">base_encoder</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>  <span class="c1"># Remove classification head</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projector</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">contrastive_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">z1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Compute similarity matrix</span>
        <span class="n">sim_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="o">/</span> <span class="n">temperature</span>

        <span class="c1"># Create labels for positive pairs</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span>
                           <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Mask out self-similarity</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">sim_matrix</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">sim_matrix</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>
<h4 id="swav-and-advanced-contrastive-methods">SwAV and Advanced Contrastive Methods</h4>
<p><strong>SwAV</strong>: <a href="https://arxiv.org/abs/2006.09882">Unsupervised Learning of Visual Features by Contrasting Cluster Assignments</a></p>
<p>Uses cluster assignments instead of individual instances for contrastive learning.</p>
<p><strong>BYOL</strong>: <a href="https://arxiv.org/abs/2006.07733">Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning</a></p>
<p>Avoids negative samples by using momentum-updated target network.</p>
<p><strong>SimSiam</strong>: <a href="https://arxiv.org/abs/2011.10566">Exploring Simple Siamese Representation Learning</a></p>
<p>Simplifies BYOL by removing momentum encoder and using stop-gradient.</p>
<h3 id="masked-modeling-approaches">Masked Modeling Approaches</h3>
<h4 id="vision-mae-and-beyond">Vision: MAE and Beyond</h4>
<p><strong>MAE</strong>: <a href="https://arxiv.org/abs/2111.06377">Masked Autoencoders Are Scalable Vision Learners</a></p>
<p>Mask random patches and reconstruct them:</p>
<div class="arithmatex">\[\mathcal{L} = \mathbb{E}[||x_{masked} - \hat{x}_{masked}||^2]\]</div>
<p><strong>SimMIM</strong>: <a href="https://arxiv.org/abs/2111.09886">SimMIM: A Simple Framework for Masked Image Modeling</a></p>
<p>Simplified masked image modeling with direct pixel prediction.</p>
<p><strong>BEiT</strong>: <a href="https://arxiv.org/abs/2106.08254">BEiT: BERT Pre-Training of Image Transformers</a></p>
<p>Uses discrete visual tokens for masked image modeling.</p>
<h4 id="language-bert-to-modern-llms">Language: BERT to Modern LLMs</h4>
<p><strong>BERT</strong>: <a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers</a></p>
<p><strong>RoBERTa</strong>: <a href="https://arxiv.org/abs/1907.11692">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></p>
<p><strong>Modern Developments</strong>: GPT series, T5, PaLM, LLaMA focusing on autoregressive modeling.</p>
<h3 id="metas-dino-series-self-supervised-vision-transformers">Meta's DINO Series: Self-Supervised Vision Transformers</h3>
<h4 id="dino-2021">DINO (2021)</h4>
<p><strong>DINO</strong>: <a href="https://arxiv.org/abs/2104.14294">Emerging Properties in Self-Supervised Vision Transformers</a></p>
<p><strong>Key Innovation</strong>: Self-distillation with no labels (DINO = self-<strong>DI</strong>stillation with <strong>NO</strong> labels)</p>
<p><strong>Architecture</strong>:
- Student network: ViT with standard augmentations
- Teacher network: EMA of student weights
- Loss: Cross-entropy between student and teacher outputs</p>
<div class="arithmatex">\[\mathcal{L} = -\sum_{x \in \{x_1^g, x_2^g\}} \sum_{i} P_t(x)[i] \log P_s(x)[i]\]</div>
<p>Where <span class="arithmatex">\(P_t\)</span> and <span class="arithmatex">\(P_s\)</span> are teacher and student probability distributions.</p>
<p><strong>Emergent Properties</strong>:
- Attention maps capture object boundaries without supervision
- Features suitable for k-NN classification
- Excellent transfer learning performance</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">DINO</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <span class="n">teacher</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">65536</span><span class="p">,</span> <span class="n">teacher_temp</span><span class="o">=</span><span class="mf">0.04</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">student</span> <span class="o">=</span> <span class="n">student</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher</span> <span class="o">=</span> <span class="n">teacher</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher_temp</span> <span class="o">=</span> <span class="n">teacher_temp</span>

        <span class="c1"># Projection heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">student_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">student</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">student</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">student</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">teacher_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">teacher</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">teacher</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">teacher</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">student_crops</span><span class="p">,</span> <span class="n">teacher_crops</span><span class="p">):</span>
        <span class="c1"># Student forward pass</span>
        <span class="n">student_out</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">student_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">student</span><span class="p">(</span><span class="n">crop</span><span class="p">))</span> <span class="k">for</span> <span class="n">crop</span> <span class="ow">in</span> <span class="n">student_crops</span><span class="p">]</span>

        <span class="c1"># Teacher forward pass (no gradients)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">teacher_out</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">teacher_head</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">teacher</span><span class="p">(</span><span class="n">crop</span><span class="p">))</span> <span class="k">for</span> <span class="n">crop</span> <span class="ow">in</span> <span class="n">teacher_crops</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">student_out</span><span class="p">,</span> <span class="n">teacher_out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">dino_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">student_output</span><span class="p">,</span> <span class="n">teacher_output</span><span class="p">,</span> <span class="n">student_temp</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="n">student_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="n">student_temp</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">student_output</span><span class="p">]</span>
        <span class="n">teacher_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">t</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">teacher_temp</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">teacher_output</span><span class="p">]</span>

        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">n_loss_terms</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">t_ix</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">teacher_out</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">s_ix</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">student_out</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">t_ix</span> <span class="o">==</span> <span class="n">s_ix</span><span class="p">:</span>
                    <span class="k">continue</span>  <span class="c1"># Skip same crop</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">t</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="n">n_loss_terms</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">n_loss_terms</span>
</code></pre></div>
<h4 id="dinov2-2023">DINOv2 (2023)</h4>
<p><strong>DINOv2</strong>: <a href="https://arxiv.org/abs/2304.07193">DINOv2: Learning Robust Visual Features without Supervision</a></p>
<p><strong>Major Improvements</strong>:
1. <strong>Scale</strong>: Trained on 142M curated images (LVD-142M dataset)
2. <strong>Architecture</strong>: Improved ViT architectures (ViT-S/B/L/g)
3. <strong>Training</strong>: Enhanced training recipe with better augmentations
4. <strong>Robustness</strong>: Better performance across diverse domains</p>
<p><strong>Technical Enhancements</strong>:
- <strong>KoLeo regularizer</strong>: Prevents feature collapse
- <strong>Improved data curation</strong>: Better image selection and filtering
- <strong>Multi-scale training</strong>: Different image resolutions
- <strong>Enhanced augmentations</strong>: More sophisticated data augmentation</p>
<p><strong>Performance</strong>:
- <strong>ImageNet-1k</strong>: 84.5% top-1 accuracy (linear evaluation)
- <strong>Transfer Learning</strong>: SOTA on multiple downstream tasks
- <strong>Robustness</strong>: Better performance on out-of-distribution data</p>
<h4 id="dinov3-2024">DINOv3 (2024)</h4>
<p><strong>DINOv3</strong>: <a href="https://arxiv.org/abs/2508.10104">DINOv3: A Major Milestone Toward Realizing Vision Foundation Models</a></p>
<p><strong>Official Code</strong>: <a href="https://github.com/facebookresearch/dinov3">Meta Research DINOv3</a></p>
<p><strong>Vision</strong>: DINOv3 represents a major milestone toward realizing true vision foundation models that can scale effortlessly to massive datasets and larger architectures without being tailored to specific tasks or domains.</p>
<h4 id="core-technical-innovations">Core Technical Innovations</h4>
<p><strong>1. Gram Anchoring Method</strong></p>
<p>DINOv3 introduces <strong>Gram anchoring</strong>, a novel technique that addresses the long-standing issue of dense feature map degradation during extended training schedules. This method:</p>
<ul>
<li><strong>Problem Solved</strong>: Dense features becoming less discriminative over long training</li>
<li><strong>Solution</strong>: Anchors the Gram matrix of feature representations to maintain feature quality</li>
<li><strong>Impact</strong>: Enables stable training for much longer periods, leading to better representations</li>
</ul>
<p><strong>Mathematical Foundation</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(\mathcal{L}_{gram} = ||G(F) - G_{anchor}||_F^2\)</span>\)</span></p>
<p>Where <span class="arithmatex">\(G(F)\)</span> is the Gram matrix of features <span class="arithmatex">\(F\)</span>, and <span class="arithmatex">\(G_{anchor}\)</span> is the anchored reference.</p>
<p><strong>2. Massive Scale Training Strategy</strong></p>
<p><strong>Dataset Scale</strong>: 
- <strong>Training Data</strong>: Leverages carefully curated datasets at unprecedented scale
- <strong>Data Preparation</strong>: Advanced filtering and curation techniques for high-quality training data
- <strong>Diversity</strong>: Covers natural images, aerial imagery, and diverse visual domains</p>
<p><strong>Model Scale</strong>:
- <strong>Architecture Variants</strong>: ViT-S/B/L/g with optimized designs
- <strong>Parameter Scaling</strong>: Up to giant-scale models with billions of parameters
- <strong>Computational Efficiency</strong>: Optimized training procedures for large-scale deployment</p>
<p><strong>3. Post-hoc Enhancement Strategies</strong></p>
<p><strong>Resolution Flexibility</strong>:
- <strong>Multi-Resolution Training</strong>: Models can handle various input resolutions
- <strong>Adaptive Inference</strong>: Dynamic resolution adjustment based on computational constraints
- <strong>Performance Consistency</strong>: Maintains quality across different resolutions</p>
<p><strong>Model Size Adaptation</strong>:
- <strong>Knowledge Distillation</strong>: Efficient transfer from large to smaller models
- <strong>Architecture Flexibility</strong>: Supports various deployment scenarios
- <strong>Resource Optimization</strong>: Tailored models for different computational budgets</p>
<p><strong>Text Alignment</strong>:
- <strong>Cross-Modal Understanding</strong>: Enhanced alignment with textual descriptions
- <strong>Zero-Shot Capabilities</strong>: Improved performance on text-guided vision tasks
- <strong>Multimodal Integration</strong>: Better integration with language models</p>
<h4 id="performance-achievements">Performance Achievements</h4>
<p><strong>Dense Feature Quality</strong>:
- <strong>Semantic Segmentation</strong>: Outstanding performance without fine-tuning
- <strong>Object Detection</strong>: Superior dense prediction capabilities
- <strong>Depth Estimation</strong>: High-quality geometric understanding</p>
<p><strong>Transfer Learning Excellence</strong>:
- <strong>Few-Shot Learning</strong>: Exceptional performance with minimal labeled data
- <strong>Domain Adaptation</strong>: Robust transfer across different visual domains
- <strong>Task Generalization</strong>: Single model performs well across diverse vision tasks</p>
<p><strong>Benchmark Results</strong>:
- <strong>ImageNet Classification</strong>: State-of-the-art linear evaluation performance
- <strong>COCO Detection</strong>: Superior object detection without task-specific training
- <strong>ADE20K Segmentation</strong>: Outstanding semantic segmentation results
- <strong>Robustness</strong>: Better performance on out-of-distribution and adversarial examples</p>
<h4 id="technical-architecture-details">Technical Architecture Details</h4>
<p><strong>Self-Supervised Training Objective</strong>:
- <strong>Enhanced DINO Loss</strong>: Improved version of the original DINO self-distillation
- <strong>Multi-Crop Strategy</strong>: Advanced augmentation and cropping strategies
- <strong>Temperature Scheduling</strong>: Optimized temperature annealing for better convergence</p>
<p><strong>Vision Transformer Optimizations</strong>:
- <strong>Attention Mechanisms</strong>: Refined attention patterns for better feature learning
- <strong>Layer Normalization</strong>: Optimized normalization strategies
- <strong>Positional Encodings</strong>: Enhanced positional encoding schemes</p>
<p><strong>Training Stability</strong>:
- <strong>Gradient Clipping</strong>: Advanced gradient management techniques
- <strong>Learning Rate Scheduling</strong>: Sophisticated learning rate strategies
- <strong>Batch Size Scaling</strong>: Optimized batch size selection for different model scales</p>
<h4 id="practical-impact-and-applications">Practical Impact and Applications</h4>
<p><strong>Foundation Model Capabilities</strong>:
- <strong>Versatile Backbone</strong>: Single model serves multiple vision tasks
- <strong>No Fine-tuning Required</strong>: Direct application to downstream tasks
- <strong>Scalable Deployment</strong>: Efficient deployment across different hardware</p>
<p><strong>Industry Applications</strong>:
- <strong>Content Understanding</strong>: Enhanced image and video analysis
- <strong>Autonomous Systems</strong>: Better visual perception for robotics and autonomous vehicles
- <strong>Medical Imaging</strong>: Improved analysis of medical scans and imagery
- <strong>Satellite Imagery</strong>: Advanced analysis of aerial and satellite data</p>
<p><strong>Research Impact</strong>:
- <strong>Benchmark Setting</strong>: New standards for self-supervised learning
- <strong>Methodology Advancement</strong>: Novel techniques adopted by the community
- <strong>Open Science</strong>: Models and code released for research advancement</p>
<h4 id="future-directions-and-limitations">Future Directions and Limitations</h4>
<p><strong>Ongoing Research</strong>:
- <strong>Multimodal Integration</strong>: Better fusion with language and audio modalities
- <strong>Efficiency Improvements</strong>: Reduced computational requirements
- <strong>Specialized Domains</strong>: Adaptation to specific application domains</p>
<p><strong>Current Limitations</strong>:
- <strong>Computational Requirements</strong>: Still requires significant resources for training
- <strong>Domain Specificity</strong>: Some specialized domains may need additional adaptation
- <strong>Interpretability</strong>: Understanding of learned representations remains challenging</p>
<p><strong>Community Impact</strong>: DINOv3 has established new benchmarks for vision foundation models and provided the research community with powerful tools for advancing computer vision research.</p>
<h3 id="current-trends-and-research-focus-2023-2024">Current Trends and Research Focus (2023-2024)</h3>
<h4 id="foundation-models-and-scaling">Foundation Models and Scaling</h4>
<p><strong>Vision Foundation Models</strong>:
- <strong>SAM</strong>: <a href="https://arxiv.org/abs/2304.02643">Segment Anything Model</a>
- <strong>CLIP</strong>: <a href="https://arxiv.org/abs/2103.00020">Learning Transferable Visual Representations</a>
- <strong>EVA</strong>: <a href="https://arxiv.org/abs/2211.07636">EVA: Exploring the Limits of Masked Visual Representation Learning</a></p>
<p><strong>Multimodal Self-Supervision</strong>:
- <strong>DALL-E 2</strong>: <a href="https://arxiv.org/abs/2204.06125">Hierarchical Text-Conditional Image Generation</a>
- <strong>Flamingo</strong>: <a href="https://arxiv.org/abs/2204.14198">Few-Shot Learning of Visual Tasks</a>
- <strong>BLIP-2</strong>: <a href="https://arxiv.org/abs/2301.12597">Bootstrapping Language-Image Pre-training</a></p>
<h4 id="efficiency-and-practical-applications">Efficiency and Practical Applications</h4>
<p><strong>Mobile and Edge Deployment</strong>:
- <strong>MobileViT</strong>: Self-supervised training for mobile vision transformers
- <strong>EfficientNet</strong>: Self-supervised variants for resource-constrained environments</p>
<p><strong>Domain-Specific Applications</strong>:
- <strong>Medical Imaging</strong>: Self-supervised pre-training for radiology, pathology
- <strong>Autonomous Driving</strong>: Self-supervised learning from driving data
- <strong>Robotics</strong>: Learning representations from robot interaction data</p>
<h4 id="research-directions-2024">Research Directions (2024)</h4>
<ol>
<li><strong>Unified Multimodal Models</strong>: Combining vision, language, and audio</li>
<li><strong>Few-Shot Adaptation</strong>: Quick adaptation to new domains with minimal data</li>
<li><strong>Continual Learning</strong>: Learning new tasks without forgetting previous ones</li>
<li><strong>Interpretability</strong>: Understanding what self-supervised models learn</li>
<li><strong>Efficiency</strong>: Reducing computational requirements for training and inference</li>
</ol>
<p><strong>Industry Adoption</strong>:
- <strong>Meta</strong>: DINO series, MAE for Instagram/Facebook content understanding
- <strong>Google</strong>: SimCLR, MoCo for Google Photos, YouTube
- <strong>OpenAI</strong>: CLIP for DALL-E, GPT-4V
- <strong>Tesla</strong>: Self-supervised learning from driving footage
- <strong>Medical</strong>: Radiology AI, drug discovery applications</p>
<hr />
<h2 id="implementation-guide">Implementation Guide</h2>
<h3 id="setting-up-a-deep-learning-project">Setting Up a Deep Learning Project</h3>
<h4 id="project-structure">Project Structure</h4>
<div class="highlight"><pre><span></span><code>project/
├── data/
│   ├── raw/
│   ├── processed/
│   └── datasets.py
├── models/
│   ├── __init__.py
│   ├── resnet.py
│   ├── vit.py
│   └── utils.py
├── training/
│   ├── __init__.py
│   ├── trainer.py
│   ├── losses.py
│   └── metrics.py
├── configs/
│   ├── base.yaml
│   ├── resnet50.yaml
│   └── vit_base.yaml
├── scripts/
│   ├── train.py
│   ├── evaluate.py
│   └── inference.py
├── requirements.txt
└── README.md
</code></pre></div>
<h4 id="configuration-management">Configuration Management</h4>
<div class="highlight"><pre><span></span><code><span class="c1"># configs/base.yaml</span>
<span class="n">model</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="s2">&quot;resnet50&quot;</span>
  <span class="n">num_classes</span><span class="p">:</span> <span class="mi">1000</span>
  <span class="n">pretrained</span><span class="p">:</span> <span class="n">true</span>

<span class="n">data</span><span class="p">:</span>
  <span class="n">dataset</span><span class="p">:</span> <span class="s2">&quot;imagenet&quot;</span>
  <span class="n">batch_size</span><span class="p">:</span> <span class="mi">256</span>
  <span class="n">num_workers</span><span class="p">:</span> <span class="mi">8</span>
  <span class="n">image_size</span><span class="p">:</span> <span class="mi">224</span>

<span class="n">training</span><span class="p">:</span>
  <span class="n">epochs</span><span class="p">:</span> <span class="mi">100</span>
  <span class="n">learning_rate</span><span class="p">:</span> <span class="mf">0.1</span>
  <span class="n">optimizer</span><span class="p">:</span> <span class="s2">&quot;sgd&quot;</span>
  <span class="n">momentum</span><span class="p">:</span> <span class="mf">0.9</span>
  <span class="n">weight_decay</span><span class="p">:</span> <span class="mf">1e-4</span>
  <span class="n">scheduler</span><span class="p">:</span> <span class="s2">&quot;cosine&quot;</span>

<span class="c1"># config.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span>

<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Config</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">updates</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre></div>
<h4 id="training-loop-template">Training Loop Template</h4>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">wandb</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Trainer</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">train_loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="n">val_loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

        <span class="c1"># Setup optimizer</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;sgd&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
                <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">momentum</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">weight_decay</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;adam&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
                <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">weight_decay</span>
            <span class="p">)</span>

        <span class="c1"># Setup scheduler</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">==</span> <span class="s1">&#39;cosine&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">epochs</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">==</span> <span class="s1">&#39;step&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pbar</span><span class="p">):</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Update progress bar</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span>
                <span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                <span class="s1">&#39;Acc&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="mf">100.</span><span class="o">*</span><span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span>
            <span class="p">})</span>

        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">),</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span><span class="p">:</span>
                <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">val_loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

        <span class="k">return</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">best_acc</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
            <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">validate</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Log metrics</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span>
                <span class="s1">&#39;train_acc&#39;</span><span class="p">:</span> <span class="n">train_acc</span><span class="p">,</span>
                <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span>
                <span class="s1">&#39;val_acc&#39;</span><span class="p">:</span> <span class="n">val_acc</span><span class="p">,</span>
                <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span>
            <span class="p">})</span>

            <span class="c1"># Save best model</span>
            <span class="k">if</span> <span class="n">val_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
                <span class="n">best_acc</span> <span class="o">=</span> <span class="n">val_acc</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
                    <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                    <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">&#39;best_acc&#39;</span><span class="p">:</span> <span class="n">best_acc</span><span class="p">,</span>
                <span class="p">},</span> <span class="s1">&#39;best_model.pth&#39;</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">: Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%, &#39;</span>
                  <span class="sa">f</span><span class="s1">&#39;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Acc: </span><span class="si">{</span><span class="n">val_acc</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</code></pre></div>
<h3 id="debugging-and-monitoring">Debugging and Monitoring</h3>
<h4 id="common-issues-and-solutions">Common Issues and Solutions</h4>
<ol>
<li>
<p><strong>Vanishing/Exploding Gradients</strong>:
   <div class="highlight"><pre><span></span><code><span class="c1"># Monitor gradient norms</span>
<span class="k">def</span><span class="w"> </span><span class="nf">monitor_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">total_norm</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">param_norm</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">param_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">total_norm</span> <span class="o">=</span> <span class="n">total_norm</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_norm</span>

<span class="c1"># Gradient clipping</span>
<span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Memory Issues</strong>:
   <div class="highlight"><pre><span></span><code><span class="c1"># Gradient accumulation</span>
<span class="n">accumulation_steps</span> <span class="o">=</span> <span class="mi">4</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="o">/</span> <span class="n">accumulation_steps</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</code></pre></div></p>
</li>
<li>
<p><strong>Learning Rate Issues</strong>:
   <div class="highlight"><pre><span></span><code><span class="c1"># Learning rate finder</span>
<span class="k">def</span><span class="w"> </span><span class="nf">find_lr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">start_lr</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span> <span class="n">end_lr</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">lrs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">lr</span> <span class="o">=</span> <span class="n">start_lr</span>
    <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>

    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">lrs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="n">lr</span> <span class="o">*=</span> <span class="p">(</span><span class="n">end_lr</span> <span class="o">/</span> <span class="n">start_lr</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>

        <span class="k">if</span> <span class="n">lr</span> <span class="o">&gt;</span> <span class="n">end_lr</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">lrs</span><span class="p">,</span> <span class="n">losses</span>
</code></pre></div></p>
</li>
</ol>
<hr />
<h2 id="references-and-resources">References and Resources</h2>
<h3 id="foundational-papers">Foundational Papers</h3>
<h4 id="historical-foundations">Historical Foundations</h4>
<ol>
<li>
<p><strong>McCulloch, W. S., &amp; Pitts, W.</strong> (1943). <a href="https://link.springer.com/article/10.1007/BF02478259">A logical calculus of the ideas immanent in nervous activity</a>. <em>Bulletin of Mathematical Biophysics</em>.</p>
</li>
<li>
<p><strong>Rosenblatt, F.</strong> (1958). <a href="https://psycnet.apa.org/record/1959-09865-001">The perceptron: a probabilistic model for information storage and organization in the brain</a>. <em>Psychological Review</em>.</p>
</li>
<li>
<p><strong>Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J.</strong> (1986). <a href="https://www.nature.com/articles/323533a0">Learning representations by back-propagating errors</a>. <em>Nature</em>.</p>
</li>
</ol>
<h4 id="modern-deep-learning">Modern Deep Learning</h4>
<ol>
<li>
<p><strong>LeCun, Y., Bottou, L., Bengio, Y., &amp; Haffner, P.</strong> (1998). <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">Gradient-based learning applied to document recognition</a>. <em>Proceedings of the IEEE</em>.</p>
</li>
<li>
<p><strong>Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E.</strong> (2012). <a href="https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">ImageNet classification with deep convolutional neural networks</a>. <em>NIPS</em>.</p>
</li>
<li>
<p><strong>Simonyan, K., &amp; Zisserman, A.</strong> (2014). <a href="https://arxiv.org/abs/1409.1556">Very deep convolutional networks for large-scale image recognition</a>. <em>ICLR</em>.</p>
</li>
<li>
<p><strong>He, K., Zhang, X., Ren, S., &amp; Sun, J.</strong> (2016). <a href="https://arxiv.org/abs/1512.03385">Deep residual learning for image recognition</a>. <em>CVPR</em>.</p>
</li>
<li>
<p><strong>Dosovitskiy, A., et al.</strong> (2020). <a href="https://arxiv.org/abs/2010.11929">An image is worth 16x16 words: Transformers for image recognition at scale</a>. <em>ICLR</em>.</p>
</li>
</ol>
<h4 id="optimization-and-training">Optimization and Training</h4>
<ol>
<li>
<p><strong>Ioffe, S., &amp; Szegedy, C.</strong> (2015). <a href="https://arxiv.org/abs/1502.03167">Batch normalization: Accelerating deep network training by reducing internal covariate shift</a>. <em>ICML</em>.</p>
</li>
<li>
<p><strong>Kingma, D. P., &amp; Ba, J.</strong> (2014). <a href="https://arxiv.org/abs/1412.6980">Adam: A method for stochastic optimization</a>. <em>ICLR</em>.</p>
</li>
<li>
<p><strong>Srivastava, N., et al.</strong> (2014). <a href="https://jmlr.org/papers/v15/srivastava14a.html">Dropout: A simple way to prevent neural networks from overfitting</a>. <em>JMLR</em>.</p>
</li>
</ol>
<h4 id="self-supervised-learning_1">Self-Supervised Learning</h4>
<ol>
<li>
<p><strong>Chen, T., et al.</strong> (2020). <a href="https://arxiv.org/abs/2002.05709">A simple framework for contrastive learning of visual representations</a>. <em>ICML</em>.</p>
</li>
<li>
<p><strong>He, K., et al.</strong> (2022). <a href="https://arxiv.org/abs/2111.06377">Masked autoencoders are scalable vision learners</a>. <em>CVPR</em>.</p>
</li>
</ol>
<h3 id="implementation-resources">Implementation Resources</h3>
<h4 id="frameworks-and-libraries">Frameworks and Libraries</h4>
<ul>
<li><strong>PyTorch</strong>: <a href="https://pytorch.org/">https://pytorch.org/</a></li>
<li><strong>TensorFlow</strong>: <a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a></li>
<li><strong>JAX</strong>: <a href="https://github.com/google/jax">https://github.com/google/jax</a></li>
<li><strong>Hugging Face Transformers</strong>: <a href="https://huggingface.co/transformers/">https://huggingface.co/transformers/</a></li>
<li><strong>timm (PyTorch Image Models)</strong>: <a href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a></li>
</ul>
<h4 id="datasets">Datasets</h4>
<ul>
<li><strong>ImageNet</strong>: <a href="http://www.image-net.org/">http://www.image-net.org/</a></li>
<li><strong>CIFAR-10/100</strong>: <a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></li>
<li><strong>COCO</strong>: <a href="https://cocodataset.org/">https://cocodataset.org/</a></li>
<li><strong>Open Images</strong>: <a href="https://storage.googleapis.com/openimages/web/index.html">https://storage.googleapis.com/openimages/web/index.html</a></li>
</ul>
<h4 id="tools-and-utilities">Tools and Utilities</h4>
<ul>
<li><strong>Weights &amp; Biases</strong>: <a href="https://wandb.ai/">https://wandb.ai/</a></li>
<li><strong>TensorBoard</strong>: <a href="https://www.tensorflow.org/tensorboard">https://www.tensorflow.org/tensorboard</a></li>
<li><strong>Optuna</strong>: <a href="https://optuna.org/">https://optuna.org/</a></li>
<li><strong>Ray Tune</strong>: <a href="https://docs.ray.io/en/latest/tune/">https://docs.ray.io/en/latest/tune/</a></li>
</ul>
<h3 id="books-and-courses">Books and Courses</h3>
<h4 id="books">Books</h4>
<ol>
<li><strong>Goodfellow, I., Bengio, Y., &amp; Courville, A.</strong> <a href="https://www.deeplearningbook.org/">Deep Learning</a>. <em>MIT Press</em>, 2016.</li>
<li><strong>Bishop, C. M.</strong> <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Pattern Recognition and Machine Learning</a>. <em>Springer</em>, 2006.</li>
<li><strong>Murphy, K. P.</strong> <a href="https://probml.github.io/pml-book/">Machine Learning: A Probabilistic Perspective</a>. <em>MIT Press</em>, 2012.</li>
</ol>
<h4 id="online-courses">Online Courses</h4>
<ol>
<li><strong>CS231n: Convolutional Neural Networks for Visual Recognition</strong> - <a href="http://cs231n.stanford.edu/">Stanford</a></li>
<li><strong>CS224n: Natural Language Processing with Deep Learning</strong> - <a href="http://web.stanford.edu/class/cs224n/">Stanford</a></li>
<li><strong>Deep Learning Specialization</strong> - <a href="https://www.coursera.org/specializations/deep-learning">Coursera</a></li>
<li><strong>Fast.ai Practical Deep Learning</strong> - <a href="https://www.fast.ai/">fast.ai</a></li>
</ol>
<hr />
<h2 id="key-takeaways">Key Takeaways</h2>
<h3 id="historical-perspective">Historical Perspective</h3>
<ul>
<li>Deep learning evolved from simple perceptrons to sophisticated architectures through decades of research</li>
<li>Key breakthroughs: backpropagation (1986), CNNs (1990s), AlexNet (2012), ResNet (2015), Transformers (2017)</li>
<li>Each era was enabled by algorithmic innovations, computational advances, and data availability</li>
</ul>
<h3 id="architectural-principles">Architectural Principles</h3>
<ul>
<li><strong>Depth matters</strong>: Deeper networks can learn more complex representations</li>
<li><strong>Skip connections</strong>: Enable training of very deep networks (ResNet)</li>
<li><strong>Attention mechanisms</strong>: Allow models to focus on relevant parts (Transformers)</li>
<li><strong>Efficiency</strong>: Balance between performance and computational cost (EfficientNet)</li>
</ul>
<h3 id="training-best-practices">Training Best Practices</h3>
<ul>
<li><strong>Initialization</strong>: Use appropriate weight initialization (He, Xavier)</li>
<li><strong>Optimization</strong>: Choose suitable optimizers (Adam, AdamW) and learning rate schedules</li>
<li><strong>Regularization</strong>: Prevent overfitting with dropout, batch normalization, data augmentation</li>
<li><strong>Monitoring</strong>: Track gradients, learning curves, and validation metrics</li>
</ul>
<h3 id="modern-trends">Modern Trends</h3>
<ul>
<li><strong>Self-supervised learning</strong>: Learn from unlabeled data</li>
<li><strong>Vision Transformers</strong>: Apply transformer architecture to computer vision</li>
<li><strong>Neural Architecture Search</strong>: Automate architecture design</li>
<li><strong>Efficient training</strong>: Mixed precision, distributed training, gradient accumulation</li>
</ul>
<h3 id="future-directions">Future Directions</h3>
<ul>
<li><strong>Multimodal learning</strong>: Combining vision, language, and other modalities</li>
<li><strong>Few-shot learning</strong>: Learning from limited examples</li>
<li><strong>Continual learning</strong>: Learning new tasks without forgetting old ones</li>
<li><strong>Interpretability</strong>: Understanding what deep networks learn</li>
<li><strong>Sustainability</strong>: Reducing computational and environmental costs</li>
</ul>
<p>Deep learning continues to evolve rapidly, with new architectures, training methods, and applications emerging regularly. The key to success is understanding the fundamental principles while staying current with the latest developments in this dynamic field.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>