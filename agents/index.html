
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../transformers/">
      
      
        <link rel="next" href="../embeddings/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>Tool Calling and Agents - Multimodal Memory LLM and AI Agent</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.4af4bdda.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#tool-calling-and-agent-capabilities-for-llms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Multimodal Memory LLM and AI Agent" class="md-header__button md-logo" aria-label="Multimodal Memory LLM and AI Agent" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Multimodal Memory LLM and AI Agent
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Tool Calling and Agents
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Multimodal Memory LLM and AI Agent" class="md-nav__button md-logo" aria-label="Multimodal Memory LLM and AI Agent" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Multimodal Memory LLM and AI Agent
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Core Modules
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Core Modules
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer Fundamentals
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Tool Calling and Agents
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Tool Calling and Agents
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    <span class="md-ellipsis">
      Table of Contents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-to-llm-agents" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction to LLM Agents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#foundations-of-tool-calling" class="md-nav__link">
    <span class="md-ellipsis">
      Foundations of Tool Calling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Foundations of Tool Calling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#research-papers" class="md-nav__link">
    <span class="md-ellipsis">
      Research Papers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Approaches
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Basic Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#function-calling" class="md-nav__link">
    <span class="md-ellipsis">
      Function Calling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#react-reasoning-and-acting" class="md-nav__link">
    <span class="md-ellipsis">
      ReAct: Reasoning and Acting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#react-vs-function-calling-a-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      ReAct vs Function Calling: A Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tool-augmented-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Tool-Augmented LLMs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Approaches
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#langgraph-a-graph-based-agent-framework" class="md-nav__link">
    <span class="md-ellipsis">
      LangGraph: A Graph-Based Agent Framework
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-context-protocol-mcp" class="md-nav__link">
    <span class="md-ellipsis">
      Model Context Protocol (MCP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agentic-workflows" class="md-nav__link">
    <span class="md-ellipsis">
      Agentic Workflows
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agentic-workflows-vs-react-a-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Agentic Workflows vs ReAct: A Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-agent-systems" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Agent Systems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tool-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Tool Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#framework-implementations" class="md-nav__link">
    <span class="md-ellipsis">
      Framework Implementations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Framework Implementations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openai" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openai-responses-api-vs-chat-completions-vs-assistants" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI Responses API vs. Chat Completions vs. Assistants
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langchain" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llamaindex" class="md-nav__link">
    <span class="md-ellipsis">
      LlamaIndex
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#semantic-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Kernel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autogen" class="md-nav__link">
    <span class="md-ellipsis">
      AutoGen
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crewai" class="md-nav__link">
    <span class="md-ellipsis">
      CrewAI
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#technical-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Technical Deep Dive
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Technical Deep Dive">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#function-calling-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Function Calling Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#react-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      ReAct Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mcp-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      MCP Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation-and-benchmarks" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation and Benchmarks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Evaluation and Benchmarks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#agentbench" class="md-nav__link">
    <span class="md-ellipsis">
      AgentBench
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbench" class="md-nav__link">
    <span class="md-ellipsis">
      ToolBench
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#react-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      ReAct Benchmark
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Key Metrics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#future-directions" class="md-nav__link">
    <span class="md-ellipsis">
      Future Directions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Future Directions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multimodal-agents" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal Agents
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agentic-memory" class="md-nav__link">
    <span class="md-ellipsis">
      Agentic Memory
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autonomous-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Autonomous Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-agent-ecosystems" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Agent Ecosystems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alignment-and-safety" class="md-nav__link">
    <span class="md-ellipsis">
      Alignment and Safety
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../embeddings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multimodal Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLM Frameworks and Architectures
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../memory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Memory Systems
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Advanced Topics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Advanced Topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers_advanced/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced Transformer Techniques
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference_optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inference Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Notebooks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Notebooks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/memory_example/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Memory Example
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    <span class="md-ellipsis">
      Table of Contents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-to-llm-agents" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction to LLM Agents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#foundations-of-tool-calling" class="md-nav__link">
    <span class="md-ellipsis">
      Foundations of Tool Calling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Foundations of Tool Calling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#research-papers" class="md-nav__link">
    <span class="md-ellipsis">
      Research Papers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Approaches
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Basic Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#function-calling" class="md-nav__link">
    <span class="md-ellipsis">
      Function Calling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#react-reasoning-and-acting" class="md-nav__link">
    <span class="md-ellipsis">
      ReAct: Reasoning and Acting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#react-vs-function-calling-a-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      ReAct vs Function Calling: A Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tool-augmented-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Tool-Augmented LLMs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Approaches
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#langgraph-a-graph-based-agent-framework" class="md-nav__link">
    <span class="md-ellipsis">
      LangGraph: A Graph-Based Agent Framework
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-context-protocol-mcp" class="md-nav__link">
    <span class="md-ellipsis">
      Model Context Protocol (MCP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agentic-workflows" class="md-nav__link">
    <span class="md-ellipsis">
      Agentic Workflows
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agentic-workflows-vs-react-a-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      Agentic Workflows vs ReAct: A Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-agent-systems" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Agent Systems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tool-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Tool Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#framework-implementations" class="md-nav__link">
    <span class="md-ellipsis">
      Framework Implementations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Framework Implementations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openai" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openai-responses-api-vs-chat-completions-vs-assistants" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI Responses API vs. Chat Completions vs. Assistants
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langchain" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llamaindex" class="md-nav__link">
    <span class="md-ellipsis">
      LlamaIndex
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#semantic-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      Semantic Kernel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autogen" class="md-nav__link">
    <span class="md-ellipsis">
      AutoGen
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crewai" class="md-nav__link">
    <span class="md-ellipsis">
      CrewAI
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#technical-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Technical Deep Dive
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Technical Deep Dive">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#function-calling-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Function Calling Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#react-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      ReAct Implementation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mcp-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      MCP Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation-and-benchmarks" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation and Benchmarks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Evaluation and Benchmarks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#agentbench" class="md-nav__link">
    <span class="md-ellipsis">
      AgentBench
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbench" class="md-nav__link">
    <span class="md-ellipsis">
      ToolBench
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#react-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      ReAct Benchmark
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Key Metrics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#future-directions" class="md-nav__link">
    <span class="md-ellipsis">
      Future Directions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Future Directions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multimodal-agents" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal Agents
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agentic-memory" class="md-nav__link">
    <span class="md-ellipsis">
      Agentic Memory
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autonomous-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Autonomous Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-agent-ecosystems" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Agent Ecosystems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alignment-and-safety" class="md-nav__link">
    <span class="md-ellipsis">
      Alignment and Safety
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="tool-calling-and-agent-capabilities-for-llms">Tool Calling and Agent Capabilities for LLMs</h1>
<p>This document provides a comprehensive overview of tool calling and agent capabilities for Large Language Models (LLMs), covering basic approaches, research foundations, advanced techniques, and practical implementations.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#introduction-to-llm-agents">Introduction to LLM Agents</a></li>
<li><a href="#foundations-of-tool-calling">Foundations of Tool Calling</a></li>
<li><a href="#basic-approaches">Basic Approaches</a></li>
<li><a href="#function-calling">Function Calling</a></li>
<li><a href="#react-reasoning-and-acting">ReAct: Reasoning and Acting</a></li>
<li><a href="#tool-augmented-llms">Tool-Augmented LLMs</a></li>
<li><a href="#advanced-approaches">Advanced Approaches</a></li>
<li><a href="#model-context-protocol-mcp">Model Context Protocol (MCP)</a></li>
<li><a href="#agentic-workflows">Agentic Workflows</a></li>
<li><a href="#multi-agent-systems">Multi-Agent Systems</a></li>
<li><a href="#tool-learning">Tool Learning</a></li>
<li><a href="#framework-implementations">Framework Implementations</a></li>
<li><a href="#openai">OpenAI</a></li>
<li><a href="#langchain">LangChain</a></li>
<li><a href="#llamaindex">LlamaIndex</a></li>
<li><a href="#semantic-kernel">Semantic Kernel</a></li>
<li><a href="#autogen">AutoGen</a></li>
<li><a href="#crewai">CrewAI</a></li>
<li><a href="#technical-deep-dive">Technical Deep Dive</a></li>
<li><a href="#function-calling-implementation">Function Calling Implementation</a></li>
<li><a href="#mcp-implementation">MCP Implementation</a></li>
<li><a href="#evaluation-and-benchmarks">Evaluation and Benchmarks</a></li>
<li><a href="#future-directions">Future Directions</a></li>
<li><a href="#references">References</a></li>
</ul>
<h2 id="introduction-to-llm-agents">Introduction to LLM Agents</h2>
<p>LLM Agents are systems that combine the reasoning capabilities of large language models with the ability to interact with external tools and environments. This combination enables LLMs to go beyond text generation and perform actions in the real world or digital environments.</p>
<p>An LLM agent typically consists of:</p>
<ol>
<li><strong>A large language model</strong>: Provides reasoning, planning, and natural language understanding</li>
<li><strong>Tool interfaces</strong>: Allow the LLM to interact with external systems</li>
<li><strong>Orchestration layer</strong>: Manages the flow between the LLM and tools</li>
<li><strong>Memory systems</strong>: Store context, history, and intermediate results</li>
<li><strong>Planning mechanisms</strong>: Enable multi-step reasoning and task decomposition</li>
</ol>
<h2 id="foundations-of-tool-calling">Foundations of Tool Calling</h2>
<h3 id="research-papers">Research Papers</h3>
<ol>
<li><strong>"Language Models as Zero-Shot Planners"</strong> (2022)</li>
<li><a href="https://arxiv.org/abs/2201.07207">Paper Link</a></li>
<li>Introduced the concept of using LLMs for planning tasks without specific training</li>
<li>
<p>Demonstrated that LLMs can break down complex tasks into steps</p>
</li>
<li>
<p><strong>"ReAct: Synergizing Reasoning and Acting in Language Models"</strong> (2023)</p>
</li>
<li><a href="https://arxiv.org/abs/2210.03629">Paper Link</a></li>
<li>Combined reasoning traces with actions in a synergistic framework</li>
<li>
<p>Showed improved performance on tasks requiring both reasoning and tool use</p>
</li>
<li>
<p><strong>"ToolFormer: Language Models Can Teach Themselves to Use Tools"</strong> (2023)</p>
</li>
<li><a href="https://arxiv.org/abs/2302.04761">Paper Link</a></li>
<li>Demonstrated self-supervised learning of tool use by LLMs</li>
<li>
<p>Introduced a method for LLMs to learn when and how to call external APIs</p>
</li>
<li>
<p><strong>"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face"</strong> (2023)</p>
</li>
<li><a href="https://arxiv.org/abs/2303.17580">Paper Link</a></li>
<li>Proposed a framework for LLMs to orchestrate specialized AI models</li>
<li>
<p>Demonstrated task planning, model selection, and execution coordination</p>
</li>
<li>
<p><strong>"Gorilla: Large Language Model Connected with Massive APIs"</strong> (2023)</p>
</li>
<li><a href="https://arxiv.org/abs/2305.15334">Paper Link</a></li>
<li>Focused on teaching LLMs to use APIs accurately</li>
<li>Introduced techniques for improving API call precision</li>
</ol>
<h2 id="basic-approaches">Basic Approaches</h2>
<h3 id="function-calling">Function Calling</h3>
<p><strong>Reference Links:</strong>
- <a href="https://platform.openai.com/docs/guides/function-calling">OpenAI Function Calling Documentation</a>
- <a href="https://docs.anthropic.com/claude/docs/tool-use">Anthropic Tool Use Documentation</a></p>
<p><strong>Motivation:</strong> Enable LLMs to interact with external systems in a structured way.</p>
<p><strong>Implementation:</strong> Function calling allows LLMs to generate structured JSON outputs that conform to predefined function schemas. The basic workflow is:</p>
<ol>
<li>Define functions with JSON Schema</li>
<li>Send the function definitions to the LLM along with a prompt</li>
<li>The LLM decides whether to call a function and generates the appropriate arguments</li>
<li>The application executes the function with the provided arguments</li>
<li>Function results are sent back to the LLM for further processing</li>
</ol>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Define a weather function</span>
<span class="n">weather_function</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;get_weather&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Get the current weather in a location&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;location&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The city and state, e.g., San Francisco, CA&quot;</span>
                <span class="p">},</span>
                <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;enum&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;celsius&quot;</span><span class="p">,</span> <span class="s2">&quot;fahrenheit&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The temperature unit&quot;</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;location&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Call the model with the function definition</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s the weather like in Boston?&quot;</span><span class="p">}],</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">weather_function</span><span class="p">],</span>
    <span class="n">tool_choice</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
<span class="p">)</span>

<span class="c1"># Extract and execute the function call</span>
<span class="n">tool_calls</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">tool_calls</span>
<span class="k">if</span> <span class="n">tool_calls</span><span class="p">:</span>
    <span class="c1"># Execute the function</span>
    <span class="n">function_name</span> <span class="o">=</span> <span class="n">tool_calls</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span>
    <span class="n">function_args</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">tool_calls</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="p">)</span>

    <span class="c1"># Call your actual weather API here</span>
    <span class="n">weather_data</span> <span class="o">=</span> <span class="n">get_weather_data</span><span class="p">(</span><span class="n">function_args</span><span class="p">[</span><span class="s2">&quot;location&quot;</span><span class="p">],</span> <span class="n">function_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;unit&quot;</span><span class="p">,</span> <span class="s2">&quot;celsius&quot;</span><span class="p">))</span>

    <span class="c1"># Send the results back to the model</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s the weather like in Boston?&quot;</span><span class="p">},</span>
        <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">,</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;tool&quot;</span><span class="p">,</span>
            <span class="s2">&quot;tool_call_id&quot;</span><span class="p">:</span> <span class="n">tool_calls</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">function_name</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">weather_data</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">]</span>

    <span class="n">final_response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">final_response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</code></pre></div>
<p><strong>Popularity:</strong> Very high. Function calling is supported by most major LLM providers and frameworks.</p>
<p><strong>Drawbacks:</strong>
- Limited to predefined function schemas
- Requires careful schema design to ensure proper use
- May struggle with complex, multi-step reasoning</p>
<h3 id="react-reasoning-and-acting">ReAct: Reasoning and Acting</h3>
<p><strong>Reference Links:</strong>
- <a href="https://arxiv.org/abs/2210.03629">ReAct Paper</a>
- <a href="https://python.langchain.com/docs/modules/agents/agent_types/react">LangChain ReAct Implementation</a></p>
<p><strong>Motivation:</strong> Combine reasoning traces with actions to improve performance on tasks requiring both thinking and doing.</p>
<p><strong>Implementation:</strong> ReAct prompts the LLM to generate both reasoning traces and actions in an interleaved manner:</p>
<ol>
<li><strong>Thought</strong>: The LLM reasons about the current state and what to do next</li>
<li><strong>Action</strong>: The LLM selects a tool and provides arguments</li>
<li><strong>Observation</strong>: The environment returns the result of the action</li>
<li>This cycle repeats until the task is complete</li>
</ol>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_react_agent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">AgentExecutor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tool</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="c1"># Define tools</span>
<span class="n">tools</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Tool</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Search&quot;</span><span class="p">,</span>
        <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">query</span><span class="p">:</span> <span class="n">search_engine</span><span class="p">(</span><span class="n">query</span><span class="p">),</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Search the web for information&quot;</span>
    <span class="p">),</span>
    <span class="n">Tool</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Calculator&quot;</span><span class="p">,</span>
        <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">expression</span><span class="p">:</span> <span class="nb">eval</span><span class="p">(</span><span class="n">expression</span><span class="p">),</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Evaluate mathematical expressions&quot;</span>
    <span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Create the agent</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">)</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">tools</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">REACT_PROMPT</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">AgentExecutor</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="n">tools</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Run the agent</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the population of France divided by the square root of 2?&quot;</span><span class="p">})</span>
</code></pre></div>
<p><strong>Popularity:</strong> High. ReAct is widely implemented in agent frameworks and has become a standard approach.</p>
<p><strong>Drawbacks:</strong>
- Can be verbose and token-intensive
- May struggle with very complex reasoning chains
- Requires careful prompt engineering</p>
<h3 id="react-vs-function-calling-a-comparison">ReAct vs Function Calling: A Comparison</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>ReAct</th>
<th>Function Calling</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Format</strong></td>
<td>Generates reasoning traces and actions in natural language</td>
<td>Produces structured JSON outputs conforming to predefined schemas</td>
</tr>
<tr>
<td><strong>Reasoning Visibility</strong></td>
<td>Explicit reasoning is visible in the output</td>
<td>Reasoning happens internally and isn't visible</td>
</tr>
<tr>
<td><strong>Structure</strong></td>
<td>Less structured, more flexible</td>
<td>Highly structured, less flexible</td>
</tr>
<tr>
<td><strong>Token Usage</strong></td>
<td>Higher (due to reasoning traces)</td>
<td>Lower (only essential function parameters)</td>
</tr>
<tr>
<td><strong>Error Handling</strong></td>
<td>Can self-correct through reasoning</td>
<td>Requires explicit error handling in the application</td>
</tr>
<tr>
<td><strong>Tool Discovery</strong></td>
<td>Can discover tools through exploration</td>
<td>Limited to predefined function schemas</td>
</tr>
<tr>
<td><strong>Implementation Complexity</strong></td>
<td>Requires more prompt engineering</td>
<td>Requires careful schema design</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Complex reasoning tasks, exploration</td>
<td>Structured API interactions, precise tool use</td>
</tr>
</tbody>
</table>
<h3 id="tool-augmented-llms">Tool-Augmented LLMs</h3>
<p><strong>Reference Links:</strong>
- <a href="https://arxiv.org/abs/2302.04761">ToolFormer Paper</a>
- <a href="https://arxiv.org/abs/2305.15334">Gorilla Paper</a></p>
<p><strong>Motivation:</strong> Train LLMs to use tools more effectively through specialized fine-tuning.</p>
<p><strong>Implementation:</strong> Tool-augmented LLMs are specifically trained or fine-tuned to use external tools:</p>
<ol>
<li>Create a dataset of tool usage examples</li>
<li>Fine-tune the LLM on this dataset</li>
<li>The resulting model learns when and how to use tools appropriately</li>
</ol>
<p><strong>Example:</strong></p>
<p>Gorilla's approach to API calling:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">gorilla</span><span class="w"> </span><span class="kn">import</span> <span class="n">GorillaChatCompletion</span>

<span class="c1"># Define the API you want to use</span>
<span class="n">api_schema</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;text_to_speech&quot;</span><span class="p">,</span>
    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Convert text to speech audio&quot;</span><span class="p">,</span>
    <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;The text to convert to speech&quot;</span><span class="p">,</span>
        <span class="s2">&quot;voice&quot;</span><span class="p">:</span> <span class="s2">&quot;The voice to use (male, female)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;speed&quot;</span><span class="p">:</span> <span class="s2">&quot;The speed of the speech (0.5-2.0)&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Call Gorilla with the API schema</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">GorillaChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gorilla-mpt-7b&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Convert &#39;Hello world&#39; to speech using a female voice&quot;</span><span class="p">}],</span>
    <span class="n">apis</span><span class="o">=</span><span class="p">[</span><span class="n">api_schema</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># The response will contain a properly formatted API call</span>
<span class="n">api_call</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
<span class="nb">print</span><span class="p">(</span><span class="n">api_call</span><span class="p">)</span>
<span class="c1"># Output: text_to_speech(text=&quot;Hello world&quot;, voice=&quot;female&quot;, speed=1.0)</span>
</code></pre></div>
<p><strong>Popularity:</strong> Medium. Tool-augmented LLMs are growing in popularity but require specialized models.</p>
<p><strong>Drawbacks:</strong>
- Requires specific fine-tuned models
- Less flexible than general-purpose approaches
- May not generalize well to new tools</p>
<h2 id="advanced-approaches">Advanced Approaches</h2>
<h3 id="langgraph-a-graph-based-agent-framework">LangGraph: A Graph-Based Agent Framework</h3>
<p><strong>Reference Links:</strong>
- <a href="https://python.langchain.com/docs/langgraph">LangGraph Documentation</a>
- <a href="https://github.com/langchain-ai/langgraph">LangGraph GitHub Repository</a></p>
<p><strong>Motivation:</strong> Enable the creation of stateful, multi-step agent workflows with explicit control flow and state management.</p>
<p><strong>Implementation:</strong> LangGraph extends LangChain's agent capabilities with a graph-based approach:</p>
<ol>
<li><strong>State Management</strong>: Explicit state objects that persist across steps</li>
<li><strong>Graph-Based Workflows</strong>: Define agent behavior as a directed graph of nodes and edges</li>
<li><strong>Conditional Branching</strong>: Dynamic decision-making based on agent outputs</li>
<li><strong>Cyclical Processing</strong>: Support for loops and recursive reasoning</li>
<li><strong>Human-in-the-Loop</strong>: Seamless integration of human feedback</li>
</ol>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">END</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">HumanMessage</span><span class="p">,</span> <span class="n">AIMessage</span>

<span class="c1"># Define the state schema</span>
<span class="k">class</span><span class="w"> </span><span class="nc">AgentState</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
    <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">HumanMessage</span><span class="p">,</span> <span class="n">AIMessage</span><span class="p">]]</span>
    <span class="n">next_step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>

<span class="c1"># Create a graph</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">AgentState</span><span class="p">)</span>

<span class="c1"># Define nodes</span>
<span class="k">def</span><span class="w"> </span><span class="nf">generate_response</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span> <span class="o">+</span> <span class="p">[</span><span class="n">response</span><span class="p">]}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">decide_next_step</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
        <span class="n">messages</span> <span class="o">+</span> <span class="p">[</span>
            <span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;What should be the next step? Options: [research, calculate, finish]&quot;</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;next_step&quot;</span><span class="p">:</span> <span class="n">decision</span><span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">research</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
    <span class="c1"># Implement research functionality</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;Research completed.&quot;</span><span class="p">)]}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">calculate</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
    <span class="c1"># Implement calculation functionality</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;messages&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;Calculation completed.&quot;</span><span class="p">)]}</span>

<span class="c1"># Add nodes to the graph</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;generate_response&quot;</span><span class="p">,</span> <span class="n">generate_response</span><span class="p">)</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;decide_next_step&quot;</span><span class="p">,</span> <span class="n">decide_next_step</span><span class="p">)</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;research&quot;</span><span class="p">,</span> <span class="n">research</span><span class="p">)</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">&quot;calculate&quot;</span><span class="p">,</span> <span class="n">calculate</span><span class="p">)</span>

<span class="c1"># Define edges</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;generate_response&quot;</span><span class="p">,</span> <span class="s2">&quot;decide_next_step&quot;</span><span class="p">)</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add_conditional_edges</span><span class="p">(</span>
    <span class="s2">&quot;decide_next_step&quot;</span><span class="p">,</span>
    <span class="k">lambda</span> <span class="n">state</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;next_step&quot;</span><span class="p">],</span>
    <span class="p">{</span>
        <span class="s2">&quot;research&quot;</span><span class="p">:</span> <span class="s2">&quot;research&quot;</span><span class="p">,</span>
        <span class="s2">&quot;calculate&quot;</span><span class="p">:</span> <span class="s2">&quot;calculate&quot;</span><span class="p">,</span>
        <span class="s2">&quot;finish&quot;</span><span class="p">:</span> <span class="n">END</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;research&quot;</span><span class="p">,</span> <span class="s2">&quot;generate_response&quot;</span><span class="p">)</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">&quot;calculate&quot;</span><span class="p">,</span> <span class="s2">&quot;generate_response&quot;</span><span class="p">)</span>

<span class="c1"># Compile the graph</span>
<span class="n">agent_executor</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>

<span class="c1"># Run the agent</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">agent_executor</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;Analyze the impact of AI on healthcare.&quot;</span><span class="p">)]})</span>
</code></pre></div>
<p><strong>Key Differences from Traditional Agents:</strong></p>
<ol>
<li>
<p><strong>Explicit vs. Implicit Control Flow</strong>: LangGraph makes the agent's decision-making process explicit through graph structure, while traditional agents rely on the LLM to manage control flow implicitly.</p>
</li>
<li>
<p><strong>State Management</strong>: LangGraph provides robust state management, allowing complex state to persist across steps, whereas traditional agents often have limited state persistence.</p>
</li>
<li>
<p><strong>Composability</strong>: LangGraph enables easy composition of multiple agents and tools into complex workflows, making it more suitable for enterprise applications.</p>
</li>
<li>
<p><strong>Debugging and Visualization</strong>: The graph structure makes it easier to debug and visualize agent behavior compared to traditional black-box agents.</p>
</li>
<li>
<p><strong>Deterministic Routing</strong>: LangGraph allows for deterministic routing between steps based on explicit conditions, reducing the unpredictability of LLM-based control flow.</p>
</li>
</ol>
<p><strong>Popularity:</strong> Medium but rapidly growing. LangGraph is becoming the preferred approach for complex agent workflows in the LangChain ecosystem.</p>
<p><strong>Drawbacks:</strong>
- Higher complexity compared to simpler agent frameworks
- Steeper learning curve
- Requires more boilerplate code
- Still evolving with frequent API changes</p>
<h3 id="model-context-protocol-mcp">Model Context Protocol (MCP)</h3>
<p><strong>Reference Links:</strong>
- <a href="https://github.com/lkk688/llm-multimem-agent/tree/main/llm-multi-core/mcp">Model Context Protocol (MCP)</a></p>
<p><strong>Motivation:</strong> Standardize the way context, tools, and memory are injected into LLM prompts.</p>
<p><strong>Implementation:</strong> MCP provides a structured JSON-based protocol for context injection:</p>
<ol>
<li>Define a context bundle with various components (memory, tools, etc.)</li>
<li>Send the bundle to an MCP server</li>
<li>The server processes the bundle and constructs an optimized prompt</li>
<li>The prompt is sent to the LLM for processing</li>
</ol>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Send a request to the MCP server</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="n">context_bundle</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;user_input&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s the weather like in Paris?&quot;</span><span class="p">,</span>
    <span class="s2">&quot;memory&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;enable&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;k&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>  <span class="c1"># Number of memories to retrieve</span>
        <span class="s2">&quot;filter&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;conversation&quot;</span><span class="p">}</span>
    <span class="p">},</span>
    <span class="s2">&quot;tools&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;get_weather&quot;</span><span class="p">,</span>
            <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Get weather information for a location&quot;</span><span class="p">,</span>
            <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;location&quot;</span><span class="p">:</span> <span class="s2">&quot;The city name&quot;</span><span class="p">,</span>
                <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="s2">&quot;Temperature unit (celsius/fahrenheit)&quot;</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s2">&quot;http://localhost:8000/mcp/context&quot;</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">context_bundle</span><span class="p">)</span>
<span class="n">enhanced_prompt</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span>

<span class="c1"># Send the enhanced prompt to an LLM</span>
<span class="c1"># ...</span>
</code></pre></div>
<p><strong>Popularity:</strong> Low to Medium. MCP is a newer approach but gaining traction for standardizing context injection.</p>
<p><strong>Drawbacks:</strong>
- Requires additional server infrastructure
- Less standardized than other approaches
- May add latency to the request pipeline</p>
<h3 id="agentic-workflows">Agentic Workflows</h3>
<p><strong>Reference Links:</strong>
- <a href="https://python.langchain.com/docs/modules/agents/">LangChain Agents</a>
- <a href="https://github.com/yoheinakajima/babyagi">BabyAGI</a>
- <a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a></p>
<p><strong>Motivation:</strong> Enable LLMs to perform complex, multi-step tasks through autonomous planning and execution.</p>
<p><strong>Implementation:</strong> Agentic workflows combine planning, tool use, and memory:</p>
<ol>
<li>The LLM creates a plan for solving a complex task</li>
<li>It breaks the plan into subtasks</li>
<li>For each subtask, it selects and uses appropriate tools</li>
<li>Results are stored in memory and used to inform subsequent steps</li>
<li>The process continues until the task is complete</li>
</ol>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">initialize_agent</span><span class="p">,</span> <span class="n">Tool</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">AgentType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.memory</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConversationBufferMemory</span>

<span class="c1"># Define tools</span>
<span class="n">tools</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Tool</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Search&quot;</span><span class="p">,</span>
        <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">query</span><span class="p">:</span> <span class="n">search_engine</span><span class="p">(</span><span class="n">query</span><span class="p">),</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Search the web for information&quot;</span>
    <span class="p">),</span>
    <span class="n">Tool</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Calculator&quot;</span><span class="p">,</span>
        <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">expression</span><span class="p">:</span> <span class="nb">eval</span><span class="p">(</span><span class="n">expression</span><span class="p">),</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Evaluate mathematical expressions&quot;</span>
    <span class="p">),</span>
    <span class="n">Tool</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;WeatherAPI&quot;</span><span class="p">,</span>
        <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">location</span><span class="p">:</span> <span class="n">get_weather</span><span class="p">(</span><span class="n">location</span><span class="p">),</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Get weather information for a location&quot;</span>
    <span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Set up memory</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">(</span><span class="n">memory_key</span><span class="o">=</span><span class="s2">&quot;chat_history&quot;</span><span class="p">)</span>

<span class="c1"># Create the agent</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">initialize_agent</span><span class="p">(</span>
    <span class="n">tools</span><span class="p">,</span> 
    <span class="n">llm</span><span class="p">,</span> 
    <span class="n">agent</span><span class="o">=</span><span class="n">AgentType</span><span class="o">.</span><span class="n">CHAT_CONVERSATIONAL_REACT_DESCRIPTION</span><span class="p">,</span>
    <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="c1">#CHAT_CONVERSATIONAL_REACT_DESCRIPTION: this is an extended version of ReAct that supports conversation and memory, making it suitable for the more complex workflows of Agentic Workflows. It uses the Thought-Action-Observation cycle but adds memory persistence and conversational abilities.</span>

<span class="c1"># Run the agent on a complex task</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="s2">&quot;Plan a day trip to Paris. I need to know the weather, top 3 attractions, &quot;</span>
    <span class="s2">&quot;and calculate a budget of 200 euros divided among these activities.&quot;</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Popularity:</strong> High. Agentic workflows are widely used for complex task automation.</p>
<p><strong>Drawbacks:</strong>
- Can be computationally expensive
- May struggle with very long-horizon planning
- Requires careful tool design and error handling</p>
<p><strong>Implementation Links:</strong>
- <a href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/agent.py">LangChain Thought-Action-Observation Implementation</a>
- <a href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/base.py">ReAct Agent Loop in LangChain</a>
- <a href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/agent_executor.py">Agent Executor Implementation</a></p>
<h3 id="agentic-workflows-vs-react-a-comparison">Agentic Workflows vs ReAct: A Comparison</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>ReAct</th>
<th>Agentic Workflows</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Scope</strong></td>
<td>Focused on single-task reasoning and execution</td>
<td>Designed for complex, multi-step tasks with planning</td>
</tr>
<tr>
<td><strong>Planning</strong></td>
<td>Limited planning, focuses on immediate next steps</td>
<td>Explicit planning phase to break down complex tasks</td>
</tr>
<tr>
<td><strong>Memory</strong></td>
<td>Typically stateless or with simple memory</td>
<td>Integrated memory to track progress across subtasks</td>
</tr>
<tr>
<td><strong>Autonomy</strong></td>
<td>Semi-autonomous with human oversight</td>
<td>Higher autonomy for extended task sequences</td>
</tr>
<tr>
<td><strong>Complexity</strong></td>
<td>Better for focused, well-defined tasks</td>
<td>Better for open-ended, complex problem-solving</td>
</tr>
<tr>
<td><strong>Structure</strong></td>
<td>Rigid Thought-Action-Observation cycle</td>
<td>Flexible workflow with planning, execution, and reflection phases</td>
</tr>
<tr>
<td><strong>Task Decomposition</strong></td>
<td>Limited task decomposition</td>
<td>Explicit task decomposition into subtasks</td>
</tr>
<tr>
<td><strong>Resource Usage</strong></td>
<td>Moderate token usage</td>
<td>Higher token usage due to planning overhead</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Single queries requiring reasoning and tool use</td>
<td>Complex tasks requiring multiple steps and planning</td>
</tr>
</tbody>
</table>
<h3 id="multi-agent-systems">Multi-Agent Systems</h3>
<p><strong>Reference Links:</strong>
- <a href="https://microsoft.github.io/autogen/">AutoGen</a>
- <a href="https://github.com/joaomdmoura/crewAI">CrewAI</a>
- <a href="https://arxiv.org/abs/2304.03442">Multi-Agent Collaboration Paper</a></p>
<p><strong>Motivation:</strong> Distribute complex tasks among specialized agents for more effective problem-solving.</p>
<p><strong>Implementation:</strong> Multi-agent systems involve multiple LLM agents with different roles:</p>
<ol>
<li>Define specialized agents with different roles and capabilities</li>
<li>Create a communication protocol between agents</li>
<li>Implement a coordination mechanism (e.g., a manager agent)</li>
<li>Allow agents to collaborate on complex tasks</li>
</ol>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">autogen</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssistantAgent</span><span class="p">,</span> <span class="n">UserProxyAgent</span><span class="p">,</span> <span class="n">config_list_from_json</span>

<span class="c1"># Configure agents</span>
<span class="n">config_list</span> <span class="o">=</span> <span class="n">config_list_from_json</span><span class="p">(</span><span class="s2">&quot;OAI_CONFIG_LIST&quot;</span><span class="p">)</span>

<span class="c1"># Create a research agent</span>
<span class="n">researcher</span> <span class="o">=</span> <span class="n">AssistantAgent</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Researcher&quot;</span><span class="p">,</span>
    <span class="n">llm_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;config_list&quot;</span><span class="p">:</span> <span class="n">config_list</span><span class="p">},</span>
    <span class="n">system_message</span><span class="o">=</span><span class="s2">&quot;You are a research expert. Find and analyze information on topics.&quot;</span>
<span class="p">)</span>

<span class="c1"># Create a coding agent</span>
<span class="n">coder</span> <span class="o">=</span> <span class="n">AssistantAgent</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Coder&quot;</span><span class="p">,</span>
    <span class="n">llm_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;config_list&quot;</span><span class="p">:</span> <span class="n">config_list</span><span class="p">},</span>
    <span class="n">system_message</span><span class="o">=</span><span class="s2">&quot;You are a Python expert. Write code to solve problems.&quot;</span>
<span class="p">)</span>

<span class="c1"># Create a user proxy agent</span>
<span class="n">user_proxy</span> <span class="o">=</span> <span class="n">UserProxyAgent</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;User&quot;</span><span class="p">,</span>
    <span class="n">human_input_mode</span><span class="o">=</span><span class="s2">&quot;TERMINATE&quot;</span><span class="p">,</span>
    <span class="n">max_consecutive_auto_reply</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">code_execution_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;work_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;coding&quot;</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Start a group chat</span>
<span class="n">user_proxy</span><span class="o">.</span><span class="n">initiate_chat</span><span class="p">(</span>
    <span class="n">researcher</span><span class="p">,</span>
    <span class="n">message</span><span class="o">=</span><span class="s2">&quot;Research the latest machine learning techniques for time series forecasting &quot;</span>
            <span class="s2">&quot;and then have the coder implement a simple example.&quot;</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Popularity:</strong> Medium to High. Multi-agent systems are gaining popularity for complex tasks.</p>
<p><strong>Drawbacks:</strong>
- Complex to set up and manage
- Can be expensive due to multiple LLM calls
- May suffer from coordination issues
- Potential for agents to get stuck in loops</p>
<h3 id="tool-learning">Tool Learning</h3>
<p><strong>Reference Links:</strong>
- <a href="https://arxiv.org/abs/2302.04761">ToolFormer Paper</a>
- <a href="https://arxiv.org/abs/2306.05301">TALM Paper</a></p>
<p><strong>Motivation:</strong> Enable LLMs to learn when and how to use tools through self-supervised learning.</p>
<p><strong>Implementation:</strong> Tool learning involves training LLMs to recognize when tools are needed:</p>
<ol>
<li>Create a dataset of problems and their solutions using tools</li>
<li>Fine-tune the LLM on this dataset</li>
<li>The model learns to identify situations where tools are helpful</li>
<li>It also learns the correct syntax and parameters for tool calls</li>
</ol>
<p><strong>Example:</strong></p>
<p>ToolFormer's approach:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Example of a ToolFormer-generated response with tool calls</span>

<span class="c1"># Input: &quot;What is the capital of France and what&#39;s the current temperature there?&quot;</span>

<span class="c1"># ToolFormer output:</span>
<span class="s2">&quot;The capital of France is Paris. [TOOL:Weather(location=&quot;</span><span class="n">Paris</span><span class="p">,</span> <span class="n">France</span><span class="s2">&quot;)] The current temperature in Paris is 18C.&quot;</span>

<span class="c1"># This output includes a tool call that would be parsed and executed by the system</span>
</code></pre></div>
<p><strong>Popularity:</strong> Medium. Tool learning is an active research area but not yet widely deployed.</p>
<p><strong>Drawbacks:</strong>
- Requires specialized training data
- May not generalize well to new tools
- Less flexible than runtime tool definition approaches</p>
<h2 id="framework-implementations">Framework Implementations</h2>
<h3 id="openai">OpenAI</h3>
<p><strong>Reference Links:</strong>
- <a href="https://platform.openai.com/docs/guides/function-calling">OpenAI Function Calling</a>
- <a href="https://platform.openai.com/docs/assistants/overview">OpenAI Assistants API</a>
- <a href="https://platform.openai.com/docs/guides/responses-vs-chat-completions">OpenAI Responses API</a></p>
<p><strong>Key Features:</strong>
- Native function calling in chat completions API
- Assistants API with built-in tool use
- Responses API combining strengths of both previous APIs
- Support for code interpreter, retrieval, and function calling
- Parallel function calling in newer models
- Server-side state management in Responses and Assistants APIs</p>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

<span class="c1"># Define functions</span>
<span class="n">tools</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
        <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;get_weather&quot;</span><span class="p">,</span>
            <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Get the current weather in a location&quot;</span><span class="p">,</span>
            <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
                <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;location&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The city and state, e.g., San Francisco, CA&quot;</span>
                    <span class="p">},</span>
                    <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;enum&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;celsius&quot;</span><span class="p">,</span> <span class="s2">&quot;fahrenheit&quot;</span><span class="p">],</span>
                        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The temperature unit&quot;</span>
                    <span class="p">}</span>
                <span class="p">},</span>
                <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;location&quot;</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">]</span>

<span class="c1"># Call the model</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s the weather like in Boston and Tokyo?&quot;</span><span class="p">}],</span>
    <span class="n">tools</span><span class="o">=</span><span class="n">tools</span><span class="p">,</span>
    <span class="n">tool_choice</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
<span class="p">)</span>

<span class="c1"># Process tool calls</span>
<span class="n">message</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span>
<span class="n">tool_calls</span> <span class="o">=</span> <span class="n">message</span><span class="o">.</span><span class="n">tool_calls</span>

<span class="k">if</span> <span class="n">tool_calls</span><span class="p">:</span>
    <span class="c1"># Process each tool call</span>
    <span class="n">tool_call_messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">message</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">tool_call</span> <span class="ow">in</span> <span class="n">tool_calls</span><span class="p">:</span>
        <span class="n">function_name</span> <span class="o">=</span> <span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span>
        <span class="n">function_args</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="p">)</span>

        <span class="c1"># Call your actual function here</span>
        <span class="n">function_response</span> <span class="o">=</span> <span class="n">get_weather</span><span class="p">(</span><span class="n">function_args</span><span class="p">[</span><span class="s2">&quot;location&quot;</span><span class="p">],</span> <span class="n">function_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;unit&quot;</span><span class="p">,</span> <span class="s2">&quot;celsius&quot;</span><span class="p">))</span>

        <span class="n">tool_call_messages</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;tool_call_id&quot;</span><span class="p">:</span> <span class="n">tool_call</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;tool&quot;</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">function_name</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">function_response</span><span class="p">)</span>
        <span class="p">})</span>

    <span class="c1"># Get the final response</span>
    <span class="n">second_response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s the weather like in Boston and Tokyo?&quot;</span><span class="p">}]</span> <span class="o">+</span> <span class="n">tool_call_messages</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">second_response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</code></pre></div>
<p><strong>Popularity:</strong> Very high. OpenAI's implementation is widely used and well-documented.</p>
<p><strong>Drawbacks:</strong>
- Requires OpenAI API access
- Can be expensive for complex agent workflows
- Limited to predefined function schemas</p>
<h3 id="openai-responses-api-vs-chat-completions-vs-assistants">OpenAI Responses API vs. Chat Completions vs. Assistants</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Chat Completions API</th>
<th>Assistants API</th>
<th>Responses API</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>State Management</strong></td>
<td>Client-side (must send full conversation history)</td>
<td>Server-side (threads)</td>
<td>Server-side (simpler than Assistants)</td>
</tr>
<tr>
<td><strong>Function/Tool Calling</strong></td>
<td>Basic support</td>
<td>Advanced support</td>
<td>Advanced support with simplified workflow</td>
</tr>
<tr>
<td><strong>Built-in Tools</strong></td>
<td>Limited</td>
<td>Code interpreter, retrieval, function calling</td>
<td>Web search, file search, function calling</td>
</tr>
<tr>
<td><strong>Conversation Flow</strong></td>
<td>Manual orchestration</td>
<td>Complex (threads, messages, runs)</td>
<td>Simplified with previous_response_id</td>
</tr>
<tr>
<td><strong>Implementation Complexity</strong></td>
<td>Higher for complex workflows</td>
<td>Highest</td>
<td>Lowest</td>
</tr>
<tr>
<td><strong>Longevity</strong></td>
<td>Indefinite support promised</td>
<td>Being sunset (2026)</td>
<td>Current focus</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Simple interactions, custom workflows</td>
<td>Complex agents (legacy)</td>
<td>Modern agent development</td>
</tr>
</tbody>
</table>
<p><strong>Responses API Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>

<span class="c1"># Define functions</span>
<span class="n">tools</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;get_weather&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Get the current weather in a location&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;location&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The city and state, e.g., San Francisco, CA&quot;</span>
                <span class="p">},</span>
                <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;enum&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;celsius&quot;</span><span class="p">,</span> <span class="s2">&quot;fahrenheit&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The temperature unit&quot;</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;location&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">]</span>

<span class="c1"># Initial request with function definition</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">,</span>
    <span class="nb">input</span><span class="o">=</span><span class="s2">&quot;What&#39;s the weather like in Boston and Tokyo?&quot;</span><span class="p">,</span>
    <span class="n">tools</span><span class="o">=</span><span class="n">tools</span><span class="p">,</span>
    <span class="n">store</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># Enable server-side state management</span>
<span class="p">)</span>

<span class="c1"># Process tool calls</span>
<span class="k">for</span> <span class="n">tool_call</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">tool_calls</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">tool_call</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;function&quot;</span> <span class="ow">and</span> <span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;get_weather&quot;</span><span class="p">:</span>
        <span class="n">args</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="p">)</span>
        <span class="n">location</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;location&quot;</span><span class="p">]</span>
        <span class="n">unit</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;unit&quot;</span><span class="p">,</span> <span class="s2">&quot;celsius&quot;</span><span class="p">)</span>

        <span class="c1"># Call your actual function here</span>
        <span class="n">weather_data</span> <span class="o">=</span> <span class="n">get_weather</span><span class="p">(</span><span class="n">location</span><span class="p">,</span> <span class="n">unit</span><span class="p">)</span>

        <span class="c1"># Submit tool output back to the model</span>
        <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">tool_outputs</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">response_id</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
            <span class="n">tool_outputs</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;tool_call_id&quot;</span><span class="p">:</span> <span class="n">tool_call</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                    <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">weather_data</span><span class="p">)</span>
                <span class="p">}</span>
            <span class="p">]</span>
        <span class="p">)</span>

<span class="c1"># Get the final response with all tool outputs processed</span>
<span class="n">final_response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">retrieve</span><span class="p">(</span><span class="n">response_id</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">final_response</span><span class="o">.</span><span class="n">output_text</span><span class="p">)</span>

<span class="c1"># Continue the conversation using previous_response_id</span>
<span class="n">follow_up</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">,</span>
    <span class="nb">input</span><span class="o">=</span><span class="s2">&quot;How does that compare to Miami?&quot;</span><span class="p">,</span>
    <span class="n">previous_response_id</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">id</span>  <span class="c1"># Reference previous conversation</span>
<span class="p">)</span>
</code></pre></div>
<h3 id="langchain">LangChain</h3>
<p><strong>Reference Links:</strong>
- <a href="https://python.langchain.com/docs/modules/agents/">LangChain Agents</a>
- <a href="https://python.langchain.com/docs/modules/tools/">LangChain Tools</a></p>
<p><strong>Key Features:</strong>
- Multiple agent types (ReAct, Plan-and-Execute, etc.)
- Extensive tool library
- Memory integration
- Support for various LLM providers
- Agent executors for managing agent-tool interaction</p>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_tools</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">initialize_agent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">AgentType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="c1"># Load tools</span>
<span class="n">tools</span> <span class="o">=</span> <span class="n">load_tools</span><span class="p">([</span><span class="s2">&quot;serpapi&quot;</span><span class="p">,</span> <span class="s2">&quot;llm-math&quot;</span><span class="p">],</span> <span class="n">llm</span><span class="o">=</span><span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># Initialize agent</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">initialize_agent</span><span class="p">(</span>
    <span class="n">tools</span><span class="p">,</span> 
    <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> 
    <span class="n">agent</span><span class="o">=</span><span class="n">AgentType</span><span class="o">.</span><span class="n">ZERO_SHOT_REACT_DESCRIPTION</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># Run the agent</span>
<span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Who is the current US president? What is their age raised to the 0.43 power?&quot;</span><span class="p">)</span>
</code></pre></div>
<p><strong>Popularity:</strong> Very high. LangChain is one of the most popular frameworks for building LLM agents.</p>
<p><strong>Drawbacks:</strong>
- Can be complex to set up for advanced use cases
- Documentation can be challenging to navigate
- Frequent API changes</p>
<h3 id="llamaindex">LlamaIndex</h3>
<p><strong>Reference Links:</strong>
- <a href="https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/">LlamaIndex Agents</a>
- <a href="https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/tools/">LlamaIndex Tools</a></p>
<p><strong>Key Features:</strong>
- Integration with retrieval-augmented generation (RAG)
- Query engines as tools
- OpenAI Assistants API integration
- Function calling support
- Agent executors similar to LangChain</p>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">llama_index.core.tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">FunctionTool</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">llama_index.agent.openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIAgent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">llama_index.core.query_engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">QueryEngine</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">llama_index.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">VectorStoreIndex</span><span class="p">,</span> <span class="n">SimpleDirectoryReader</span>

<span class="c1"># Define a simple tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">multiply</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multiply two integers and return the result.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>

<span class="n">multiply_tool</span> <span class="o">=</span> <span class="n">FunctionTool</span><span class="o">.</span><span class="n">from_defaults</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">multiply</span><span class="p">)</span>

<span class="c1"># Create a RAG query engine</span>
<span class="n">documents</span> <span class="o">=</span> <span class="n">SimpleDirectoryReader</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">VectorStoreIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
<span class="n">query_engine</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">as_query_engine</span><span class="p">()</span>

<span class="c1"># Create an agent with tools</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">OpenAIAgent</span><span class="o">.</span><span class="n">from_tools</span><span class="p">(</span>
    <span class="p">[</span><span class="n">multiply_tool</span><span class="p">,</span> <span class="n">query_engine</span><span class="p">],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># Run the agent</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="s2">&quot;What information is in my documents? Also, what is 123 * 456?&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<p><strong>Popularity:</strong> High. LlamaIndex is popular especially for RAG-based agents.</p>
<p><strong>Drawbacks:</strong>
- More focused on retrieval than general agent capabilities
- Less extensive tool library than LangChain
- Documentation can be sparse for advanced use cases</p>
<h3 id="semantic-kernel">Semantic Kernel</h3>
<p><strong>Reference Links:</strong>
- <a href="https://github.com/microsoft/semantic-kernel">Semantic Kernel</a>
- <a href="https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/KernelSyntaxExamples/Example20_HuggingFace.ipynb">SK Function Calling</a></p>
<p><strong>Key Features:</strong>
- Plugin architecture for tools
- Native .NET and Python support
- Semantic functions and native functions
- Planning capabilities
- Memory integration</p>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">semantic_kernel</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sk</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">semantic_kernel.connectors.ai.open_ai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIChatCompletion</span>

<span class="c1"># Create a kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">sk</span><span class="o">.</span><span class="n">Kernel</span><span class="p">()</span>

<span class="c1"># Add OpenAI service</span>
<span class="n">kernel</span><span class="o">.</span><span class="n">add_chat_service</span><span class="p">(</span><span class="s2">&quot;chat-gpt&quot;</span><span class="p">,</span> <span class="n">OpenAIChatCompletion</span><span class="p">(</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">))</span>

<span class="c1"># Define a native function</span>
<span class="nd">@sk</span><span class="o">.</span><span class="n">kernel_function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_weather</span><span class="p">(</span><span class="n">location</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the weather for a location.&quot;&quot;&quot;</span>
    <span class="c1"># In a real scenario, call a weather API here</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;It&#39;s sunny in </span><span class="si">{</span><span class="n">location</span><span class="si">}</span><span class="s2"> with a temperature of 72F.&quot;</span>

<span class="c1"># Register the function</span>
<span class="n">kernel</span><span class="o">.</span><span class="n">add_function</span><span class="p">(</span><span class="n">get_weather</span><span class="p">)</span>

<span class="c1"># Create a semantic function</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;{{$input}}</span><span class="se">\n\n</span><span class="s2">Answer the user&#39;s question. If you need to know the weather, use the get_weather function.&quot;&quot;&quot;</span>
<span class="n">function</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">create_semantic_function</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># Run the function</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">function</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;What&#39;s the weather like in Seattle?&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div>
<p><strong>Popularity:</strong> Medium. Semantic Kernel is growing in popularity, especially in Microsoft ecosystem.</p>
<p><strong>Drawbacks:</strong>
- Less mature than LangChain or OpenAI's solutions
- Smaller community and fewer examples
- Documentation can be technical and dense</p>
<h3 id="autogen">AutoGen</h3>
<p><strong>Reference Links:</strong>
- <a href="https://microsoft.github.io/autogen/">AutoGen</a>
- <a href="https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat">AutoGen Multi-Agent Collaboration</a></p>
<p><strong>Key Features:</strong>
- Multi-agent conversation framework
- Customizable agent roles and capabilities
- Code generation and execution
- Human-in-the-loop interactions
- Conversational memory</p>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">autogen</span><span class="w"> </span><span class="kn">import</span> <span class="n">AssistantAgent</span><span class="p">,</span> <span class="n">UserProxyAgent</span><span class="p">,</span> <span class="n">config_list_from_json</span>

<span class="c1"># Load LLM configuration</span>
<span class="n">config_list</span> <span class="o">=</span> <span class="n">config_list_from_json</span><span class="p">(</span><span class="s2">&quot;OAI_CONFIG_LIST&quot;</span><span class="p">)</span>

<span class="c1"># Create an assistant agent</span>
<span class="n">assistant</span> <span class="o">=</span> <span class="n">AssistantAgent</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Assistant&quot;</span><span class="p">,</span>
    <span class="n">llm_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;config_list&quot;</span><span class="p">:</span> <span class="n">config_list</span><span class="p">},</span>
    <span class="n">system_message</span><span class="o">=</span><span class="s2">&quot;You are a helpful AI assistant.&quot;</span>
<span class="p">)</span>

<span class="c1"># Create a user proxy agent with code execution capability</span>
<span class="n">user_proxy</span> <span class="o">=</span> <span class="n">UserProxyAgent</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;User&quot;</span><span class="p">,</span>
    <span class="n">human_input_mode</span><span class="o">=</span><span class="s2">&quot;TERMINATE&quot;</span><span class="p">,</span>
    <span class="n">code_execution_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;work_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;coding&quot;</span><span class="p">,</span> <span class="s2">&quot;use_docker&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Start a conversation</span>
<span class="n">user_proxy</span><span class="o">.</span><span class="n">initiate_chat</span><span class="p">(</span>
    <span class="n">assistant</span><span class="p">,</span>
    <span class="n">message</span><span class="o">=</span><span class="s2">&quot;Create a Python function to calculate the Fibonacci sequence up to n terms.&quot;</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Popularity:</strong> Medium and growing. AutoGen is gaining traction for multi-agent systems.</p>
<p><strong>Drawbacks:</strong>
- Steeper learning curve than some alternatives
- More complex to set up
- Less extensive documentation and examples</p>
<h3 id="crewai">CrewAI</h3>
<p><strong>Reference Links:</strong>
- <a href="https://github.com/joaomdmoura/crewAI">CrewAI</a>
- <a href="https://docs.crewai.com/">CrewAI Documentation</a></p>
<p><strong>Key Features:</strong>
- Role-based agent framework
- Process-oriented workflows
- Task delegation and management
- Agent collaboration patterns
- Human-in-the-loop capabilities</p>
<p><strong>Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">crewai</span><span class="w"> </span><span class="kn">import</span> <span class="n">Agent</span><span class="p">,</span> <span class="n">Task</span><span class="p">,</span> <span class="n">Crew</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">crewai.tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">SerperDevTool</span>

<span class="c1"># Create a search tool</span>
<span class="n">search_tool</span> <span class="o">=</span> <span class="n">SerperDevTool</span><span class="p">()</span>

<span class="c1"># Create agents with specific roles</span>
<span class="n">researcher</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">role</span><span class="o">=</span><span class="s2">&quot;Senior Research Analyst&quot;</span><span class="p">,</span>
    <span class="n">goal</span><span class="o">=</span><span class="s2">&quot;Uncover cutting-edge developments in AI&quot;</span><span class="p">,</span>
    <span class="n">backstory</span><span class="o">=</span><span class="s2">&quot;You are an expert in analyzing AI research papers and trends&quot;</span><span class="p">,</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">search_tool</span><span class="p">],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">writer</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">role</span><span class="o">=</span><span class="s2">&quot;Technical Writer&quot;</span><span class="p">,</span>
    <span class="n">goal</span><span class="o">=</span><span class="s2">&quot;Create engaging content about AI developments&quot;</span><span class="p">,</span>
    <span class="n">backstory</span><span class="o">=</span><span class="s2">&quot;You transform complex technical concepts into accessible content&quot;</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># Define tasks for each agent</span>
<span class="n">research_task</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Research the latest developments in large language models&quot;</span><span class="p">,</span>
    <span class="n">agent</span><span class="o">=</span><span class="n">researcher</span><span class="p">,</span>
    <span class="n">expected_output</span><span class="o">=</span><span class="s2">&quot;A comprehensive report on recent LLM advancements&quot;</span>
<span class="p">)</span>

<span class="n">writing_task</span> <span class="o">=</span> <span class="n">Task</span><span class="p">(</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Write a blog post about the latest LLM developments&quot;</span><span class="p">,</span>
    <span class="n">agent</span><span class="o">=</span><span class="n">writer</span><span class="p">,</span>
    <span class="n">expected_output</span><span class="o">=</span><span class="s2">&quot;A 500-word blog post about LLM advancements&quot;</span><span class="p">,</span>
    <span class="n">context</span><span class="o">=</span><span class="p">[</span><span class="n">research_task</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Create a crew with the agents and tasks</span>
<span class="n">crew</span> <span class="o">=</span> <span class="n">Crew</span><span class="p">(</span>
    <span class="n">agents</span><span class="o">=</span><span class="p">[</span><span class="n">researcher</span><span class="p">,</span> <span class="n">writer</span><span class="p">],</span>
    <span class="n">tasks</span><span class="o">=</span><span class="p">[</span><span class="n">research_task</span><span class="p">,</span> <span class="n">writing_task</span><span class="p">],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="c1"># Execute the crew&#39;s tasks</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">crew</span><span class="o">.</span><span class="n">kickoff</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div>
<p><strong>Popularity:</strong> Medium but rapidly growing. CrewAI is newer but gaining popularity for role-based agents.</p>
<p><strong>Drawbacks:</strong>
- Newer framework with less community support
- Limited tool integrations compared to more established frameworks
- Documentation is still evolving</p>
<h2 id="technical-deep-dive">Technical Deep Dive</h2>
<h3 id="function-calling-implementation">Function Calling Implementation</h3>
<p>Function calling in LLMs involves several key technical components:</p>
<ol>
<li>
<p><strong>JSON Schema Definition</strong>: Functions are defined using JSON Schema, which provides a structured way to describe the function's parameters and return values.</p>
</li>
<li>
<p><strong>Prompt Engineering</strong>: The LLM needs to be prompted in a way that encourages it to use the provided functions when appropriate. This often involves system prompts that instruct the model to output JSON when calling tools. Implementation examples:</p>
</li>
<li><a href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb">OpenAI Function Calling System Prompt Example</a></li>
<li><a href="https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/tool_use_with_claude.ipynb">Anthropic Tool Use System Prompt</a></li>
<li><a href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/prompts/chat.py">LangChain Tool Calling Templates</a></li>
</ol>
<p>Example system prompt for JSON tool calling:
   <div class="highlight"><pre><span></span><code>You are a helpful assistant with access to tools. When you need to use a tool, respond in the following JSON format:
{&quot;tool&quot;: &quot;tool_name&quot;, &quot;parameters&quot;: {&quot;param1&quot;: &quot;value1&quot;, &quot;param2&quot;: &quot;value2&quot;}}

If you don&#39;t need to use a tool, respond normally. Always use proper JSON with double quotes for both keys and string values.
</code></pre></div></p>
<ol>
<li>
<p><strong>Output Parsing</strong>: The LLM's output needs to be parsed to extract function calls and their arguments.</p>
</li>
<li>
<p><strong>Function Execution</strong>: The extracted function calls need to be executed in the application environment.</p>
</li>
<li>
<p><strong>Result Integration</strong>: The results of the function execution need to be integrated back into the conversation.</p>
</li>
</ol>
<p>Here's a detailed look at how function calling is implemented in the OpenAI API:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 1. Define the function schema</span>
<span class="n">function_schema</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;get_stock_price&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Get the current stock price for a company&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;symbol&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The stock symbol, e.g., AAPL for Apple&quot;</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;symbol&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># 2. Send the request to the API with the function definition</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s the current stock price of Apple?&quot;</span><span class="p">}],</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">function_schema</span><span class="p">],</span>
    <span class="n">tool_choice</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
<span class="p">)</span>

<span class="c1"># 3. Parse the response to extract function calls</span>
<span class="n">message</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span>
<span class="n">tool_calls</span> <span class="o">=</span> <span class="n">message</span><span class="o">.</span><span class="n">tool_calls</span>

<span class="k">if</span> <span class="n">tool_calls</span><span class="p">:</span>
    <span class="c1"># 4. Execute the function</span>
    <span class="n">function_call</span> <span class="o">=</span> <span class="n">tool_calls</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">function</span>
    <span class="n">function_name</span> <span class="o">=</span> <span class="n">function_call</span><span class="o">.</span><span class="n">name</span>
    <span class="n">function_args</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">function_call</span><span class="o">.</span><span class="n">arguments</span><span class="p">)</span>

    <span class="c1"># Call the actual function</span>
    <span class="k">if</span> <span class="n">function_name</span> <span class="o">==</span> <span class="s2">&quot;get_stock_price&quot;</span><span class="p">:</span>
        <span class="n">stock_price</span> <span class="o">=</span> <span class="n">get_real_stock_price</span><span class="p">(</span><span class="n">function_args</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span><span class="p">])</span>

    <span class="c1"># 5. Send the function result back to the API</span>
    <span class="n">second_response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s the current stock price of Apple?&quot;</span><span class="p">},</span>
            <span class="n">message</span><span class="p">,</span>
            <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;tool&quot;</span><span class="p">,</span>
                <span class="s2">&quot;tool_call_id&quot;</span><span class="p">:</span> <span class="n">tool_calls</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">function_name</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span><span class="s2">&quot;price&quot;</span><span class="p">:</span> <span class="n">stock_price</span><span class="p">,</span> <span class="s2">&quot;currency&quot;</span><span class="p">:</span> <span class="s2">&quot;USD&quot;</span><span class="p">})</span>
            <span class="p">}</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># Final response with the information</span>
    <span class="n">final_response</span> <span class="o">=</span> <span class="n">second_response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">final_response</span><span class="p">)</span>
</code></pre></div>
<p>Under the hood, the LLM has been trained to:</p>
<ol>
<li>Recognize when a function would be useful for answering a query</li>
<li>Generate a properly formatted function call with appropriate arguments</li>
<li>Incorporate the function results into its response</li>
</ol>
<p>This is typically implemented through fine-tuning on function calling examples or through few-shot learning in the prompt.</p>
<h3 id="react-implementation">ReAct Implementation</h3>
<p>ReAct (Reasoning and Acting) is a powerful paradigm that combines reasoning traces with actions. Here's a detailed look at how ReAct is implemented in LangChain:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">AgentType</span><span class="p">,</span> <span class="n">initialize_agent</span><span class="p">,</span> <span class="n">load_tools</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.memory</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConversationBufferMemory</span>

<span class="c1"># Initialize the language model</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Load tools</span>
<span class="n">tools</span> <span class="o">=</span> <span class="n">load_tools</span><span class="p">([</span><span class="s2">&quot;serpapi&quot;</span><span class="p">,</span> <span class="s2">&quot;llm-math&quot;</span><span class="p">],</span> <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>

<span class="c1"># Set up memory</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">(</span><span class="n">memory_key</span><span class="o">=</span><span class="s2">&quot;chat_history&quot;</span><span class="p">)</span>

<span class="c1"># Create the ReAct agent</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">initialize_agent</span><span class="p">(</span>
    <span class="n">tools</span><span class="p">,</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="n">agent</span><span class="o">=</span><span class="n">AgentType</span><span class="o">.</span><span class="n">REACT_DOCSTORE</span><span class="p">,</span>  <span class="c1"># Using the ReAct agent type</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">memory</span><span class="o">=</span><span class="n">memory</span>
<span class="p">)</span>

<span class="c1"># Run the agent</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="s2">&quot;What was the high temperature in SF yesterday? What is that number raised to the .023 power?&quot;</span>
<span class="p">)</span>
</code></pre></div>
<p>Under the hood, LangChain's ReAct implementation works through these key components:</p>
<ol>
<li>
<p><strong>Prompt Template</strong>: A specialized prompt that instructs the LLM to follow the Thought-Action-Observation pattern</p>
</li>
<li>
<p><strong>Output Parser</strong>: Parses the LLM's output to extract the thought, action, and action input</p>
</li>
<li>
<p><strong>Tool Execution</strong>: Executes the specified action with the provided input</p>
</li>
<li>
<p><strong>Agent Loop</strong>: Continues the cycle until a final answer is reached</p>
</li>
</ol>
<p><strong>Implementation Links:</strong>
- <a href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/base.py">LangChain ReAct Agent Source Code</a>
- <a href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/prompt.py">ReAct Prompt Templates</a>
- <a href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/agent.py">Agent Executor Implementation</a></p>
<p>The ReAct implementation demonstrates how structured reasoning can be combined with tool use to create more effective agents.</p>
<h3 id="mcp-implementation">MCP Implementation</h3>
<p><strong>Motivation:</strong> The Model Context Protocol (MCP) was developed to address several key challenges in LLM applications:</p>
<ol>
<li>
<p><strong>Standardization</strong>: Different LLM providers and frameworks use different formats for context injection, making it difficult to switch between them.</p>
</li>
<li>
<p><strong>Optimization</strong>: Naively injecting context can lead to token wastage and reduced performance.</p>
</li>
<li>
<p><strong>Modularity</strong>: Applications often need to combine multiple types of context (memory, tools, etc.) in a flexible way.</p>
</li>
<li>
<p><strong>Scalability</strong>: As applications grow more complex, managing context becomes increasingly challenging.</p>
</li>
</ol>
<p><strong>How It Works:</strong> MCP provides a standardized way to inject context, tools, and memory into LLM prompts. Here's a technical overview of how MCP works:</p>
<ol>
<li>
<p><strong>Context Bundle</strong>: The client creates a context bundle containing the user input, memory configuration, tools, and other context.</p>
</li>
<li>
<p><strong>MCP Server</strong>: The bundle is sent to an MCP server, which processes it and constructs an optimized prompt.</p>
</li>
<li>
<p><strong>Prompt Construction</strong>: The server uses templates and plugins to construct a prompt that includes the relevant context and tools.</p>
</li>
<li>
<p><strong>LLM Processing</strong>: The constructed prompt is sent to the LLM for processing.</p>
</li>
<li>
<p><strong>Response Parsing</strong>: The LLM's response is parsed to extract tool calls and other structured information. This often relies on system prompts that instruct the model to output in specific JSON formats when using tools. See <a href="https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/prompt_template/prompt_template_config.py">MCP JSON Response Format Example</a> for implementation details.</p>
</li>
</ol>
<p><strong>Internal Implementation:</strong> The MCP architecture consists of several key components:</p>
<ol>
<li><strong>Protocol Definition</strong>: Standardized schemas for context bundles, tools, memory, and other components. These schemas define the structure and format of data exchanged between clients and the MCP server, ensuring consistency and interoperability across different implementations. The protocol includes definitions for message formats, parameter types, and response structures that facilitate seamless communication between components.</li>
<li><a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/kernel">Semantic Kernel Protocol Implementation</a></li>
<li>
<p><a href="https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/schema">LangChain Protocol Implementation</a></p>
</li>
<li>
<p><strong>Server Implementation</strong>: A FastAPI server that processes context bundles and constructs prompts. The server receives context bundles from clients, applies optimization algorithms to select relevant context, constructs prompts using templates, and manages the communication with LLM providers. It handles authentication, rate limiting, caching, and other infrastructure concerns to ensure reliable and efficient operation.</p>
</li>
<li>
<p><a href="https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/connectors/ai/open_ai/services/azure_chat_completion.py">Semantic Kernel Server Implementation</a></p>
</li>
<li>
<p><strong>Plugin System</strong>: Extensible plugins for different types of context (memory, tools, etc.). Plugins are modular components that can be dynamically loaded to extend the functionality of the MCP server. Each plugin type handles a specific aspect of context processing, such as retrieving relevant memories, defining available tools, or incorporating domain-specific knowledge. The plugin architecture allows for easy customization and extension without modifying the core server code.</p>
</li>
<li>
<p><a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/plugins">Semantic Kernel Plugin System</a></p>
</li>
<li>
<p><strong>Client Libraries</strong>: Libraries for different programming languages to interact with MCP servers. These libraries provide high-level abstractions and utilities for creating context bundles, sending them to MCP servers, and processing the responses. They handle serialization, error handling, retries, and other client-side concerns to simplify integration with applications. Client libraries are available for multiple programming languages to support diverse development environments.</p>
</li>
<li><a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors">Semantic Kernel Python Client</a></li>
</ol>
<p><strong>Framework Adoption:</strong></p>
<ol>
<li><strong>Semantic Kernel</strong>: Microsoft's Semantic Kernel has fully embraced MCP as its core architecture.</li>
<li>Status: Production-ready, actively maintained</li>
<li>
<p><a href="https://learn.microsoft.com/en-us/semantic-kernel/">Semantic Kernel MCP Documentation</a></p>
</li>
<li>
<p><strong>LangChain</strong>: LangChain has implemented some MCP concepts but with its own variations.</p>
</li>
<li>Status: Partial adoption, evolving</li>
<li>
<p><a href="https://python.langchain.com/docs/modules/model_io/">LangChain Schema Documentation</a></p>
</li>
<li>
<p><strong>LlamaIndex</strong>: LlamaIndex has begun adopting MCP-like concepts for context management.</p>
</li>
<li>Status: Early adoption, experimental</li>
<li>
<p><a href="https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/managing_state/">LlamaIndex Context Management</a></p>
</li>
<li>
<p><strong>Custom Implementations</strong>: Many organizations are implementing custom MCP-like systems.</p>
</li>
<li>Status: Varied, from experimental to production</li>
</ol>
<p><strong>Future Directions:</strong> MCP is evolving in several key directions:</p>
<ol>
<li><strong>Standardization</strong>: Efforts to create a cross-framework standard for context injection</li>
<li><strong>Optimization</strong>: More sophisticated context selection and prompt construction algorithms</li>
<li><strong>Multimodal Support</strong>: Extending MCP to handle images, audio, and other modalities</li>
<li><strong>Distributed Architecture</strong>: Scaling MCP to handle large-scale applications</li>
</ol>
<p>Here's a simplified implementation of an MCP server:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">fastapi</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastAPI</span><span class="p">,</span> <span class="n">HTTPException</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">FastAPI</span><span class="p">()</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MemoryConfig</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">enable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="nb">filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Tool</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">description</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ContextBundle</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">user_input</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MemoryConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">tools</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">additional_context</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PromptResponse</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">context_used</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>

<span class="nd">@app</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s2">&quot;/mcp/context&quot;</span><span class="p">,</span> <span class="n">response_model</span><span class="o">=</span><span class="n">PromptResponse</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">process_context</span><span class="p">(</span><span class="n">bundle</span><span class="p">:</span> <span class="n">ContextBundle</span><span class="p">):</span>
    <span class="c1"># Initialize the prompt components</span>
    <span class="n">prompt_parts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">context_used</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Add system instructions</span>
    <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;You are a helpful AI assistant.&quot;</span><span class="p">)</span>

    <span class="c1"># Add memory if enabled</span>
    <span class="k">if</span> <span class="n">bundle</span><span class="o">.</span><span class="n">memory</span> <span class="ow">and</span> <span class="n">bundle</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">enable</span><span class="p">:</span>
        <span class="c1"># In a real implementation, this would retrieve relevant memories</span>
        <span class="n">memories</span> <span class="o">=</span> <span class="n">retrieve_memories</span><span class="p">(</span><span class="n">bundle</span><span class="o">.</span><span class="n">user_input</span><span class="p">,</span> <span class="n">bundle</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">bundle</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">filter</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">memories</span><span class="p">:</span>
            <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Relevant context from memory:&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">memory</span> <span class="ow">in</span> <span class="n">memories</span><span class="p">:</span>
                <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- </span><span class="si">{</span><span class="n">memory</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">context_used</span><span class="p">[</span><span class="s2">&quot;memories&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">memories</span>

    <span class="c1"># Add tools if provided</span>
    <span class="k">if</span> <span class="n">bundle</span><span class="o">.</span><span class="n">tools</span><span class="p">:</span>
        <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">You have access to the following tools:&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">tool</span> <span class="ow">in</span> <span class="n">bundle</span><span class="o">.</span><span class="n">tools</span><span class="p">:</span>
            <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">tool</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">tool</span><span class="o">.</span><span class="n">description</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameters: </span><span class="si">{</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">tool</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span><span class="w"> </span><span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">context_used</span><span class="p">[</span><span class="s2">&quot;tools&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">bundle</span><span class="o">.</span><span class="n">tools</span><span class="p">]</span>

        <span class="c1"># Add instructions for tool usage</span>
        <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">To use a tool, respond with:&quot;</span><span class="p">)</span>
        <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;{&quot;tool&quot;: &quot;tool_name&quot;, &quot;parameters&quot;: {&quot;param1&quot;: &quot;value1&quot;}}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># Add additional context if provided</span>
    <span class="k">if</span> <span class="n">bundle</span><span class="o">.</span><span class="n">additional_context</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">bundle</span><span class="o">.</span><span class="n">additional_context</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">context_used</span><span class="p">[</span><span class="s2">&quot;additional_context&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bundle</span><span class="o">.</span><span class="n">additional_context</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="c1"># Add the user input</span>
    <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">User: </span><span class="si">{</span><span class="n">bundle</span><span class="o">.</span><span class="n">user_input</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">prompt_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Assistant:&quot;</span><span class="p">)</span>

    <span class="c1"># Combine all parts into the final prompt</span>
    <span class="n">final_prompt</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">prompt_parts</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">PromptResponse</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">final_prompt</span><span class="p">,</span> <span class="n">context_used</span><span class="o">=</span><span class="n">context_used</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">retrieve_memories</span><span class="p">(</span><span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">filter_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]):</span>
    <span class="c1"># In a real implementation, this would query a vector database</span>
    <span class="c1"># For this example, we&#39;ll return dummy memories</span>
    <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;This is a relevant memory&quot;</span><span class="p">,</span> <span class="s2">&quot;This is another relevant memory&quot;</span><span class="p">]</span>
</code></pre></div>
<p>This implementation demonstrates the core concepts of MCP:</p>
<ol>
<li>Standardized context bundle format</li>
<li>Modular prompt construction</li>
<li>Memory integration</li>
<li>Tool definition and usage instructions</li>
<li>Additional context injection</li>
</ol>
<p>The actual implementation would include more sophisticated memory retrieval, tool handling, and prompt optimization.</p>
<h2 id="evaluation-and-benchmarks">Evaluation and Benchmarks</h2>
<p>Evaluating LLM agents is challenging due to the complexity and diversity of tasks they can perform. Several benchmarks and evaluation frameworks have emerged:</p>
<h3 id="agentbench">AgentBench</h3>
<p><strong>Reference Link:</strong> <a href="https://arxiv.org/abs/2308.03688">AgentBench Paper</a></p>
<p>AgentBench evaluates agents on eight diverse tasks:</p>
<ol>
<li>Operating System Interaction</li>
<li>Database Querying</li>
<li>Knowledge Graph Querying</li>
<li>Web Browsing</li>
<li>Digital Card Game Playing</li>
<li>Embodied Household Tasks</li>
<li>Open-Domain Question Answering</li>
<li>Web Shopping</li>
</ol>
<p>Results show that even advanced models like GPT-4 achieve only 54.2% success rate, highlighting the challenges in building effective agents.</p>
<h3 id="toolbench">ToolBench</h3>
<p><strong>Reference Link:</strong> <a href="https://arxiv.org/abs/2307.16789">ToolBench Paper</a></p>
<p>ToolBench focuses specifically on tool use capabilities:</p>
<ol>
<li>Tool Selection: Choosing the right tool for a task</li>
<li>Parameter Filling: Providing correct parameters</li>
<li>Tool Composition: Using multiple tools together</li>
<li>Error Recovery: Handling errors in tool execution</li>
</ol>
<p>The benchmark includes 16,464 tasks involving 248 real-world APIs.</p>
<h3 id="react-benchmark">ReAct Benchmark</h3>
<p><strong>Reference Link:</strong> <a href="https://arxiv.org/abs/2210.03629">ReAct Paper</a></p>
<p>The ReAct benchmark evaluates agents on:</p>
<ol>
<li>HotpotQA: Multi-hop question answering</li>
<li>FEVER: Fact verification</li>
<li>WebShop: Web shopping simulation</li>
<li>ALFWorld: Household tasks in a text environment</li>
</ol>
<p>Results show that ReAct outperforms standard prompting and chain-of-thought approaches.</p>
<h3 id="key-metrics">Key Metrics</h3>
<p>When evaluating LLM agents, several key metrics are important:</p>
<ol>
<li><strong>Task Completion Rate</strong>: Percentage of tasks successfully completed</li>
<li><strong>Efficiency</strong>: Number of steps or API calls needed to complete a task</li>
<li><strong>Accuracy</strong>: Correctness of the final result</li>
<li><strong>Robustness</strong>: Performance under different conditions or with unexpected inputs</li>
<li><strong>Cost</strong>: Computational and financial cost of running the agent</li>
</ol>
<h2 id="future-directions">Future Directions</h2>
<h3 id="multimodal-agents">Multimodal Agents</h3>
<p>Future agents will increasingly incorporate multimodal capabilities:</p>
<ul>
<li>Vision for understanding images and videos</li>
<li>Audio for speech recognition and generation</li>
<li>Tactile feedback for robotic applications</li>
</ul>
<p>This will enable more natural and comprehensive interactions with the physical world.</p>
<h3 id="agentic-memory">Agentic Memory</h3>
<p>Advanced memory systems will enhance agent capabilities:</p>
<ul>
<li>Episodic memory for remembering past interactions</li>
<li>Procedural memory for learning and improving skills</li>
<li>Semantic memory for storing knowledge</li>
<li>Working memory for handling complex reasoning tasks</li>
</ul>
<h3 id="autonomous-learning">Autonomous Learning</h3>
<p>Agents will become more capable of learning from experience:</p>
<ul>
<li>Self-improvement through reflection</li>
<li>Learning new tools and APIs</li>
<li>Adapting to user preferences</li>
<li>Discovering new strategies for problem-solving</li>
</ul>
<h3 id="multi-agent-ecosystems">Multi-Agent Ecosystems</h3>
<p>Complex systems of specialized agents will emerge:</p>
<ul>
<li>Hierarchical organization with manager and worker agents</li>
<li>Collaborative problem-solving</li>
<li>Market-based allocation of tasks</li>
<li>Emergent behaviors from agent interactions</li>
</ul>
<h3 id="alignment-and-safety">Alignment and Safety</h3>
<p>Ensuring agents act in accordance with human values will be crucial:</p>
<ul>
<li>Constitutional AI approaches</li>
<li>Human feedback mechanisms</li>
<li>Sandboxed execution environments</li>
<li>Monitoring and intervention systems</li>
</ul>
<h2 id="references">References</h2>
<ol>
<li>
<p>Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., &amp; Cao, Y. (2022). ReAct: Synergizing Reasoning and Acting in Language Models. arXiv:2210.03629.</p>
</li>
<li>
<p>Schick, T., Dwivedi-Yu, J., Dess, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., &amp; Scialom, T. (2023). ToolFormer: Language Models Can Teach Themselves to Use Tools. arXiv:2302.04761.</p>
</li>
<li>
<p>Shen, Y., Jiang, Y., Kalyan, A., Rajani, N., Aggarwal, K., Zhou, B., Mooney, R., &amp; Bansal, M. (2023). HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. arXiv:2303.17580.</p>
</li>
<li>
<p>Patil, S., Peng, B., Shen, Y., Zhou, X., Liang, P., Salakhutdinov, R., &amp; Ren, X. (2023). Gorilla: Large Language Model Connected with Massive APIs. arXiv:2305.15334.</p>
</li>
<li>
<p>Huang, W., Xie, S. M., Stein, S. A., Metz, L., Shrivastava, A., Freeman, C. D., &amp; Dyer, E. (2022). Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents. arXiv:2201.07207.</p>
</li>
<li>
<p>Qin, Y., Liang, W., Ye, H., Zhong, V., Zhuang, Y., Li, X., Cui, Y., Gu, N., Liu, X., &amp; Jiang, N. (2023). ToolBench: Towards Evaluating and Enhancing Tool Manipulation Capabilities of Large Language Models. arXiv:2307.16789.</p>
</li>
<li>
<p>Liu, Q., Yao, S., Chen, F., Wang, C., Brohan, A., Xu, J., Zeng, A., Zhao, J., Ahn, M., Yan, W., Peng, B., Duan, N., &amp; Russakovsky, O. (2023). AgentBench: Evaluating LLMs as Agents. arXiv:2308.03688.</p>
</li>
<li>
<p>Wu, C., Hou, S., Zhao, Z., Xu, C., &amp; Yin, P. (2023). TALM: Tool Augmented Language Models. arXiv:2306.05301.</p>
</li>
<li>
<p>Qian, W., Patil, S. A., Peng, B., Bisk, Y., Zettlemoyer, L., Gupta, S., Kembhavi, A., &amp; Schwing, A. (2023). Communicative Agents for Software Development. arXiv:2307.07924.</p>
</li>
<li>
<p>Hong, X., Xiong, Z., Xiao, C., Boyd-Graber, J., &amp; Daum III, H. (2023). Cognitive Architectures for Language Agents. arXiv:2309.02427.</p>
</li>
</ol>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>